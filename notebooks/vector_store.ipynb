{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T06:26:38.856924Z",
     "start_time": "2023-10-20T06:26:38.618714Z"
    }
   },
   "id": "d3e7c9e21dd4790"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import json\n",
    "import re, os\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain import hub\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import utils.paper_utils as pu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T06:26:39.183761Z",
     "start_time": "2023-10-20T06:26:39.103442Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Embedding Store"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db14611f82cabdf1"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "CONNECTION_STRING = (\n",
    "    f\"postgresql+psycopg2://{pu.db_params['user']}:{pu.db_params['password']}\"\n",
    "    f\"@{pu.db_params['host']}:{pu.db_params['port']}/{pu.db_params['dbname']}\"\n",
    ")\n",
    "COLLECTION_NAME = 'arxiv_vectors'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T06:26:43.943220Z",
     "start_time": "2023-10-20T06:26:43.866723Z"
    }
   },
   "id": "973b012d75a092e9"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n",
    "store = PGVector(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T06:26:50.755837Z",
     "start_time": "2023-10-20T06:26:45.917429Z"
    }
   },
   "id": "783bb30beea52c44"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "question = \"Is there a literary interpretation of large language models?\"\n",
    "docs = store.similarity_search(question)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T06:26:55.255116Z",
     "start_time": "2023-10-20T06:26:50.756937Z"
    }
   },
   "id": "d03a18c5b006bf3e"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "retriever = store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 7})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T06:26:55.347631Z",
     "start_time": "2023-10-20T06:26:55.264460Z"
    }
   },
   "id": "f00b819d6b7c48"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "ConfigError",
     "evalue": "field \"client\" not yet prepared so type is still a ForwardRef, you might need to call CohereRerank.update_forward_refs().",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConfigError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m compressor \u001B[38;5;241m=\u001B[39m \u001B[43mCohereRerank\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m compressor\u001B[38;5;241m.\u001B[39mupdate_forward_refs()\n\u001B[1;32m      3\u001B[0m compression_retriever \u001B[38;5;241m=\u001B[39m ContextualCompressionRetriever(\n\u001B[1;32m      4\u001B[0m     base_compressor\u001B[38;5;241m=\u001B[39mcompressor, base_retriever\u001B[38;5;241m=\u001B[39mretriever\n\u001B[1;32m      5\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llmpedia/lib/python3.11/site-packages/pydantic/main.py:339\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llmpedia/lib/python3.11/site-packages/pydantic/main.py:1076\u001B[0m, in \u001B[0;36mpydantic.main.validate_model\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llmpedia/lib/python3.11/site-packages/pydantic/fields.py:860\u001B[0m, in \u001B[0;36mpydantic.fields.ModelField.validate\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mConfigError\u001B[0m: field \"client\" not yet prepared so type is still a ForwardRef, you might need to call CohereRerank.update_forward_refs()."
     ]
    }
   ],
   "source": [
    "compressor = CohereRerank()\n",
    "compressor.update_forward_refs()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T07:05:03.504592Z",
     "start_time": "2023-10-20T07:05:02.086466Z"
    }
   },
   "id": "9eb62451f779affb"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='One way to speed up the attention mechanism in LLMs is by using sliding window attention. Sliding window attention limits each token to attend to at most W tokens from the previous layer, reducing the number of operations and memory required (arxiv:2310.06825). Another approach is to use low-rank adaptation, which updates the weight matrix of pre-trained models with a low-rank decomposition, making the training more efficient (arxiv:2309.12307). Additionally, zero-initialized attention can be used at the last layers of the transformer to speed up the attention mechanism (arxiv:2303.16199).' additional_kwargs={} example=False\n",
      "Tokens Used: 3543\n",
      "\tPrompt Tokens: 3415\n",
      "\tCompletion Tokens: 128\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0053785000000000005\n"
     ]
    }
   ],
   "source": [
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use as many sentences as needed to provide a thorough, complete but concise answer.\n",
    "When providing your answer add citations referencing the relevant arxiv_codes (e.g.: *reference content* (arxiv:1234.5678)).\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "rag_prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt_custom \n",
    "    | llm \n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    print(rag_chain.invoke(\"How can one speed up the attention mechanism in LLMs?\"))\n",
    "    \n",
    "print(cb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T00:15:56.121593Z",
     "start_time": "2023-10-19T00:15:41.136043Z"
    }
   },
   "id": "2b9ab80d58a9d6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7fffb7a2e2a5ccf6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
