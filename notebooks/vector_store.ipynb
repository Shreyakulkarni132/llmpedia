{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T21:52:14.681405Z",
     "start_time": "2023-10-22T21:52:14.667277Z"
    }
   },
   "id": "d3e7c9e21dd4790"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import json\n",
    "import re, os\n",
    "from pydantic import BaseModel\n",
    "import cohere\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings, HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain import hub\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import utils.paper_utils as pu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T21:52:16.355705Z",
     "start_time": "2023-10-22T21:52:14.682477Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Embedding Store"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db14611f82cabdf1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "CONNECTION_STRING = (\n",
    "    f\"postgresql+psycopg2://{pu.db_params['user']}:{pu.db_params['password']}\"\n",
    "    f\"@{pu.db_params['host']}:{pu.db_params['port']}/{pu.db_params['dbname']}\"\n",
    ")\n",
    "COLLECTION_NAME = 'arxiv_vectors'\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T21:52:05.867291Z",
     "start_time": "2023-10-22T21:52:05.793564Z"
    }
   },
   "id": "973b012d75a092e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=HUGGINGFACE_API_KEY,\n",
    "    model_name=\"thenlper/gte-large\"\n",
    ")\n",
    "\n",
    "store = PGVector(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-22T21:52:06.492854Z"
    }
   },
   "id": "783bb30beea52c44"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "retriever = store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T20:21:19.002415Z",
     "start_time": "2023-10-22T20:21:18.944332Z"
    }
   },
   "id": "f00b819d6b7c48"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m co \u001B[38;5;241m=\u001B[39m cohere\u001B[38;5;241m.\u001B[39mClient(key)\n\u001B[1;32m      9\u001B[0m compressor \u001B[38;5;241m=\u001B[39m CustomCohereRerank(client\u001B[38;5;241m=\u001B[39mco, top_n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m compression_retriever \u001B[38;5;241m=\u001B[39m ContextualCompressionRetriever(base_compressor\u001B[38;5;241m=\u001B[39mcompressor, base_retriever\u001B[38;5;241m=\u001B[39m\u001B[43mretriever\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class CustomCohereRerank(CohereRerank):\n",
    "    class Config(BaseModel.Config):\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "CustomCohereRerank.update_forward_refs()\n",
    "key = os.getenv(\"COHERE_API_KEY\")\n",
    "co = cohere.Client(key)\n",
    "\n",
    "compressor = CustomCohereRerank(client=co, top_n=3)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T21:51:58.485113Z",
     "start_time": "2023-10-22T21:51:58.425784Z"
    }
   },
   "id": "deb4b4ab2a03ee75"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compression_retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 15\u001B[0m\n\u001B[1;32m      5\u001B[0m template \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mUse the following pieces of context to answer the question at the end. \u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124mIf you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know the answer, just say that you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know, don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt try to make up an answer.\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124mProvide a thorough, complete but concise answer. Try to be practical and reference any existing libraries or implementations mentioned on the documents if possible.\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124mQuestion: \u001B[39m\u001B[38;5;132;01m{question}\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124mHelpful Answer:\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     12\u001B[0m rag_prompt_custom \u001B[38;5;241m=\u001B[39m PromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(template)\n\u001B[1;32m     14\u001B[0m rag_chain \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m---> 15\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mcompression_retriever\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m: RunnablePassthrough()} \n\u001B[1;32m     16\u001B[0m     \u001B[38;5;241m|\u001B[39m rag_prompt_custom \n\u001B[1;32m     17\u001B[0m     \u001B[38;5;241m|\u001B[39m llm \n\u001B[1;32m     18\u001B[0m )\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_openai_callback() \u001B[38;5;28;01mas\u001B[39;00m cb:\n\u001B[1;32m     21\u001B[0m     res \u001B[38;5;241m=\u001B[39m rag_chain\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIs there a way to extend the context length of a pre-trained LLM?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'compression_retriever' is not defined"
     ]
    }
   ],
   "source": [
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1, max_tokens=900)\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Provide a thorough, complete but concise answer. Try to be practical and reference any existing libraries or implementations mentioned on the documents if possible.\n",
    "When providing your answer add citations referencing the relevant arxiv_codes (e.g.: *reference content* (arxiv:1234.5678)).\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "rag_prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": compression_retriever, \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt_custom \n",
    "    | llm \n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    res = rag_chain.invoke(\"Is there a way to extend the context length of a pre-trained LLM?\")\n",
    "    \n",
    "print(cb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T21:52:45.127452Z",
     "start_time": "2023-10-22T21:52:38.344260Z"
    }
   },
   "id": "7fffb7a2e2a5ccf6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'The main contribution of the CodeLlama model is that it provides a family of large language models for code, including foundation models, Python specializations, and instruction-following models, with different parameter sizes (7B, 13B, and 34B). These models have state-of-the-art performance among open models, support large input contexts, and have the ability to perform tasks such as code generation, code completion, code translation, bug fixing, code refinement, and code question answering. The CodeLlama models also show improvements on inputs with up to 100k tokens and outperform other publicly available models on benchmarks such as HumanEval, MBPP, and MultiPL-E (arxiv:2308.12950).'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.vector_store as vs\n",
    "vs.query_llmpedia(\"What is the main contribution of the CodeLlama model?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T21:54:58.896032Z",
     "start_time": "2023-10-22T21:53:14.844429Z"
    }
   },
   "id": "9e99a601147bbd32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bf256eb20c9dd901"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
