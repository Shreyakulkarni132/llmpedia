{"Published": "2023-09-07", "Title": "FLM-101B: An Open LLM and How to Train It with $100K Budget", "Authors": "Xiang Li, Yiqun Yao, Xin Jiang, Xuezhi Fang, Xuying Meng, Siqi Fan, Peng Han, Jing Li, Li Du, Bowen Qin, Zheng Zhang, Aixin Sun, Yequan Wang", "Summary": "Large language models (LLMs) have achieved remarkable success in NLP and multimodal tasks. Despite these successes, their development faces two main challenges: (i) high computational cost; and (ii) difficulty in conducting fair and objective evaluations. LLMs are prohibitively expensive, making it feasible for only a few major players to undertake their training, thereby constraining both research and application opportunities. This underscores the importance of cost-effective LLM training. In this paper, we utilize a growth strategy to significantly reduce LLM training cost. We demonstrate that an LLM with 101B parameters and 0.31TB tokens can be trained on a $100K budget. We also adopt a systematic evaluation paradigm for the IQ evaluation of LLMs, in complement to existing evaluations that focus more on knowledge-oriented abilities. We introduce our benchmark including evaluations on important aspects of intelligence including symbolic mapping, itrule understanding, pattern mining, and anti-interference. Such evaluations minimize the potential impact of memorization. Experimental results show that our model FLM-101B, trained with a budget of $100K, achieves comparable performance to powerful and well-known models, eg GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with contexts unseen in training data. The checkpoint of FLM-101B will be open-sourced at https://huggingface.co/CofeAI/FLM-101B.", "main_contribution": {"headline": "FLM-101B: A Cost-Effective Large Language Model with IQ Evaluation", "description": "The paper introduces FLM-101B, a Large Language Model (LLM) that can be trained with a budget of $100,000. The authors achieve this by utilizing a growth strategy, where the number of parameters is not fixed during the training process but expands from a smaller size to larger ones. This approach significantly reduces the computational cost of training LLMs. The authors also introduce a systematic evaluation paradigm for the IQ evaluation of LLMs, focusing on aspects such as symbolic mapping, rule understanding, pattern mining, and anti-interference. The FLM-101B model, trained with this cost-effective approach, demonstrates comparable performance to well-known models like GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with contexts unseen in the training data."}, "takeaways": {"headline": "Cost-Effective Training and IQ Evaluation for Large Language Models", "description": "The FLM-101B model and its training approach offer a cost-effective solution for training large language models, making it feasible for a wider range of researchers and organizations. The growth strategy used in the training process allows for the expansion of model parameters, leading to significant computational savings. The IQ evaluation paradigm introduced in this work provides a more comprehensive measure of a model's intelligence, focusing on its ability to generalize to unseen contexts and conditions. This approach could be beneficial for LLM practitioners aiming to train large models on a budget while ensuring their models' robustness and intelligence.", "example": "For instance, an organization aiming to train a large language model could adopt the growth strategy used in FLM-101B. Starting with a smaller model, they could progressively increase the number of parameters during the training process, thereby reducing the computational cost. They could also use the IQ evaluation paradigm to assess the model's intelligence, focusing on its ability to generalize to unseen contexts and conditions."}, "category": "TRAINING", "novelty_analysis": "The paper presents a novel approach to training large language models in a cost-effective manner. The use of a growth strategy, where the number of parameters expands during the training process, is a unique contribution to the field. Additionally, the introduction of a systematic IQ evaluation paradigm for LLMs, focusing on their ability to generalize to unseen contexts, is a significant advancement in the evaluation of these models.", "novelty_score": 3, "technical_analysis": "The paper is quite technical, delving into the details of the growth strategy used for training the model, the architecture of the FLM-101B model, and the specifics of the IQ evaluation paradigm. It requires a solid understanding of LLMs, their training processes, and evaluation metrics to fully comprehend the methodologies and results presented.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and provides a comprehensive overview of the FLM-101B model, its training process, and evaluation. The clear presentation of the growth strategy and the IQ evaluation paradigm, along with the comparative results with other well-known models, makes it an engaging read for those interested in cost-effective training of large language models and their evaluation.", "enjoyable_score": 2}