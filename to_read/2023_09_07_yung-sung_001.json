{"Published": "2023-09-07", "Title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models", "Authors": "Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James Glass, Pengcheng He", "Summary": "Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining. We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning. Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers. We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA by 12-17% absolute points, demonstrating its potential in making LLMs reliably generate truthful facts.", "main_contribution": {"headline": "Decoding by Contrasting Layers (DoLa) Enhances Factuality in Large Language Models", "description": "The paper introduces Decoding by Contrasting Layers (DoLa), a novel decoding strategy aimed at reducing hallucinations in Large Language Models (LLMs). DoLa exploits the hierarchical encoding of factual knowledge within transformer LLMs by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space. The approach dynamically selects appropriate layers for contrasting based on token difficulty, thereby catering to token and context complexity. Experimental results demonstrate that DoLa significantly improves truthfulness across multiple tasks without requiring external information retrieval or model fine-tuning. The method is shown to be effective in enhancing the factuality of LLMs, with improvements of up to 17% absolute points on the TruthfulQA task."}, "takeaways": {"headline": "DoLa: A Practical Strategy for Enhancing Factuality in LLMs", "description": "DoLa offers a practical and efficient strategy for enhancing the factuality of LLMs. By contrasting the differences in logits obtained from projecting the later layers versus earlier layers, DoLa is able to better surface factual knowledge and reduce the generation of incorrect facts. This approach can be applied to a variety of tasks, including multiple choice tasks and open-ended generation tasks, and has been shown to improve performance on tasks such as TruthfulQA and FACTOR. Furthermore, DoLa introduces minimal additional latency in the decoding process, making it a practical and useful decoding strategy for improving the truthfulness of LLMs.", "example": "For instance, when using an LLM to generate responses to a question, DoLa can be applied to ensure that the generated responses are more factual. Given a sequence of tokens, the model contrasts the higher-layer and lower-layer information to obtain the probability of the next token. This approach emphasizes the knowledge from higher layers and downplays the lower or intermediate layer knowledge, potentially making the LLM more factual and consequently reducing hallucinations."}, "category": "BEHAVIOR", "novelty_analysis": "The introduction of Decoding by Contrasting Layers (DoLa) presents a novel approach to enhancing the factuality of LLMs. While previous work has explored the hierarchical encoding of factual knowledge within transformer LLMs, DoLa is unique in its use of contrasting logits from different layers to improve the generation of factual content. The dynamic selection of layers for contrasting based on token difficulty further adds to the novelty of the approach.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, delving into the workings of transformer LLMs and the concept of contrasting logits from different layers. However, the authors provide clear explanations and illustrations, making the content accessible to readers with a basic understanding of LLMs and transformer architectures. The paper also provides a detailed description of the proposed DoLa method, including the method for dynamic premature layer selection and the contrastive decoding approach.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a clear narrative, making it an enjoyable read. The authors provide a thorough explanation of the proposed DoLa method, supported by clear illustrations and experimental results. The paper also offers practical insights into the application of DoLa, demonstrating its potential in enhancing the factuality of LLMs across a variety of tasks.", "enjoyable_score": 3}