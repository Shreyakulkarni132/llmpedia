{"Published": "2023-02-06", "Title": "Data Selection for Language Models via Importance Resampling", "Authors": "Sang Michael Xie, Shibani Santurkar, Tengyu Ma, Percy Liang", "Summary": "Selecting a suitable training dataset is crucial for both general-domain (e.g., GPT-3) and domain-specific (e.g., Codex) language models (LMs). We formalize this data selection problem as selecting a subset of a large raw unlabeled dataset to match a desired target distribution, given some unlabeled target samples. Due to the large scale and dimensionality of the raw text data, existing methods use simple heuristics to select data that are similar to a high-quality reference corpus (e.g., Wikipedia), or leverage experts to manually curate data. Instead, we extend the classic importance resampling approach used in low-dimensions for LM data selection. Crucially, we work in a reduced feature space to make importance weight estimation tractable over the space of text. To determine an appropriate feature space, we first show that KL reduction, a data metric that measures the proximity between selected data and the target in a feature space, has high correlation with average accuracy on 8 downstream tasks (r=0.89) when computed with simple n-gram features. From this observation, we present Data Selection with Importance Resampling (DSIR), an efficient and scalable algorithm that estimates importance weights in a reduced feature space (e.g., n-gram features in our instantiation) and selects data with importance resampling according to these weights. When training general-domain models (target is Wikipedia + books), DSIR improves over random selection and heuristic filtering baselines by 2--2.5% on the GLUE benchmark. When performing continued pretraining towards a specific domain, DSIR performs comparably to expert curated data across 8 target distributions.", "main_contribution": {"headline": "Data Selection with Importance Resampling (DSIR) for Efficient Language Model Training", "description": "The paper introduces Data Selection with Importance Resampling (DSIR), a novel method for selecting a subset of a large raw unlabeled dataset to match a desired target distribution for training language models. DSIR extends the classic importance resampling approach used in low-dimensions for language model data selection. It operates in a reduced feature space, specifically using n-gram features, to make importance weight estimation tractable over the space of text. The authors demonstrate that DSIR improves over random selection and heuristic filtering baselines by 2\u20132.5% on the GLUE benchmark when training general-domain models. Furthermore, DSIR performs comparably to expert curated data across 8 target distributions when performing continued pretraining towards a specific domain."}, "takeaways": {"headline": "DSIR Provides Efficient and Scalable Data Selection for Language Model Training", "description": "DSIR's approach to data selection can be leveraged to improve the efficiency and effectiveness of training both general-domain and domain-specific language models. By selecting a subset of raw data that matches the desired target distribution in a reduced feature space, DSIR can improve model performance on downstream tasks. This method is particularly useful when dealing with large-scale and high-dimensional raw text data where traditional methods may be computationally expensive or ineffective. DSIR's scalability and efficiency make it a promising tool for practitioners working with large language models.", "example": "For instance, if you are training a language model to understand medical texts, you can use DSIR to select a subset of a large raw dataset that closely matches the distribution of your target medical text data. This can lead to a more efficient training process and potentially improved model performance on medical text-related tasks."}, "category": "TRAINING", "novelty_analysis": "The paper presents a novel approach to data selection for training language models. While the concept of importance resampling is not new, its application to language model data selection in a reduced feature space is a unique contribution. The use of n-gram features for this purpose and the demonstrated correlation between KL reduction and downstream task performance further add to the novelty of the work.", "novelty_score": 3, "technical_analysis": "The paper is quite technical, delving into the specifics of the DSIR algorithm, the use of n-gram features, and the concept of KL reduction. It requires a solid understanding of language model training, data selection methods, and statistical concepts such as importance resampling and KL divergence. The paper also includes a detailed experimental setup and results section, further adding to its technical depth.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and provides a clear explanation of the proposed DSIR method, its implementation, and its benefits. The use of visual aids and detailed experimental results adds to the readability of the paper. However, the technical depth of the paper may make it a challenging read for those without a strong background in the field.", "enjoyable_score": 2}