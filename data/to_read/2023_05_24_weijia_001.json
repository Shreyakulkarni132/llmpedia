{"Published": "2023-05-24", "Title": "REPLUG: Retrieval-Augmented Black-Box Language Models", "Authors": "Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, Wen-tau Yih", "Summary": "We introduce REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model. Unlike prior retrieval-augmented LMs that train language models with special cross attention mechanisms to encode the retrieved text, REPLUG simply prepends retrieved documents to the input for the frozen black-box LM. This simple design can be easily applied to any existing retrieval and language models. Furthermore, we show that the LM can be used to supervise the retrieval model, which can then find documents that help the LM make better predictions. Our experiments demonstrate that REPLUG with the tuned retriever significantly improves the performance of GPT-3 (175B) on language modeling by 6.3%, as well as the performance of Codex on five-shot MMLU by 5.1%.", "main_contribution": {"headline": "REPLUG: A Novel Framework for Retrieval-Augmented Black-Box Language Models", "description": "The paper introduces REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model. Unlike previous retrieval-augmented LMs that require access to the internal LM representations, REPLUG simply prepends retrieved documents to the input for the frozen black-box LM. This design can be easily applied to any existing retrieval and language models. The paper also introduces REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that adapts the retriever to the LM using the language modeling scores as supervision signals. This approach is shown to significantly improve the performance of GPT-3 and Codex on language modeling and five-shot MMLU tasks respectively."}, "takeaways": {"headline": "REPLUG: A Flexible and Effective Approach for Enhancing Black-Box LLMs", "description": "REPLUG offers a flexible and effective approach to enhance the performance of black-box LLMs. By treating the LM as a black box and augmenting it with a tuneable retrieval model, REPLUG can be applied to any existing retrieval and language models, making it a versatile tool for LLM practitioners. Furthermore, the REPLUG LSR training scheme allows the retriever to be adapted to the LM, leading to improved retrieval quality and better performance on various tasks. For instance, REPLUG can be used to improve the performance of a chatbot by retrieving relevant documents that help the chatbot generate more accurate responses.", "example": "For example, given an input context 'What is the capital of France?', REPLUG first retrieves relevant documents (e.g., 'Paris is the capital of France.') from an external corpus. The retrieved document is then prepended to the input context and fed into the black-box LM to make the final prediction."}, "category": "ARCHITECTURES", "novelty_analysis": "REPLUG presents a novel approach to retrieval-augmented language modeling by treating the LM as a black box and augmenting it with a tuneable retrieval model. The introduction of the REPLUG LSR training scheme, which adapts the retriever to the LM using the language modeling scores as supervision signals, is also a unique contribution. This work is the first to demonstrate the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and improving in-context learning performance.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, detailing the design and implementation of the REPLUG framework and the REPLUG LSR training scheme. It provides a comprehensive explanation of the retrieval and input reformulation processes, as well as the training procedure for the dense retriever. However, the concepts and methodologies are explained clearly, making it accessible to readers with a basic understanding of LLMs and retrieval models.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and provides a clear and comprehensive explanation of the REPLUG framework and its applications. The use of diagrams to illustrate the REPLUG process and the detailed experimental results make the paper engaging and informative. The significant improvements achieved by REPLUG in various tasks also make the paper an interesting read for LLM practitioners.", "enjoyable_score": 3}