{"Published": "2023-06-01", "Title": "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker", "Authors": "Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov", "Summary": "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental states of other people$\\unicode{x2014}$is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision? We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity's beliefs, their estimation of other entities' beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches. Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks' theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines. Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.", "main_contribution": {"headline": "SymbolicToM: Enhancing Theory of Mind in LLMs with Symbolic Representation", "description": "The paper introduces SymbolicToM, a plug-and-play approach that enhances the Theory of Mind (ToM) capabilities of off-the-shelf Large Language Models (LLMs) without explicit supervision. ToM, the ability to reason about the mental states of others, is a crucial aspect of social intelligence that current LLMs lack. SymbolicToM addresses this by tracking the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. The approach uses graphical representations to track each entity's beliefs, their estimation of other entities' beliefs, and higher-order levels of reasoning. The authors demonstrate that SymbolicToM significantly enhances the ToM capabilities of LLMs in a zero-shot setting, showing robust out-of-distribution performance compared to supervised baselines."}, "takeaways": {"headline": "SymbolicToM: A Step Towards More Socially Intelligent LLMs", "description": "SymbolicToM's approach to enhancing the Theory of Mind capabilities of LLMs opens up new possibilities for creating more socially intelligent AI systems. By tracking the belief states of multiple characters, LLMs can better understand and reason about complex social interactions. This could be particularly useful in applications such as interactive storytelling, social simulations, or any context where understanding and predicting the behavior of multiple interacting agents is crucial. Furthermore, the plug-and-play nature of SymbolicToM means it can be applied to any off-the-shelf LLM, making it a versatile tool for AI researchers and practitioners.", "example": "For instance, in a chatbot application, SymbolicToM could be used to enhance the bot's ability to understand and respond to complex social scenarios. Given a conversation where multiple users are interacting, the chatbot could use SymbolicToM to track the beliefs and intentions of each user, allowing it to respond in a more socially intelligent manner."}, "category": "BEHAVIOR", "novelty_analysis": "SymbolicToM presents a novel approach to enhancing the Theory of Mind capabilities of LLMs. While previous efforts have primarily relied on supervised methods, SymbolicToM offers an unsupervised, decoding-time algorithm that uses explicit symbolic representation to track the belief states of multiple characters. This represents a significant advancement in the field of LLMs and their ability to understand and reason about social interactions.", "novelty_score": 3, "technical_analysis": "The paper is quite technical, delving into the specifics of how SymbolicToM constructs and updates belief-tracking structures, and how it uses these structures to answer questions. It requires a good understanding of LLMs, symbolic representation, and the concept of Theory of Mind. However, the authors do a good job of explaining these concepts, making the paper accessible to readers with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a compelling argument for the need for Theory of Mind capabilities in LLMs. The introduction of SymbolicToM and the demonstration of its effectiveness make for an engaging read. The paper also raises important questions about the limitations of current LLMs and the need for out-of-distribution evaluation, adding depth to the discussion.", "enjoyable_score": 2}