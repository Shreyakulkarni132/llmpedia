{"Published": "2023-03-30", "Title": "DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents", "Authors": "Varun Nair, Elliot Schumacher, Geoffrey Tso, Anitha Kannan", "Summary": "Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks. In safety-critical applications such as healthcare, the utility of these models is governed by their ability to generate outputs that are factually accurate and complete. In this work, we present dialog-enabled resolving agents (DERA). DERA is a paradigm made possible by the increased conversational abilities of LLMs, namely GPT-4. It provides a simple, interpretable forum for models to communicate feedback and iteratively improve output. We frame our dialog as a discussion between two agent types - a Researcher, who processes information and identifies crucial problem components, and a Decider, who has the autonomy to integrate the Researcher's information and makes judgments on the final output.   We test DERA against three clinically-focused tasks. For medical conversation summarization and care plan generation, DERA shows significant improvement over the base GPT-4 performance in both human expert preference evaluations and quantitative metrics. In a new finding, we also show that GPT-4's performance (70%) on an open-ended version of the MedQA question-answering (QA) dataset (Jin et al. 2021, USMLE) is well above the passing level (60%), with DERA showing similar performance. We release the open-ended MEDQA dataset at https://github.com/curai/curai-research/tree/main/DERA.", "main_contribution": {"headline": "DERA: A Dialog-Enabled Resolving Agent Framework for Improving LLM Outputs", "description": "The paper introduces Dialog-Enabled Resolving Agents (DERA), a novel framework designed to enhance the output of Large Language Models (LLMs) like GPT-4. DERA employs a dialog-based approach where two agents, a Researcher and a Decider, interact to iteratively refine the model's output. The Researcher identifies crucial problem components, while the Decider integrates this information and makes judgments on the final output. The authors demonstrate DERA's effectiveness in three clinically-focused tasks: medical conversation summarization, care plan generation, and an open-ended version of the MedQA question-answering dataset. In both human expert preference evaluations and quantitative metrics, DERA shows significant improvement over the base GPT-4 performance in medical conversation summarization and care plan generation tasks."}, "takeaways": {"headline": "DERA Enhances LLM Performance in Clinically-Focused Tasks", "description": "The DERA framework presents a promising approach to improve the performance of LLMs in tasks that require factual accuracy and completeness, particularly in safety-critical applications like healthcare. By breaking down tasks into sub-tasks and using a dialog-based approach for iterative refinement, DERA can significantly improve the quality of LLM outputs. This approach could be particularly beneficial in tasks that involve long-form generation with fine-grained details. For practitioners working with LLMs in healthcare or other critical domains, DERA offers a valuable tool for enhancing model outputs and reducing errors.", "example": "For instance, in a healthcare application, an LLM could be used to generate a summary of a patient-doctor conversation. The initial output could be processed by the Researcher agent to identify any inaccuracies or omissions, and the Decider agent could then refine the summary based on this feedback, resulting in a more accurate and complete summary."}, "category": "PROMPTING", "novelty_analysis": "The introduction of the DERA framework represents a significant advancement in the field of LLMs. The dialog-based approach for iterative refinement of LLM outputs is a novel concept, and the use of distinct agent roles for information processing and decision-making is a unique feature of DERA. The application of this framework in clinically-focused tasks and its demonstrated effectiveness in improving LLM performance adds to its novelty.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, discussing the workings of the DERA framework and its application in various tasks. It delves into the roles of the Researcher and Decider agents, the dialog process, and the evaluation of DERA's performance. However, the concepts are explained clearly, making it accessible to readers with a basic understanding of LLMs.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting approach to improving LLM outputs. The use of real-world, clinically-focused tasks to demonstrate DERA's effectiveness adds practical relevance to the paper, making it an engaging read for those interested in the application of LLMs in critical domains.", "enjoyable_score": 2}