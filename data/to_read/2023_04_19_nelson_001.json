{"Published": "2023-04-19", "Title": "Evaluating Verifiability in Generative Search Engines", "Authors": "Nelson F. Liu, Tianyi Zhang, Percy Liang", "Summary": "Generative search engines directly generate responses to user queries, along with in-line citations. A prerequisite trait of a trustworthy generative search engine is verifiability, i.e., systems should cite comprehensively (high citation recall; all statements are fully supported by citations) and accurately (high citation precision; every cite supports its associated statement). We conduct human evaluation to audit four popular generative search engines -- Bing Chat, NeevaAI, perplexity.ai, and YouChat -- across a diverse set of queries from a variety of sources (e.g., historical Google user queries, dynamically-collected open-ended questions on Reddit, etc.). We find that responses from existing generative search engines are fluent and appear informative, but frequently contain unsupported statements and inaccurate citations: on average, a mere 51.5% of generated sentences are fully supported by citations and only 74.5% of citations support their associated sentence. We believe that these results are concerningly low for systems that may serve as a primary tool for information-seeking users, especially given their facade of trustworthiness. We hope that our results further motivate the development of trustworthy generative search engines and help researchers and users better understand the shortcomings of existing commercial systems.", "main_contribution": {"headline": "Evaluating Verifiability in Generative Search Engines", "description": "This paper presents a comprehensive evaluation of the verifiability of four popular generative search engines: Bing Chat, NeevaAI, perplexity.ai, and YouChat. The authors define verifiability as the ability of a system to cite comprehensively and accurately, and they measure this through citation recall and citation precision. The study reveals that while these search engines generate fluent and seemingly informative responses, they often contain unsupported statements and inaccurate citations. On average, only 51.5% of generated sentences are fully supported by citations, and only 74.5% of citations support their associated sentence. This work highlights the need for further development of trustworthy generative search engines."}, "takeaways": {"headline": "Generative Search Engines Need Improvement in Verifiability", "description": "The findings of this study underscore the need for improving the verifiability of generative search engines. While these systems can generate fluent and seemingly informative responses, they often contain unsupported statements and inaccurate citations. This could potentially mislead users, especially those who rely on these systems as their primary tool for seeking information. The authors propose the use of citation recall and citation precision as evaluation metrics to encourage the development of systems that cite comprehensively and correctly.", "example": "For instance, if a generative search engine is used to answer a query about the latest discoveries from the James Webb Space Telescope, it should be able to generate a response that is not only fluent and informative but also fully supported by accurate citations. This would involve ensuring that each statement made in the response is backed by a citation and that each citation supports its associated statement."}, "category": "BEHAVIOR", "novelty_analysis": "The paper introduces a novel approach to evaluating the verifiability of generative search engines. While previous studies have focused on the fluency and perceived utility of these systems, this work emphasizes the importance of citation recall and citation precision. The findings reveal a significant gap in the verifiability of existing systems, highlighting an area that requires further research and development.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it involves the evaluation of generative search engines based on citation recall and citation precision. However, the authors explain these concepts clearly and provide detailed examples, making the paper accessible to readers with a basic understanding of large language models and search engines.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting evaluation of generative search engines. The findings are clearly presented and the implications are discussed in a way that is engaging and thought-provoking. The use of real-world examples also adds to the readability of the paper.", "enjoyable_score": 2}