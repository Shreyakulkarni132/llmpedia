{"id": "http://arxiv.org/abs/2308.06259v2", "guidislink": true, "link": "http://arxiv.org/abs/2308.06259v2", "updated": "2023-08-14T16:44:01Z", "updated_parsed": [2023, 8, 14, 16, 44, 1, 0, 226, 0], "published": "2023-08-11T17:47:54Z", "published_parsed": [2023, 8, 11, 17, 47, 54, 4, 223, 0], "title": "Self-Alignment with Instruction Backtranslation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=self+alignment+with+instruction+backtranslation&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Self-Alignment with Instruction Backtranslation"}, "summary": "We present a scalable method to build a high quality instruction following\nlanguage model by automatically labelling human-written text with corresponding\ninstructions. Our approach, named instruction backtranslation, starts with a\nlanguage model finetuned on a small amount of seed data, and a given web\ncorpus. The seed model is used to construct training examples by generating\ninstruction prompts for web documents (self-augmentation), and then selecting\nhigh quality examples from among these candidates (self-curation). This data is\nthen used to finetune a stronger model. Finetuning LLaMa on two iterations of\nour approach yields a model that outperforms all other LLaMa-based models on\nthe Alpaca leaderboard not relying on distillation data, demonstrating highly\neffective self-alignment.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=self+alignment+with+instruction+backtranslation&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "We present a scalable method to build a high quality instruction following\nlanguage model by automatically labelling human-written text with corresponding\ninstructions. Our approach, named instruction backtranslation, starts with a\nlanguage model finetuned on a small amount of seed data, and a given web\ncorpus. The seed model is used to construct training examples by generating\ninstruction prompts for web documents (self-augmentation), and then selecting\nhigh quality examples from among these candidates (self-curation). This data is\nthen used to finetune a stronger model. Finetuning LLaMa on two iterations of\nour approach yields a model that outperforms all other LLaMa-based models on\nthe Alpaca leaderboard not relying on distillation data, demonstrating highly\neffective self-alignment."}, "authors": [{"name": "Xian Li"}, {"name": "Ping Yu"}, {"name": "Chunting Zhou"}, {"name": "Timo Schick"}, {"name": "Luke Zettlemoyer"}, {"name": "Omer Levy"}, {"name": "Jason Weston"}, {"name": "Mike Lewis"}], "author_detail": {"name": "Mike Lewis"}, "author": "Mike Lewis", "links": [{"href": "http://arxiv.org/abs/2308.06259v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2308.06259v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}