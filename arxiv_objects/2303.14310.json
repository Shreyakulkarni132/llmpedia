{"id": "http://arxiv.org/abs/2303.14310v1", "guidislink": true, "link": "http://arxiv.org/abs/2303.14310v1", "updated": "2023-03-25T00:43:41Z", "updated_parsed": [2023, 3, 25, 0, 43, 41, 5, 84, 0], "published": "2023-03-25T00:43:41Z", "published_parsed": [2023, 3, 25, 0, 43, 41, 5, 84, 0], "title": "GPT is becoming a Turing machine: Here are some ways to program it", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=gpt+is+becoming+a+turing+machine++here+are+some+ways+to+program+it&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "GPT is becoming a Turing machine: Here are some ways to program it"}, "summary": "We demonstrate that, through appropriate prompting, GPT-3 family of models\ncan be triggered to perform iterative behaviours necessary to execute (rather\nthan just write or recall) programs that involve loops, including several\npopular algorithms found in computer science curricula or software developer\ninterviews. We trigger execution and description of Iterations by Regimenting\nSelf-Attention (IRSA) in one (or a combination) of three ways: 1) Using strong\nrepetitive structure in an example of an execution path of a target program for\none particular input, 2) Prompting with fragments of execution paths, and 3)\nExplicitly forbidding (skipping) self-attention to parts of the generated text.\nOn a dynamic program execution, IRSA leads to larger accuracy gains than\nreplacing the model with the much more powerful GPT-4. IRSA has promising\napplications in education, as the prompts and responses resemble student\nassignments in data structures and algorithms classes. Our findings hold\nimplications for evaluating LLMs, which typically target the in-context\nlearning: We show that prompts that may not even cover one full task example\ncan trigger algorithmic behaviour, allowing solving problems previously thought\nof as hard for LLMs, such as logical puzzles. Consequently, prompt design plays\nan even more critical role in LLM performance than previously recognized.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=gpt+is+becoming+a+turing+machine++here+are+some+ways+to+program+it&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "We demonstrate that, through appropriate prompting, GPT-3 family of models\ncan be triggered to perform iterative behaviours necessary to execute (rather\nthan just write or recall) programs that involve loops, including several\npopular algorithms found in computer science curricula or software developer\ninterviews. We trigger execution and description of Iterations by Regimenting\nSelf-Attention (IRSA) in one (or a combination) of three ways: 1) Using strong\nrepetitive structure in an example of an execution path of a target program for\none particular input, 2) Prompting with fragments of execution paths, and 3)\nExplicitly forbidding (skipping) self-attention to parts of the generated text.\nOn a dynamic program execution, IRSA leads to larger accuracy gains than\nreplacing the model with the much more powerful GPT-4. IRSA has promising\napplications in education, as the prompts and responses resemble student\nassignments in data structures and algorithms classes. Our findings hold\nimplications for evaluating LLMs, which typically target the in-context\nlearning: We show that prompts that may not even cover one full task example\ncan trigger algorithmic behaviour, allowing solving problems previously thought\nof as hard for LLMs, such as logical puzzles. Consequently, prompt design plays\nan even more critical role in LLM performance than previously recognized."}, "authors": [{"name": "Ana Jojic"}, {"name": "Zhen Wang"}, {"name": "Nebojsa Jojic"}], "author_detail": {"name": "Nebojsa Jojic"}, "author": "Nebojsa Jojic", "arxiv_comment": "25 pages, 1 figure", "links": [{"href": "http://arxiv.org/abs/2303.14310v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2303.14310v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}