{"id": "http://arxiv.org/abs/2307.10169v1", "guidislink": true, "link": "http://arxiv.org/abs/2307.10169v1", "updated": "2023-07-19T17:55:13Z", "updated_parsed": [2023, 7, 19, 17, 55, 13, 2, 200, 0], "published": "2023-07-19T17:55:13Z", "published_parsed": [2023, 7, 19, 17, 55, 13, 2, 200, 0], "title": "Challenges and Applications of Large Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=challenges+and+applications+of+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Challenges and Applications of Large Language Models"}, "summary": "Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=challenges+and+applications+of+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive."}, "authors": [{"name": "Jean Kaddour"}, {"name": "Joshua Harris"}, {"name": "Maximilian Mozes"}, {"name": "Herbie Bradley"}, {"name": "Roberta Raileanu"}, {"name": "Robert McHardy"}], "author_detail": {"name": "Robert McHardy"}, "author": "Robert McHardy", "arxiv_comment": "72 pages. v01. Work in progress. Feedback and comments are highly\n  appreciated!", "links": [{"href": "http://arxiv.org/abs/2307.10169v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2307.10169v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}