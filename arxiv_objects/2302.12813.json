{"id": "http://arxiv.org/abs/2302.12813v3", "guidislink": true, "link": "http://arxiv.org/abs/2302.12813v3", "updated": "2023-03-08T23:41:49Z", "updated_parsed": [2023, 3, 8, 23, 41, 49, 2, 67, 0], "published": "2023-02-24T18:48:43Z", "published_parsed": [2023, 2, 24, 18, 48, 43, 4, 55, 0], "title": "Check Your Facts and Try Again: Improving Large Language Models with\n  External Knowledge and Automated Feedback", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=check+your+facts+and+try+again++improving+large+language+models+with+external+knowledge+and+automated+feedback&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Check Your Facts and Try Again: Improving Large Language Models with\n  External Knowledge and Automated Feedback"}, "summary": "Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and their inability to use external knowledge. This\npaper proposes a LLM-Augmenter system, which augments a black-box LLM with a\nset of plug-and-play modules. Our system makes the LLM generate responses\ngrounded in external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of scenarios, task-oriented dialog and open-domain question answering.\nLLM-Augmenter significantly reduces ChatGPT's hallucinations without\nsacrificing the fluency and informativeness of its responses. We make the\nsource code and models publicly available.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=check+your+facts+and+try+again++improving+large+language+models+with+external+knowledge+and+automated+feedback&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and their inability to use external knowledge. This\npaper proposes a LLM-Augmenter system, which augments a black-box LLM with a\nset of plug-and-play modules. Our system makes the LLM generate responses\ngrounded in external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of scenarios, task-oriented dialog and open-domain question answering.\nLLM-Augmenter significantly reduces ChatGPT's hallucinations without\nsacrificing the fluency and informativeness of its responses. We make the\nsource code and models publicly available."}, "authors": [{"name": "Baolin Peng"}, {"name": "Michel Galley"}, {"name": "Pengcheng He"}, {"name": "Hao Cheng"}, {"name": "Yujia Xie"}, {"name": "Yu Hu"}, {"name": "Qiuyuan Huang"}, {"name": "Lars Liden"}, {"name": "Zhou Yu"}, {"name": "Weizhu Chen"}, {"name": "Jianfeng Gao"}], "author_detail": {"name": "Jianfeng Gao"}, "author": "Jianfeng Gao", "arxiv_comment": "15 pages", "links": [{"href": "http://arxiv.org/abs/2302.12813v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2302.12813v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}