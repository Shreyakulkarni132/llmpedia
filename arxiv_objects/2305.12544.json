{"id": "http://arxiv.org/abs/2305.12544v1", "guidislink": true, "link": "http://arxiv.org/abs/2305.12544v1", "updated": "2023-05-21T19:06:30Z", "updated_parsed": [2023, 5, 21, 19, 6, 30, 6, 141, 0], "published": "2023-05-21T19:06:30Z", "published_parsed": [2023, 5, 21, 19, 6, 30, 6, 141, 0], "title": "A PhD Student's Perspective on Research in NLP in the Era of Very Large\n  Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=a+phd+student+s+perspective+on+research+in+nlp+in+the+era+of+very+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "A PhD Student's Perspective on Research in NLP in the Era of Very Large\n  Language Models"}, "summary": "Recent progress in large language models has enabled the deployment of many\ngenerative NLP applications. At the same time, it has also led to a misleading\npublic discourse that ``it's all been solved.'' Not surprisingly, this has in\nturn made many NLP researchers -- especially those at the beginning of their\ncareer -- wonder about what NLP research area they should focus on. This\ndocument is a compilation of NLP research directions that are rich for\nexploration, reflecting the views of a diverse group of PhD students in an\nacademic research lab. While we identify many research areas, many others\nexist; we do not cover those areas that are currently addressed by LLMs but\nwhere LLMs lag behind in performance, or those focused on LLM development. We\nwelcome suggestions for other research directions to include:\nhttps://bit.ly/nlp-era-llm", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=a+phd+student+s+perspective+on+research+in+nlp+in+the+era+of+very+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Recent progress in large language models has enabled the deployment of many\ngenerative NLP applications. At the same time, it has also led to a misleading\npublic discourse that ``it's all been solved.'' Not surprisingly, this has in\nturn made many NLP researchers -- especially those at the beginning of their\ncareer -- wonder about what NLP research area they should focus on. This\ndocument is a compilation of NLP research directions that are rich for\nexploration, reflecting the views of a diverse group of PhD students in an\nacademic research lab. While we identify many research areas, many others\nexist; we do not cover those areas that are currently addressed by LLMs but\nwhere LLMs lag behind in performance, or those focused on LLM development. We\nwelcome suggestions for other research directions to include:\nhttps://bit.ly/nlp-era-llm"}, "authors": [{"name": "Oana Ignat"}, {"name": "Zhijing Jin"}, {"name": "Artem Abzaliev"}, {"name": "Laura Biester"}, {"name": "Santiago Castro"}, {"name": "Naihao Deng"}, {"name": "Xinyi Gao"}, {"name": "Aylin Gunal"}, {"name": "Jacky He"}, {"name": "Ashkan Kazemi"}, {"name": "Muhammad Khalifa"}, {"name": "Namho Koh"}, {"name": "Andrew Lee"}, {"name": "Siyang Liu"}, {"name": "Do June Min"}, {"name": "Shinka Mori"}, {"name": "Joan Nwatu"}, {"name": "Veronica Perez-Rosas"}, {"name": "Siqi Shen"}, {"name": "Zekun Wang"}, {"name": "Winston Wu"}, {"name": "Rada Mihalcea"}], "author_detail": {"name": "Rada Mihalcea"}, "author": "Rada Mihalcea", "links": [{"href": "http://arxiv.org/abs/2305.12544v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2305.12544v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}