{"id": "http://arxiv.org/abs/2306.07906v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.07906v1", "updated": "2023-06-13T16:57:53Z", "updated_parsed": [2023, 6, 13, 16, 57, 53, 1, 164, 0], "published": "2023-06-13T16:57:53Z", "published_parsed": [2023, 6, 13, 16, 57, 53, 1, 164, 0], "title": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with\n  Human Preferences", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=webglm++towards+an+efficient+web+enhanced+question+answering+system+with+human+preferences&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with\n  Human Preferences"}, "summary": "We present WebGLM, a web-enhanced question-answering system based on the\nGeneral Language Model (GLM). Its goal is to augment a pre-trained large\nlanguage model (LLM) with web search and retrieval capabilities while being\nefficient for real-world deployments. To achieve this, we develop WebGLM with\nstrategies for the LLM-augmented retriever, bootstrapped generator, and human\npreference-aware scorer. Specifically, we identify and address the limitations\nof WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,\nand cost-effectiveness advantages. In addition, we propose systematic criteria\nfor evaluating web-enhanced QA systems. We conduct multi-dimensional human\nevaluation and quantitative ablation studies, which suggest the outperformance\nof the proposed WebGLM designs over existing systems. WebGLM with the\n10-billion-parameter GLM (10B) is shown to perform better than the\nsimilar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human\nevaluation. The code, demo, and data are at\n\\url{https://github.com/THUDM/WebGLM}.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=webglm++towards+an+efficient+web+enhanced+question+answering+system+with+human+preferences&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "We present WebGLM, a web-enhanced question-answering system based on the\nGeneral Language Model (GLM). Its goal is to augment a pre-trained large\nlanguage model (LLM) with web search and retrieval capabilities while being\nefficient for real-world deployments. To achieve this, we develop WebGLM with\nstrategies for the LLM-augmented retriever, bootstrapped generator, and human\npreference-aware scorer. Specifically, we identify and address the limitations\nof WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,\nand cost-effectiveness advantages. In addition, we propose systematic criteria\nfor evaluating web-enhanced QA systems. We conduct multi-dimensional human\nevaluation and quantitative ablation studies, which suggest the outperformance\nof the proposed WebGLM designs over existing systems. WebGLM with the\n10-billion-parameter GLM (10B) is shown to perform better than the\nsimilar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human\nevaluation. The code, demo, and data are at\n\\url{https://github.com/THUDM/WebGLM}."}, "authors": [{"name": "Xiao Liu"}, {"name": "Hanyu Lai"}, {"name": "Hao Yu"}, {"name": "Yifan Xu"}, {"name": "Aohan Zeng"}, {"name": "Zhengxiao Du"}, {"name": "Peng Zhang"}, {"name": "Yuxiao Dong"}, {"name": "Jie Tang"}], "author_detail": {"name": "Jie Tang"}, "author": "Jie Tang", "arxiv_comment": "Accepted to KDD 2023", "links": [{"href": "http://arxiv.org/abs/2306.07906v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.07906v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}