{"id": "http://arxiv.org/abs/2306.15448v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.15448v1", "updated": "2023-06-21T16:42:15Z", "updated_parsed": [2023, 6, 21, 16, 42, 15, 2, 172, 0], "published": "2023-06-21T16:42:15Z", "published_parsed": [2023, 6, 21, 16, 42, 15, 2, 172, 0], "title": "Understanding Social Reasoning in Language Models with Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=understanding+social+reasoning+in+language+models+with+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Understanding Social Reasoning in Language Models with Language Models"}, "summary": "As Large Language Models (LLMs) become increasingly integrated into our\neveryday lives, understanding their ability to comprehend human mental states\nbecomes critical for ensuring effective interactions. However, despite the\nrecent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of\nLLMs, the degree to which these models can align with human ToM remains a\nnuanced topic of exploration. This is primarily due to two distinct challenges:\n(1) the presence of inconsistent results from previous evaluations, and (2)\nconcerns surrounding the validity of existing evaluation methodologies. To\naddress these challenges, we present a novel framework for procedurally\ngenerating evaluations with LLMs by populating causal templates. Using our\nframework, we create a new social reasoning benchmark (BigToM) for LLMs which\nconsists of 25 controls and 5,000 model-written evaluations. We find that human\nparticipants rate the quality of our benchmark higher than previous\ncrowd-sourced evaluations and comparable to expert-written evaluations. Using\nBigToM, we evaluate the social reasoning capabilities of a variety of LLMs and\ncompare model performances with human performance. Our results suggest that\nGPT4 has ToM capabilities that mirror human inference patterns, though less\nreliable, while other LLMs struggle.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=understanding+social+reasoning+in+language+models+with+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "As Large Language Models (LLMs) become increasingly integrated into our\neveryday lives, understanding their ability to comprehend human mental states\nbecomes critical for ensuring effective interactions. However, despite the\nrecent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of\nLLMs, the degree to which these models can align with human ToM remains a\nnuanced topic of exploration. This is primarily due to two distinct challenges:\n(1) the presence of inconsistent results from previous evaluations, and (2)\nconcerns surrounding the validity of existing evaluation methodologies. To\naddress these challenges, we present a novel framework for procedurally\ngenerating evaluations with LLMs by populating causal templates. Using our\nframework, we create a new social reasoning benchmark (BigToM) for LLMs which\nconsists of 25 controls and 5,000 model-written evaluations. We find that human\nparticipants rate the quality of our benchmark higher than previous\ncrowd-sourced evaluations and comparable to expert-written evaluations. Using\nBigToM, we evaluate the social reasoning capabilities of a variety of LLMs and\ncompare model performances with human performance. Our results suggest that\nGPT4 has ToM capabilities that mirror human inference patterns, though less\nreliable, while other LLMs struggle."}, "authors": [{"name": "Kanishk Gandhi"}, {"name": "Jan-Philipp Fr\u00e4nken"}, {"name": "Tobias Gerstenberg"}, {"name": "Noah D. Goodman"}], "author_detail": {"name": "Noah D. Goodman"}, "author": "Noah D. Goodman", "links": [{"href": "http://arxiv.org/abs/2306.15448v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.15448v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}