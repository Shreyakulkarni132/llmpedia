{"id": "http://arxiv.org/abs/2307.13854v1", "guidislink": true, "link": "http://arxiv.org/abs/2307.13854v1", "updated": "2023-07-25T22:59:32Z", "updated_parsed": [2023, 7, 25, 22, 59, 32, 1, 206, 0], "published": "2023-07-25T22:59:32Z", "published_parsed": [2023, 7, 25, 22, 59, 32, 1, 206, 0], "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=webarena++a+realistic+web+environment+for+building+autonomous+agents&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "WebArena: A Realistic Web Environment for Building Autonomous Agents"}, "summary": "With generative AI advances, the exciting potential for autonomous agents to\nmanage daily tasks via natural language commands has emerged. However, cur rent\nagents are primarily created and tested in simplified synthetic environments,\nsubstantially limiting real-world scenario representation. In this paper, we\nbuild an environment for agent command and control that is highly realistic and\nreproducible. Specifically, we focus on agents that perform tasks on websites,\nand we create an environment with fully functional websites from four common\ndomains: e-commerce, social forum discussions, collaborative software\ndevelopment, and content management. Our environment is enriched with tools\n(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage\nhuman-like task-solving. Building upon our environment, we release a set of\nbenchmark tasks focusing on evaluating the functional correctness of task\ncompletions. The tasks in our benchmark are diverse, long-horizon, and are\ndesigned to emulate tasks that humans routinely perform on the internet. We\ndesign and implement several autonomous agents, integrating recent techniques\nsuch as reasoning before acting. The results demonstrate that solving complex\ntasks is challenging: our best GPT-4-based agent only achieves an end-to-end\ntask success rate of 10.59%. These results highlight the need for further\ndevelopment of robust agents, that current state-of-the-art LMs are far from\nperfect performance in these real-life tasks, and that WebArena can be used to\nmeasure such progress. Our code, data, environment reproduction resources, and\nvideo demonstrations are publicly available at https://webarena.dev/.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=webarena++a+realistic+web+environment+for+building+autonomous+agents&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "With generative AI advances, the exciting potential for autonomous agents to\nmanage daily tasks via natural language commands has emerged. However, cur rent\nagents are primarily created and tested in simplified synthetic environments,\nsubstantially limiting real-world scenario representation. In this paper, we\nbuild an environment for agent command and control that is highly realistic and\nreproducible. Specifically, we focus on agents that perform tasks on websites,\nand we create an environment with fully functional websites from four common\ndomains: e-commerce, social forum discussions, collaborative software\ndevelopment, and content management. Our environment is enriched with tools\n(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage\nhuman-like task-solving. Building upon our environment, we release a set of\nbenchmark tasks focusing on evaluating the functional correctness of task\ncompletions. The tasks in our benchmark are diverse, long-horizon, and are\ndesigned to emulate tasks that humans routinely perform on the internet. We\ndesign and implement several autonomous agents, integrating recent techniques\nsuch as reasoning before acting. The results demonstrate that solving complex\ntasks is challenging: our best GPT-4-based agent only achieves an end-to-end\ntask success rate of 10.59%. These results highlight the need for further\ndevelopment of robust agents, that current state-of-the-art LMs are far from\nperfect performance in these real-life tasks, and that WebArena can be used to\nmeasure such progress. Our code, data, environment reproduction resources, and\nvideo demonstrations are publicly available at https://webarena.dev/."}, "authors": [{"name": "Shuyan Zhou"}, {"name": "Frank F. Xu"}, {"name": "Hao Zhu"}, {"name": "Xuhui Zhou"}, {"name": "Robert Lo"}, {"name": "Abishek Sridhar"}, {"name": "Xianyi Cheng"}, {"name": "Yonatan Bisk"}, {"name": "Daniel Fried"}, {"name": "Uri Alon"}, {"name": "Graham Neubig"}], "author_detail": {"name": "Graham Neubig"}, "author": "Graham Neubig", "arxiv_comment": "Work in progress", "links": [{"href": "http://arxiv.org/abs/2307.13854v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2307.13854v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}