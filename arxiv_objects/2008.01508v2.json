{"id": "http://arxiv.org/abs/2008.01508v2", "guidislink": true, "link": "http://arxiv.org/abs/2008.01508v2", "updated": "2020-12-24T13:24:37Z", "updated_parsed": [2020, 12, 24, 13, 24, 37, 3, 359, 0], "published": "2020-08-04T13:21:19Z", "published_parsed": [2020, 8, 4, 13, 21, 19, 1, 217, 0], "title": "Explanation of Reinforcement Learning Model in Dynamic Multi-Agent\n  System", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=explanation+of+reinforcement+learning+model+in+dynamic+multi+agent+system&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Explanation of Reinforcement Learning Model in Dynamic Multi-Agent\n  System"}, "summary": "Recently, there has been increasing interest in transparency and\ninterpretability in Deep Reinforcement Learning (DRL) systems. Verbal\nexplanations, as the most natural way of communication in our daily life,\ndeserve more attention, since they allow users to gain a better understanding\nof the system which ultimately could lead to a high level of trust and smooth\ncollaboration. This paper reports a novel work in generating verbal\nexplanations for DRL behaviors agent. A rule-based model is designed to\nconstruct explanations using a series of rules which are predefined with prior\nknowledge. A learning model is then proposed to expand the implicit logic of\ngenerating verbal explanation to general situations by employing rule-based\nexplanations as training data. The learning model is shown to have better\nflexibility and generalizability than the static rule-based model. The\nperformance of both models is evaluated quantitatively through objective\nmetrics. The results show that verbal explanation generated by both models\nimprove subjective satisfaction of users towards the interpretability of DRL\nsystems. Additionally, seven variants of the learning model are designed to\nillustrate the contribution of input channels, attention mechanism, and\nproposed encoder in improving the quality of verbal explanation.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=explanation+of+reinforcement+learning+model+in+dynamic+multi+agent+system&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Recently, there has been increasing interest in transparency and\ninterpretability in Deep Reinforcement Learning (DRL) systems. Verbal\nexplanations, as the most natural way of communication in our daily life,\ndeserve more attention, since they allow users to gain a better understanding\nof the system which ultimately could lead to a high level of trust and smooth\ncollaboration. This paper reports a novel work in generating verbal\nexplanations for DRL behaviors agent. A rule-based model is designed to\nconstruct explanations using a series of rules which are predefined with prior\nknowledge. A learning model is then proposed to expand the implicit logic of\ngenerating verbal explanation to general situations by employing rule-based\nexplanations as training data. The learning model is shown to have better\nflexibility and generalizability than the static rule-based model. The\nperformance of both models is evaluated quantitatively through objective\nmetrics. The results show that verbal explanation generated by both models\nimprove subjective satisfaction of users towards the interpretability of DRL\nsystems. Additionally, seven variants of the learning model are designed to\nillustrate the contribution of input channels, attention mechanism, and\nproposed encoder in improving the quality of verbal explanation."}, "authors": [{"name": "Xinzhi Wang"}, {"name": "Huao Li"}, {"name": "Hui Zhang"}, {"name": "Michael Lewis"}, {"name": "Katia Sycara"}], "author_detail": {"name": "Katia Sycara"}, "author": "Katia Sycara", "links": [{"href": "http://arxiv.org/abs/2008.01508v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2008.01508v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}