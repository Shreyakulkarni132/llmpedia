{"id": "http://arxiv.org/abs/2212.10403v2", "guidislink": true, "link": "http://arxiv.org/abs/2212.10403v2", "updated": "2023-05-26T17:59:33Z", "updated_parsed": [2023, 5, 26, 17, 59, 33, 4, 146, 0], "published": "2022-12-20T16:29:03Z", "published_parsed": [2022, 12, 20, 16, 29, 3, 1, 354, 0], "title": "Towards Reasoning in Large Language Models: A Survey", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=towards+reasoning+in+large+language+models++a+survey&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Towards Reasoning in Large Language Models: A Survey"}, "summary": "Reasoning is a fundamental aspect of human intelligence that plays a crucial\nrole in activities such as problem solving, decision making, and critical\nthinking. In recent years, large language models (LLMs) have made significant\nprogress in natural language processing, and there is observation that these\nmodels may exhibit reasoning abilities when they are sufficiently large.\nHowever, it is not yet clear to what extent LLMs are capable of reasoning. This\npaper provides a comprehensive overview of the current state of knowledge on\nreasoning in LLMs, including techniques for improving and eliciting reasoning\nin these models, methods and benchmarks for evaluating reasoning abilities,\nfindings and implications of previous research in this field, and suggestions\non future directions. Our aim is to provide a detailed and up-to-date review of\nthis topic and stimulate meaningful discussion and future work.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=towards+reasoning+in+large+language+models++a+survey&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Reasoning is a fundamental aspect of human intelligence that plays a crucial\nrole in activities such as problem solving, decision making, and critical\nthinking. In recent years, large language models (LLMs) have made significant\nprogress in natural language processing, and there is observation that these\nmodels may exhibit reasoning abilities when they are sufficiently large.\nHowever, it is not yet clear to what extent LLMs are capable of reasoning. This\npaper provides a comprehensive overview of the current state of knowledge on\nreasoning in LLMs, including techniques for improving and eliciting reasoning\nin these models, methods and benchmarks for evaluating reasoning abilities,\nfindings and implications of previous research in this field, and suggestions\non future directions. Our aim is to provide a detailed and up-to-date review of\nthis topic and stimulate meaningful discussion and future work."}, "authors": [{"name": "Jie Huang"}, {"name": "Kevin Chen-Chuan Chang"}], "author_detail": {"name": "Kevin Chen-Chuan Chang"}, "author": "Kevin Chen-Chuan Chang", "arxiv_comment": "ACL 2023 Findings, 15 pages", "links": [{"href": "http://arxiv.org/abs/2212.10403v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2212.10403v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}