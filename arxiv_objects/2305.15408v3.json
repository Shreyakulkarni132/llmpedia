{"id": "http://arxiv.org/abs/2305.15408v3", "guidislink": true, "link": "http://arxiv.org/abs/2305.15408v3", "updated": "2023-06-28T13:44:19Z", "updated_parsed": [2023, 6, 28, 13, 44, 19, 2, 179, 0], "published": "2023-05-24T17:59:21Z", "published_parsed": [2023, 5, 24, 17, 59, 21, 2, 144, 0], "title": "Towards Revealing the Mystery behind Chain of Thought: A Theoretical\n  Perspective", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=towards+revealing+the+mystery+behind+chain+of+thought++a+theoretical+perspective&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Towards Revealing the Mystery behind Chain of Thought: A Theoretical\n  Perspective"}, "summary": "Recent studies have discovered that Chain-of-Thought prompting (CoT) can\ndramatically improve the performance of Large Language Models (LLMs),\nparticularly when dealing with complex tasks involving mathematics or\nreasoning. Despite the enormous empirical success, the underlying mechanisms\nbehind CoT and how it unlocks the potential of LLMs remain elusive. In this\npaper, we take a first step towards theoretically answering these questions.\nSpecifically, we examine the expressivity of LLMs with CoT in solving\nfundamental mathematical and decision-making problems. We start by giving an\nimpossibility result showing that bounded-depth Transformers are unable to\ndirectly produce correct answers for basic arithmetic/equation tasks unless the\nmodel size grows super-polynomially with respect to the input length. In\ncontrast, we then prove by construction that autoregressive Transformers of\nconstant size suffice to solve both tasks by generating CoT derivations using a\ncommonly-used math language format. Moreover, we show LLMs with CoT are capable\nof solving a general class of decision-making problems known as Dynamic\nProgramming, thus justifying its power in tackling complex real-world tasks.\nFinally, extensive experiments on four tasks show that, while Transformers\nalways fail to predict the answers directly, they can consistently learn to\ngenerate correct solutions step-by-step given sufficient CoT demonstrations.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=towards+revealing+the+mystery+behind+chain+of+thought++a+theoretical+perspective&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Recent studies have discovered that Chain-of-Thought prompting (CoT) can\ndramatically improve the performance of Large Language Models (LLMs),\nparticularly when dealing with complex tasks involving mathematics or\nreasoning. Despite the enormous empirical success, the underlying mechanisms\nbehind CoT and how it unlocks the potential of LLMs remain elusive. In this\npaper, we take a first step towards theoretically answering these questions.\nSpecifically, we examine the expressivity of LLMs with CoT in solving\nfundamental mathematical and decision-making problems. We start by giving an\nimpossibility result showing that bounded-depth Transformers are unable to\ndirectly produce correct answers for basic arithmetic/equation tasks unless the\nmodel size grows super-polynomially with respect to the input length. In\ncontrast, we then prove by construction that autoregressive Transformers of\nconstant size suffice to solve both tasks by generating CoT derivations using a\ncommonly-used math language format. Moreover, we show LLMs with CoT are capable\nof solving a general class of decision-making problems known as Dynamic\nProgramming, thus justifying its power in tackling complex real-world tasks.\nFinally, extensive experiments on four tasks show that, while Transformers\nalways fail to predict the answers directly, they can consistently learn to\ngenerate correct solutions step-by-step given sufficient CoT demonstrations."}, "authors": [{"name": "Guhao Feng"}, {"name": "Bohang Zhang"}, {"name": "Yuntian Gu"}, {"name": "Haotian Ye"}, {"name": "Di He"}, {"name": "Liwei Wang"}], "author_detail": {"name": "Liwei Wang"}, "author": "Liwei Wang", "arxiv_comment": "38 pages; This version (V3) polishes the proofs for better\n  readability", "links": [{"href": "http://arxiv.org/abs/2305.15408v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2305.15408v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.ML", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}