{"id": "http://arxiv.org/abs/2307.08922v1", "guidislink": true, "link": "http://arxiv.org/abs/2307.08922v1", "updated": "2023-07-18T01:43:00Z", "updated_parsed": [2023, 7, 18, 1, 43, 0, 1, 199, 0], "published": "2023-07-18T01:43:00Z", "published_parsed": [2023, 7, 18, 1, 43, 0, 1, 199, 0], "title": "Large Language Models Perform Diagnostic Reasoning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+perform+diagnostic+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large Language Models Perform Diagnostic Reasoning"}, "summary": "We explore the extension of chain-of-thought (CoT) prompting to medical\nreasoning for the task of automatic diagnosis. Motivated by doctors' underlying\nreasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical\nresults demonstrate that by simply prompting large language models trained only\non general text corpus with two DR-CoT exemplars, the diagnostic accuracy\nimproves by 15% comparing to standard prompting. Moreover, the gap reaches a\npronounced 18% in out-domain settings. Our findings suggest expert-knowledge\nreasoning in large language models can be elicited through proper promptings.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+perform+diagnostic+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "We explore the extension of chain-of-thought (CoT) prompting to medical\nreasoning for the task of automatic diagnosis. Motivated by doctors' underlying\nreasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical\nresults demonstrate that by simply prompting large language models trained only\non general text corpus with two DR-CoT exemplars, the diagnostic accuracy\nimproves by 15% comparing to standard prompting. Moreover, the gap reaches a\npronounced 18% in out-domain settings. Our findings suggest expert-knowledge\nreasoning in large language models can be elicited through proper promptings."}, "authors": [{"name": "Cheng-Kuang Wu"}, {"name": "Wei-Lin Chen"}, {"name": "Hsin-Hsi Chen"}], "author_detail": {"name": "Hsin-Hsi Chen"}, "author": "Hsin-Hsi Chen", "arxiv_comment": "Accepted as a Tiny Paper at ICLR 2023 (10 pages, 5 figures)", "links": [{"href": "http://arxiv.org/abs/2307.08922v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2307.08922v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}