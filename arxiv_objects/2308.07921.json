{"id": "http://arxiv.org/abs/2308.07921v1", "guidislink": true, "link": "http://arxiv.org/abs/2308.07921v1", "updated": "2023-08-15T17:58:45Z", "updated_parsed": [2023, 8, 15, 17, 58, 45, 1, 227, 0], "published": "2023-08-15T17:58:45Z", "published_parsed": [2023, 8, 15, 17, 58, 45, 1, 227, 0], "title": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with\n  Code-based Self-Verification", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=solving+challenging+math+word+problems+using+gpt+4+code+interpreter+with+code+based+self+verification&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with\n  Code-based Self-Verification"}, "summary": "Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has\nbrought significant advancements in addressing math reasoning problems. In\nparticular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,\nshows remarkable performance on challenging math datasets. In this paper, we\nexplore the effect of code on enhancing LLMs' reasoning capability by\nintroducing different constraints on the \\textit{Code Usage Frequency} of GPT-4\nCode Interpreter. We found that its success can be largely attributed to its\npowerful skills in generating and executing code, evaluating the output of code\nexecution, and rectifying its solution when receiving unreasonable outputs.\nBased on this insight, we propose a novel and effective prompting method,\nexplicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further\nboost the mathematical reasoning potential of GPT-4 Code Interpreter. This\nmethod employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to\nuse code to self-verify its answers. In instances where the verification state\nregisters as ``False'', the model shall automatically amend its solution,\nanalogous to our approach of rectifying errors during a mathematics\nexamination. Furthermore, we recognize that the states of the verification\nresult indicate the confidence of a solution, which can improve the\neffectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we\nachieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$\n84.3\\%)}.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=solving+challenging+math+word+problems+using+gpt+4+code+interpreter+with+code+based+self+verification&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has\nbrought significant advancements in addressing math reasoning problems. In\nparticular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,\nshows remarkable performance on challenging math datasets. In this paper, we\nexplore the effect of code on enhancing LLMs' reasoning capability by\nintroducing different constraints on the \\textit{Code Usage Frequency} of GPT-4\nCode Interpreter. We found that its success can be largely attributed to its\npowerful skills in generating and executing code, evaluating the output of code\nexecution, and rectifying its solution when receiving unreasonable outputs.\nBased on this insight, we propose a novel and effective prompting method,\nexplicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further\nboost the mathematical reasoning potential of GPT-4 Code Interpreter. This\nmethod employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to\nuse code to self-verify its answers. In instances where the verification state\nregisters as ``False'', the model shall automatically amend its solution,\nanalogous to our approach of rectifying errors during a mathematics\nexamination. Furthermore, we recognize that the states of the verification\nresult indicate the confidence of a solution, which can improve the\neffectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we\nachieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$\n84.3\\%)}."}, "authors": [{"name": "Aojun Zhou"}, {"name": "Ke Wang"}, {"name": "Zimu Lu"}, {"name": "Weikang Shi"}, {"name": "Sichun Luo"}, {"name": "Zipeng Qin"}, {"name": "Shaoqing Lu"}, {"name": "Anya Jia"}, {"name": "Linqi Song"}, {"name": "Mingjie Zhan"}, {"name": "Hongsheng Li"}], "author_detail": {"name": "Hongsheng Li"}, "author": "Hongsheng Li", "arxiv_comment": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter\n  with Code-based Self-Verification", "links": [{"href": "http://arxiv.org/abs/2308.07921v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2308.07921v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}