{"id": "http://arxiv.org/abs/2306.12672v2", "guidislink": true, "link": "http://arxiv.org/abs/2306.12672v2", "updated": "2023-06-23T06:05:31Z", "updated_parsed": [2023, 6, 23, 6, 5, 31, 4, 174, 0], "published": "2023-06-22T05:14:00Z", "published_parsed": [2023, 6, 22, 5, 14, 0, 3, 173, 0], "title": "From Word Models to World Models: Translating from Natural Language to\n  the Probabilistic Language of Thought", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=from+word+models+to+world+models++translating+from+natural+language+to+the+probabilistic+language+of+thought&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "From Word Models to World Models: Translating from Natural Language to\n  the Probabilistic Language of Thought"}, "summary": "How does language inform our downstream thinking? In particular, how do\nhumans make meaning from language--and how can we leverage a theory of\nlinguistic meaning to build machines that think in more human-like ways? In\nthis paper, we propose rational meaning construction, a computational framework\nfor language-informed thinking that combines neural language models with\nprobabilistic models for rational inference. We frame linguistic meaning as a\ncontext-sensitive mapping from natural language into a probabilistic language\nof thought (PLoT)--a general-purpose symbolic substrate for generative world\nmodeling. Our architecture integrates two computational tools that have not\npreviously come together: we model thinking with probabilistic programs, an\nexpressive representation for commonsense reasoning; and we model meaning\nconstruction with large language models (LLMs), which support broad-coverage\ntranslation from natural language utterances to code expressions in a\nprobabilistic programming language. We illustrate our framework through\nexamples covering four core domains from cognitive science: probabilistic\nreasoning, logical and relational reasoning, visual and physical reasoning, and\nsocial reasoning. In each, we show that LLMs can generate context-sensitive\ntranslations that capture pragmatically-appropriate linguistic meanings, while\nBayesian inference with the generated programs supports coherent and robust\ncommonsense reasoning. We extend our framework to integrate\ncognitively-motivated symbolic modules (physics simulators, graphics engines,\nand planning algorithms) to provide a unified commonsense thinking interface\nfrom language. Finally, we explore how language can drive the construction of\nworld models themselves. We hope this work will provide a roadmap towards\ncognitive models and AI systems that synthesize the insights of both modern and\nclassical computational perspectives.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=from+word+models+to+world+models++translating+from+natural+language+to+the+probabilistic+language+of+thought&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "How does language inform our downstream thinking? In particular, how do\nhumans make meaning from language--and how can we leverage a theory of\nlinguistic meaning to build machines that think in more human-like ways? In\nthis paper, we propose rational meaning construction, a computational framework\nfor language-informed thinking that combines neural language models with\nprobabilistic models for rational inference. We frame linguistic meaning as a\ncontext-sensitive mapping from natural language into a probabilistic language\nof thought (PLoT)--a general-purpose symbolic substrate for generative world\nmodeling. Our architecture integrates two computational tools that have not\npreviously come together: we model thinking with probabilistic programs, an\nexpressive representation for commonsense reasoning; and we model meaning\nconstruction with large language models (LLMs), which support broad-coverage\ntranslation from natural language utterances to code expressions in a\nprobabilistic programming language. We illustrate our framework through\nexamples covering four core domains from cognitive science: probabilistic\nreasoning, logical and relational reasoning, visual and physical reasoning, and\nsocial reasoning. In each, we show that LLMs can generate context-sensitive\ntranslations that capture pragmatically-appropriate linguistic meanings, while\nBayesian inference with the generated programs supports coherent and robust\ncommonsense reasoning. We extend our framework to integrate\ncognitively-motivated symbolic modules (physics simulators, graphics engines,\nand planning algorithms) to provide a unified commonsense thinking interface\nfrom language. Finally, we explore how language can drive the construction of\nworld models themselves. We hope this work will provide a roadmap towards\ncognitive models and AI systems that synthesize the insights of both modern and\nclassical computational perspectives."}, "authors": [{"name": "Lionel Wong"}, {"name": "Gabriel Grand"}, {"name": "Alexander K. Lew"}, {"name": "Noah D. Goodman"}, {"name": "Vikash K. Mansinghka"}, {"name": "Jacob Andreas"}, {"name": "Joshua B. Tenenbaum"}], "author_detail": {"name": "Joshua B. Tenenbaum"}, "author": "Joshua B. Tenenbaum", "links": [{"href": "http://arxiv.org/abs/2306.12672v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.12672v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.SC", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}