{"id": "http://arxiv.org/abs/2306.05182v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.05182v1", "updated": "2023-05-15T18:38:25Z", "updated_parsed": [2023, 5, 15, 18, 38, 25, 0, 135, 0], "published": "2023-05-15T18:38:25Z", "published_parsed": [2023, 5, 15, 18, 38, 25, 0, 135, 0], "title": "Interactive Fashion Content Generation Using LLMs and Latent Diffusion\n  Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=interactive+fashion+content+generation+using+llms+and+latent+diffusion+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Interactive Fashion Content Generation Using LLMs and Latent Diffusion\n  Models"}, "summary": "Fashionable image generation aims to synthesize images of diverse fashion\nprevalent around the globe, helping fashion designers in real-time\nvisualization by giving them a basic customized structure of how a specific\ndesign preference would look in real life and what further improvements can be\nmade for enhanced customer satisfaction. Moreover, users can alone interact and\ngenerate fashionable images by just giving a few simple prompts. Recently,\ndiffusion models have gained popularity as generative models owing to their\nflexibility and generation of realistic images from Gaussian noise. Latent\ndiffusion models are a type of generative model that use diffusion processes to\nmodel the generation of complex data, such as images, audio, or text. They are\ncalled \"latent\" because they learn a hidden representation, or latent variable,\nof the data that captures its underlying structure. We propose a method\nexploiting the equivalence between diffusion models and energy-based models\n(EBMs) and suggesting ways to compose multiple probability distributions. We\ndescribe a pipeline on how our method can be used specifically for new\nfashionable outfit generation and virtual try-on using LLM-guided text-to-image\ngeneration. Our results indicate that using an LLM to refine the prompts to the\nlatent diffusion model assists in generating globally creative and culturally\ndiversified fashion styles and reducing bias.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=interactive+fashion+content+generation+using+llms+and+latent+diffusion+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Fashionable image generation aims to synthesize images of diverse fashion\nprevalent around the globe, helping fashion designers in real-time\nvisualization by giving them a basic customized structure of how a specific\ndesign preference would look in real life and what further improvements can be\nmade for enhanced customer satisfaction. Moreover, users can alone interact and\ngenerate fashionable images by just giving a few simple prompts. Recently,\ndiffusion models have gained popularity as generative models owing to their\nflexibility and generation of realistic images from Gaussian noise. Latent\ndiffusion models are a type of generative model that use diffusion processes to\nmodel the generation of complex data, such as images, audio, or text. They are\ncalled \"latent\" because they learn a hidden representation, or latent variable,\nof the data that captures its underlying structure. We propose a method\nexploiting the equivalence between diffusion models and energy-based models\n(EBMs) and suggesting ways to compose multiple probability distributions. We\ndescribe a pipeline on how our method can be used specifically for new\nfashionable outfit generation and virtual try-on using LLM-guided text-to-image\ngeneration. Our results indicate that using an LLM to refine the prompts to the\nlatent diffusion model assists in generating globally creative and culturally\ndiversified fashion styles and reducing bias."}, "authors": [{"name": "Krishna Sri Ipsit Mantri"}, {"name": "Nevasini Sasikumar"}], "author_detail": {"name": "Nevasini Sasikumar"}, "author": "Nevasini Sasikumar", "arxiv_comment": "Third Workshop on Ethical Considerations in Creative applications of\n  Computer Vision (EC3V) at CVPR 2023. arXiv admin note: substantial text\n  overlap with arXiv:2301.02110, arXiv:2112.10752 by other authors", "links": [{"href": "http://arxiv.org/abs/2306.05182v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.05182v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}