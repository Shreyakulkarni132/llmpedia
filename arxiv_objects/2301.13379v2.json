{"id": "http://arxiv.org/abs/2301.13379v2", "guidislink": true, "link": "http://arxiv.org/abs/2301.13379v2", "updated": "2023-02-01T19:25:24Z", "updated_parsed": [2023, 2, 1, 19, 25, 24, 2, 32, 0], "published": "2023-01-31T03:04:26Z", "published_parsed": [2023, 1, 31, 3, 4, 26, 1, 31, 0], "title": "Faithful Chain-of-Thought Reasoning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=faithful+chain+of+thought+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Faithful Chain-of-Thought Reasoning"}, "summary": "While Chain-of-Thought (CoT) prompting boosts Language Models' (LM)\nperformance on a gamut of complex reasoning tasks, the generated reasoning\nchain does not necessarily reflect how the model arrives at the answer (aka.\nfaithfulness). We propose Faithful CoT, a faithful-by-construction framework\nthat decomposes a reasoning task into two stages: Translation (Natural Language\nquery $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning\nchain $\\rightarrow$ answer), using an LM and a deterministic solver\nrespectively. We demonstrate the efficacy of our approach on 10 reasoning\ndatasets from 4 diverse domains. It outperforms traditional CoT prompting on 9\nout of the 10 datasets, with an average accuracy gain of 4.4 on Math Word\nProblems, 1.9 on Planning, 4.0 on Multi-hop Question Answering (QA), and 18.1\non Logical Inference, under greedy decoding. Together with self-consistency\ndecoding, we achieve new state-of-the-art few-shot performance on 7 out of the\n10 datasets, showing a strong synergy between faithfulness and accuracy.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=faithful+chain+of+thought+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "While Chain-of-Thought (CoT) prompting boosts Language Models' (LM)\nperformance on a gamut of complex reasoning tasks, the generated reasoning\nchain does not necessarily reflect how the model arrives at the answer (aka.\nfaithfulness). We propose Faithful CoT, a faithful-by-construction framework\nthat decomposes a reasoning task into two stages: Translation (Natural Language\nquery $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning\nchain $\\rightarrow$ answer), using an LM and a deterministic solver\nrespectively. We demonstrate the efficacy of our approach on 10 reasoning\ndatasets from 4 diverse domains. It outperforms traditional CoT prompting on 9\nout of the 10 datasets, with an average accuracy gain of 4.4 on Math Word\nProblems, 1.9 on Planning, 4.0 on Multi-hop Question Answering (QA), and 18.1\non Logical Inference, under greedy decoding. Together with self-consistency\ndecoding, we achieve new state-of-the-art few-shot performance on 7 out of the\n10 datasets, showing a strong synergy between faithfulness and accuracy."}, "authors": [{"name": "Qing Lyu"}, {"name": "Shreya Havaldar"}, {"name": "Adam Stein"}, {"name": "Li Zhang"}, {"name": "Delip Rao"}, {"name": "Eric Wong"}, {"name": "Marianna Apidianaki"}, {"name": "Chris Callison-Burch"}], "author_detail": {"name": "Chris Callison-Burch"}, "author": "Chris Callison-Burch", "links": [{"href": "http://arxiv.org/abs/2301.13379v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2301.13379v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}