{"id": "http://arxiv.org/abs/2102.02503v1", "guidislink": true, "link": "http://arxiv.org/abs/2102.02503v1", "updated": "2021-02-04T09:27:04Z", "updated_parsed": [2021, 2, 4, 9, 27, 4, 3, 35, 0], "published": "2021-02-04T09:27:04Z", "published_parsed": [2021, 2, 4, 9, 27, 4, 3, 35, 0], "title": "Understanding the Capabilities, Limitations, and Societal Impact of\n  Large Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=understanding+the+capabilities++limitations++and+societal+impact+of+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Understanding the Capabilities, Limitations, and Societal Impact of\n  Large Language Models"}, "summary": "On October 14th, 2020, researchers from OpenAI, the Stanford Institute for\nHuman-Centered Artificial Intelligence, and other universities convened to\ndiscuss open research questions surrounding GPT-3, the largest\npublicly-disclosed dense language model at the time. The meeting took place\nunder Chatham House Rules. Discussants came from a variety of research\nbackgrounds including computer science, linguistics, philosophy, political\nscience, communications, cyber policy, and more. Broadly, the discussion\ncentered around two main questions: 1) What are the technical capabilities and\nlimitations of large language models? 2) What are the societal effects of\nwidespread use of large language models? Here, we provide a detailed summary of\nthe discussion organized by the two themes above.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=understanding+the+capabilities++limitations++and+societal+impact+of+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "On October 14th, 2020, researchers from OpenAI, the Stanford Institute for\nHuman-Centered Artificial Intelligence, and other universities convened to\ndiscuss open research questions surrounding GPT-3, the largest\npublicly-disclosed dense language model at the time. The meeting took place\nunder Chatham House Rules. Discussants came from a variety of research\nbackgrounds including computer science, linguistics, philosophy, political\nscience, communications, cyber policy, and more. Broadly, the discussion\ncentered around two main questions: 1) What are the technical capabilities and\nlimitations of large language models? 2) What are the societal effects of\nwidespread use of large language models? Here, we provide a detailed summary of\nthe discussion organized by the two themes above."}, "authors": [{"name": "Alex Tamkin"}, {"name": "Miles Brundage"}, {"name": "Jack Clark"}, {"name": "Deep Ganguli"}], "author_detail": {"name": "Deep Ganguli"}, "author": "Deep Ganguli", "links": [{"href": "http://arxiv.org/abs/2102.02503v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2102.02503v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}