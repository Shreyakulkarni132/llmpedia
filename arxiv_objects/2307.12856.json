{"id": "http://arxiv.org/abs/2307.12856v1", "guidislink": true, "link": "http://arxiv.org/abs/2307.12856v1", "updated": "2023-07-24T14:56:30Z", "updated_parsed": [2023, 7, 24, 14, 56, 30, 0, 205, 0], "published": "2023-07-24T14:56:30Z", "published_parsed": [2023, 7, 24, 14, 56, 30, 0, 205, 0], "title": "A Real-World WebAgent with Planning, Long Context Understanding, and\n  Program Synthesis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=a+real+world+webagent+with+planning++long+context+understanding++and+program+synthesis&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "A Real-World WebAgent with Planning, Long Context Understanding, and\n  Program Synthesis"}, "summary": "Pre-trained large language models (LLMs) have recently achieved better\ngeneralization and sample efficiency in autonomous web navigation. However, the\nperformance on real-world websites has still suffered from (1) open domainness,\n(2) limited context length, and (3) lack of inductive bias on HTML. We\nintroduce WebAgent, an LLM-driven agent that can complete the tasks on real\nwebsites following natural language instructions. WebAgent plans ahead by\ndecomposing instructions into canonical sub-instructions, summarizes long HTML\ndocuments into task-relevant snippets, and acts on websites via generated\nPython programs from those. We design WebAgent with Flan-U-PaLM, for grounded\ncode generation, and HTML-T5, new pre-trained LLMs for long HTML documents\nusing local and global attention mechanisms and a mixture of long-span\ndenoising objectives, for planning and summarization. We empirically\ndemonstrate that our recipe improves the success on a real website by over 50%,\nand that HTML-T5 is the best model to solve HTML-based tasks; achieving 14.9%\nhigher success rate than prior SoTA on the MiniWoB web navigation benchmark and\nbetter accuracy on offline task planning evaluation.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=a+real+world+webagent+with+planning++long+context+understanding++and+program+synthesis&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Pre-trained large language models (LLMs) have recently achieved better\ngeneralization and sample efficiency in autonomous web navigation. However, the\nperformance on real-world websites has still suffered from (1) open domainness,\n(2) limited context length, and (3) lack of inductive bias on HTML. We\nintroduce WebAgent, an LLM-driven agent that can complete the tasks on real\nwebsites following natural language instructions. WebAgent plans ahead by\ndecomposing instructions into canonical sub-instructions, summarizes long HTML\ndocuments into task-relevant snippets, and acts on websites via generated\nPython programs from those. We design WebAgent with Flan-U-PaLM, for grounded\ncode generation, and HTML-T5, new pre-trained LLMs for long HTML documents\nusing local and global attention mechanisms and a mixture of long-span\ndenoising objectives, for planning and summarization. We empirically\ndemonstrate that our recipe improves the success on a real website by over 50%,\nand that HTML-T5 is the best model to solve HTML-based tasks; achieving 14.9%\nhigher success rate than prior SoTA on the MiniWoB web navigation benchmark and\nbetter accuracy on offline task planning evaluation."}, "authors": [{"name": "Izzeddin Gur"}, {"name": "Hiroki Furuta"}, {"name": "Austin Huang"}, {"name": "Mustafa Safdari"}, {"name": "Yutaka Matsuo"}, {"name": "Douglas Eck"}, {"name": "Aleksandra Faust"}], "author_detail": {"name": "Aleksandra Faust"}, "author": "Aleksandra Faust", "links": [{"href": "http://arxiv.org/abs/2307.12856v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2307.12856v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}