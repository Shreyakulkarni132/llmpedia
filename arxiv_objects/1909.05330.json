{"id": "http://arxiv.org/abs/1909.05330v1", "guidislink": true, "link": "http://arxiv.org/abs/1909.05330v1", "updated": "2019-09-11T19:46:21Z", "updated_parsed": [2019, 9, 11, 19, 46, 21, 2, 254, 0], "published": "2019-09-11T19:46:21Z", "published_parsed": [2019, 9, 11, 19, 46, 21, 2, 254, 0], "title": "Large-Scale Multilingual Speech Recognition with a Streaming End-to-End\n  Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+scale+multilingual+speech+recognition+with+a+streaming+end+to+end+model&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large-Scale Multilingual Speech Recognition with a Streaming End-to-End\n  Model"}, "summary": "Multilingual end-to-end (E2E) models have shown great promise in expansion of\nautomatic speech recognition (ASR) coverage of the world's languages. They have\nshown improvement over monolingual systems, and have simplified training and\nserving by eliminating language-specific acoustic, pronunciation, and language\nmodels. This work presents an E2E multilingual system which is equipped to\noperate in low-latency interactive applications, as well as handle a key\nchallenge of real world data: the imbalance in training data across languages.\nUsing nine Indic languages, we compare a variety of techniques, and find that a\ncombination of conditioning on a language vector and training language-specific\nadapter layers produces the best model. The resulting E2E multilingual model\nachieves a lower word error rate (WER) than both monolingual E2E models (eight\nof nine languages) and monolingual conventional systems (all nine languages).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+scale+multilingual+speech+recognition+with+a+streaming+end+to+end+model&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Multilingual end-to-end (E2E) models have shown great promise in expansion of\nautomatic speech recognition (ASR) coverage of the world's languages. They have\nshown improvement over monolingual systems, and have simplified training and\nserving by eliminating language-specific acoustic, pronunciation, and language\nmodels. This work presents an E2E multilingual system which is equipped to\noperate in low-latency interactive applications, as well as handle a key\nchallenge of real world data: the imbalance in training data across languages.\nUsing nine Indic languages, we compare a variety of techniques, and find that a\ncombination of conditioning on a language vector and training language-specific\nadapter layers produces the best model. The resulting E2E multilingual model\nachieves a lower word error rate (WER) than both monolingual E2E models (eight\nof nine languages) and monolingual conventional systems (all nine languages)."}, "authors": [{"name": "Anjuli Kannan"}, {"name": "Arindrima Datta"}, {"name": "Tara N. Sainath"}, {"name": "Eugene Weinstein"}, {"name": "Bhuvana Ramabhadran"}, {"name": "Yonghui Wu"}, {"name": "Ankur Bapna"}, {"name": "Zhifeng Chen"}, {"name": "Seungji Lee"}], "author_detail": {"name": "Seungji Lee"}, "author": "Seungji Lee", "arxiv_comment": "Accepted in Interspeech 2019", "links": [{"href": "http://arxiv.org/abs/1909.05330v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1909.05330v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "eess.AS", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "eess.AS", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.SD", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.ML", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}