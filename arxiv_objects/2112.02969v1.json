{"id": "http://arxiv.org/abs/2112.02969v1", "guidislink": true, "link": "http://arxiv.org/abs/2112.02969v1", "updated": "2021-12-06T12:30:22Z", "updated_parsed": [2021, 12, 6, 12, 30, 22, 0, 340, 0], "published": "2021-12-06T12:30:22Z", "published_parsed": [2021, 12, 6, 12, 30, 22, 0, 340, 0], "title": "Jigsaw: Large Language Models meet Program Synthesis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=jigsaw++large+language+models+meet+program+synthesis&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Jigsaw: Large Language Models meet Program Synthesis"}, "summary": "Large pre-trained language models such as GPT-3, Codex, and Google's language\nmodel are now capable of generating code from natural language specifications\nof programmer intent. We view these developments with a mixture of optimism and\ncaution. On the optimistic side, such large language models have the potential\nto improve productivity by providing an automated AI pair programmer for every\nprogrammer in the world. On the cautionary side, since these large language\nmodels do not understand program semantics, they offer no guarantees about\nquality of the suggested code. In this paper, we present an approach to augment\nthese large language models with post-processing steps based on program\nanalysis and synthesis techniques, that understand the syntax and semantics of\nprograms. Further, we show that such techniques can make use of user feedback\nand improve with usage. We present our experiences from building and evaluating\nsuch a tool jigsaw, targeted at synthesizing code for using Python Pandas API\nusing multi-modal inputs. Our experience suggests that as these large language\nmodels evolve for synthesizing code from intent, jigsaw has an important role\nto play in improving the accuracy of the systems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=jigsaw++large+language+models+meet+program+synthesis&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large pre-trained language models such as GPT-3, Codex, and Google's language\nmodel are now capable of generating code from natural language specifications\nof programmer intent. We view these developments with a mixture of optimism and\ncaution. On the optimistic side, such large language models have the potential\nto improve productivity by providing an automated AI pair programmer for every\nprogrammer in the world. On the cautionary side, since these large language\nmodels do not understand program semantics, they offer no guarantees about\nquality of the suggested code. In this paper, we present an approach to augment\nthese large language models with post-processing steps based on program\nanalysis and synthesis techniques, that understand the syntax and semantics of\nprograms. Further, we show that such techniques can make use of user feedback\nand improve with usage. We present our experiences from building and evaluating\nsuch a tool jigsaw, targeted at synthesizing code for using Python Pandas API\nusing multi-modal inputs. Our experience suggests that as these large language\nmodels evolve for synthesizing code from intent, jigsaw has an important role\nto play in improving the accuracy of the systems."}, "authors": [{"name": "Naman Jain"}, {"name": "Skanda Vaidyanath"}, {"name": "Arun Iyer"}, {"name": "Nagarajan Natarajan"}, {"name": "Suresh Parthasarathy"}, {"name": "Sriram Rajamani"}, {"name": "Rahul Sharma"}], "author_detail": {"name": "Rahul Sharma"}, "author": "Rahul Sharma", "arxiv_comment": "Accepted to ICSE'22", "links": [{"href": "http://arxiv.org/abs/2112.02969v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2112.02969v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}