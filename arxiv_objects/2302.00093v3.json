{"id": "http://arxiv.org/abs/2302.00093v3", "guidislink": true, "link": "http://arxiv.org/abs/2302.00093v3", "updated": "2023-06-06T08:36:20Z", "updated_parsed": [2023, 6, 6, 8, 36, 20, 1, 157, 0], "published": "2023-01-31T20:48:57Z", "published_parsed": [2023, 1, 31, 20, 48, 57, 1, 31, 0], "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+can+be+easily+distracted+by+irrelevant+context&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large Language Models Can Be Easily Distracted by Irrelevant Context"}, "summary": "Large language models have achieved impressive performance on various natural\nlanguage processing tasks. However, so far they have been evaluated primarily\non benchmarks where all information in the input context is relevant for\nsolving the task. In this work, we investigate the distractibility of large\nlanguage models, i.e., how the model problem-solving accuracy can be influenced\nby irrelevant context. In particular, we introduce Grade-School Math with\nIrrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant\ninformation in the problem description. We use this benchmark to measure the\ndistractibility of cutting-edge prompting techniques for large language models,\nand find that the model performance is dramatically decreased when irrelevant\ninformation is included. We also identify several approaches for mitigating\nthis deficiency, such as decoding with self-consistency and adding to the\nprompt an instruction that tells the language model to ignore the irrelevant\ninformation.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+can+be+easily+distracted+by+irrelevant+context&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large language models have achieved impressive performance on various natural\nlanguage processing tasks. However, so far they have been evaluated primarily\non benchmarks where all information in the input context is relevant for\nsolving the task. In this work, we investigate the distractibility of large\nlanguage models, i.e., how the model problem-solving accuracy can be influenced\nby irrelevant context. In particular, we introduce Grade-School Math with\nIrrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant\ninformation in the problem description. We use this benchmark to measure the\ndistractibility of cutting-edge prompting techniques for large language models,\nand find that the model performance is dramatically decreased when irrelevant\ninformation is included. We also identify several approaches for mitigating\nthis deficiency, such as decoding with self-consistency and adding to the\nprompt an instruction that tells the language model to ignore the irrelevant\ninformation."}, "authors": [{"name": "Freda Shi"}, {"name": "Xinyun Chen"}, {"name": "Kanishka Misra"}, {"name": "Nathan Scales"}, {"name": "David Dohan"}, {"name": "Ed Chi"}, {"name": "Nathanael Sch\u00e4rli"}, {"name": "Denny Zhou"}], "author_detail": {"name": "Denny Zhou"}, "author": "Denny Zhou", "arxiv_comment": "Published in ICML 2023", "links": [{"href": "http://arxiv.org/abs/2302.00093v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2302.00093v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}