{"id": "http://arxiv.org/abs/2306.07967v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.07967v1", "updated": "2023-06-13T17:59:32Z", "updated_parsed": [2023, 6, 13, 17, 59, 32, 1, 164, 0], "published": "2023-06-13T17:59:32Z", "published_parsed": [2023, 6, 13, 17, 59, 32, 1, 164, 0], "title": "One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=one+for+all++generalized+lora+for+parameter+efficient+fine+tuning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning"}, "summary": "We present Generalized LoRA (GLoRA), an advanced approach for universal\nparameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA),\nGLoRA employs a generalized prompt module to optimize pre-trained model weights\nand adjust intermediate activations, providing more flexibility and capability\nacross diverse tasks and datasets. Moreover, GLoRA facilitates efficient\nparameter adaptation by employing a scalable, modular, layer-wise structure\nsearch that learns individual adapter of each layer. Originating from a unified\nmathematical formulation, GLoRA exhibits strong transfer learning, few-shot\nlearning and domain generalization abilities, as it adjusts to new tasks\nthrough additional dimensions on weights and activations. Comprehensive\nexperiments demonstrate that GLoRA outperforms all previous methods in natural,\nspecialized, and structured benchmarks, achieving superior accuracy with fewer\nparameters and computations on various datasets. Furthermore, our structural\nre-parameterization design ensures that GLoRA incurs no extra inference cost,\nrendering it a practical solution for resource-limited applications. Code is\navailable at: https://github.com/Arnav0400/ViT-Slim/tree/master/GLoRA.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=one+for+all++generalized+lora+for+parameter+efficient+fine+tuning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "We present Generalized LoRA (GLoRA), an advanced approach for universal\nparameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA),\nGLoRA employs a generalized prompt module to optimize pre-trained model weights\nand adjust intermediate activations, providing more flexibility and capability\nacross diverse tasks and datasets. Moreover, GLoRA facilitates efficient\nparameter adaptation by employing a scalable, modular, layer-wise structure\nsearch that learns individual adapter of each layer. Originating from a unified\nmathematical formulation, GLoRA exhibits strong transfer learning, few-shot\nlearning and domain generalization abilities, as it adjusts to new tasks\nthrough additional dimensions on weights and activations. Comprehensive\nexperiments demonstrate that GLoRA outperforms all previous methods in natural,\nspecialized, and structured benchmarks, achieving superior accuracy with fewer\nparameters and computations on various datasets. Furthermore, our structural\nre-parameterization design ensures that GLoRA incurs no extra inference cost,\nrendering it a practical solution for resource-limited applications. Code is\navailable at: https://github.com/Arnav0400/ViT-Slim/tree/master/GLoRA."}, "authors": [{"name": "Arnav Chavan"}, {"name": "Zhuang Liu"}, {"name": "Deepak Gupta"}, {"name": "Eric Xing"}, {"name": "Zhiqiang Shen"}], "author_detail": {"name": "Zhiqiang Shen"}, "author": "Zhiqiang Shen", "arxiv_comment": "Technical report", "links": [{"href": "http://arxiv.org/abs/2306.07967v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.07967v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}