{"id": "http://arxiv.org/abs/2206.10498v3", "guidislink": true, "link": "http://arxiv.org/abs/2206.10498v3", "updated": "2023-04-08T00:43:13Z", "updated_parsed": [2023, 4, 8, 0, 43, 13, 5, 98, 0], "published": "2022-06-21T16:15:27Z", "published_parsed": [2022, 6, 21, 16, 15, 27, 1, 172, 0], "title": "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning\n  and Reasoning about Change)", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+still+can+t+plan++a+benchmark+for+llms+on+planning+and+reasoning+about+change+&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning\n  and Reasoning about Change)"}, "summary": "Recent advances in large language models (LLMs) have transformed the field of\nnatural language processing (NLP). From GPT-3 to PaLM, the state-of-the-art\nperformance on natural language tasks is being pushed forward with every new\nlarge language model. Along with natural language abilities, there has been a\nsignificant interest in understanding whether such models exhibit reasoning\ncapabilities with the use of reasoning benchmarks. However, even though results\nare seemingly positive, these benchmarks prove to be simplistic in nature and\nthe performance of LLMs on these benchmarks cannot be used as evidence to\nsupport, many a times outlandish, claims being made about LLMs' reasoning\ncapabilities. Further, these only represent a very limited set of simple\nreasoning tasks and we need to look at more sophisticated reasoning problems if\nwe are to measure the true limits of such LLM-based systems. Motivated by this,\nwe propose an extensible assessment framework to test the capabilities of LLMs\non reasoning about actions and change, a central aspect of human intelligence.\nWe provide multiple test cases that are more involved than any of the\npreviously established benchmarks and each test case evaluates a different\naspect of reasoning about actions and change. Results on GPT-3 (davinci),\nInstruct-GPT3 (text-davinci-002) and BLOOM (176B), showcase subpar performance\non such reasoning tasks.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+still+can+t+plan++a+benchmark+for+llms+on+planning+and+reasoning+about+change+&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Recent advances in large language models (LLMs) have transformed the field of\nnatural language processing (NLP). From GPT-3 to PaLM, the state-of-the-art\nperformance on natural language tasks is being pushed forward with every new\nlarge language model. Along with natural language abilities, there has been a\nsignificant interest in understanding whether such models exhibit reasoning\ncapabilities with the use of reasoning benchmarks. However, even though results\nare seemingly positive, these benchmarks prove to be simplistic in nature and\nthe performance of LLMs on these benchmarks cannot be used as evidence to\nsupport, many a times outlandish, claims being made about LLMs' reasoning\ncapabilities. Further, these only represent a very limited set of simple\nreasoning tasks and we need to look at more sophisticated reasoning problems if\nwe are to measure the true limits of such LLM-based systems. Motivated by this,\nwe propose an extensible assessment framework to test the capabilities of LLMs\non reasoning about actions and change, a central aspect of human intelligence.\nWe provide multiple test cases that are more involved than any of the\npreviously established benchmarks and each test case evaluates a different\naspect of reasoning about actions and change. Results on GPT-3 (davinci),\nInstruct-GPT3 (text-davinci-002) and BLOOM (176B), showcase subpar performance\non such reasoning tasks."}, "authors": [{"name": "Karthik Valmeekam"}, {"name": "Alberto Olmo"}, {"name": "Sarath Sreedharan"}, {"name": "Subbarao Kambhampati"}], "author_detail": {"name": "Subbarao Kambhampati"}, "author": "Subbarao Kambhampati", "arxiv_comment": "An updated version of this work is here: arXiv:2302.06706 Accepted at\n  Foundation Models for Decision Making Workshop at Neural Information\n  Processing Systems, 2022", "links": [{"href": "http://arxiv.org/abs/2206.10498v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.10498v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}