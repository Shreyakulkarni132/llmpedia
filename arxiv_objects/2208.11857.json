{"id": "http://arxiv.org/abs/2208.11857v2", "guidislink": true, "link": "http://arxiv.org/abs/2208.11857v2", "updated": "2023-05-07T23:55:09Z", "updated_parsed": [2023, 5, 7, 23, 55, 9, 6, 127, 0], "published": "2022-08-25T03:51:39Z", "published_parsed": [2022, 8, 25, 3, 51, 39, 3, 237, 0], "title": "Shortcut Learning of Large Language Models in Natural Language\n  Understanding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=shortcut+learning+of+large+language+models+in+natural+language+understanding&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Shortcut Learning of Large Language Models in Natural Language\n  Understanding"}, "summary": "Large language models (LLMs) have achieved state-of-the-art performance on a\nseries of natural language understanding tasks. However, these LLMs might rely\non dataset bias and artifacts as shortcuts for prediction. This has\nsignificantly affected their generalizability and adversarial robustness. In\nthis paper, we provide a review of recent developments that address the\nshortcut learning and robustness challenge of LLMs. We first introduce the\nconcepts of shortcut learning of language models. We then introduce methods to\nidentify shortcut learning behavior in language models, characterize the\nreasons for shortcut learning, as well as introduce mitigation solutions.\nFinally, we discuss key research challenges and potential research directions\nin order to advance the field of LLMs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=shortcut+learning+of+large+language+models+in+natural+language+understanding&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large language models (LLMs) have achieved state-of-the-art performance on a\nseries of natural language understanding tasks. However, these LLMs might rely\non dataset bias and artifacts as shortcuts for prediction. This has\nsignificantly affected their generalizability and adversarial robustness. In\nthis paper, we provide a review of recent developments that address the\nshortcut learning and robustness challenge of LLMs. We first introduce the\nconcepts of shortcut learning of language models. We then introduce methods to\nidentify shortcut learning behavior in language models, characterize the\nreasons for shortcut learning, as well as introduce mitigation solutions.\nFinally, we discuss key research challenges and potential research directions\nin order to advance the field of LLMs."}, "authors": [{"name": "Mengnan Du"}, {"name": "Fengxiang He"}, {"name": "Na Zou"}, {"name": "Dacheng Tao"}, {"name": "Xia Hu"}], "author_detail": {"name": "Xia Hu"}, "author": "Xia Hu", "arxiv_comment": "Accepted by Communications of the ACM (CACM), Review Article", "links": [{"href": "http://arxiv.org/abs/2208.11857v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2208.11857v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}