{"id": "http://arxiv.org/abs/2203.10133v2", "guidislink": true, "link": "http://arxiv.org/abs/2203.10133v2", "updated": "2022-03-29T00:08:38Z", "updated_parsed": [2022, 3, 29, 0, 8, 38, 1, 88, 0], "published": "2022-03-18T19:18:54Z", "published_parsed": [2022, 3, 18, 19, 18, 54, 4, 77, 0], "title": "Probing Factually Grounded Content Transfer with Factual Ablation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=probing+factually+grounded+content+transfer+with+factual+ablation&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Probing Factually Grounded Content Transfer with Factual Ablation"}, "summary": "Despite recent success, large neural models often generate factually\nincorrect text. Compounding this is the lack of a standard automatic evaluation\nfor factuality--it cannot be meaningfully improved if it cannot be measured.\nGrounded generation promises a path to solving both of these problems: models\ndraw on a reliable external document (grounding) for factual information,\nsimplifying the challenge of factuality. Measuring factuality is also\nsimplified--to factual consistency, testing whether the generation agrees with\nthe grounding, rather than all facts. Yet, without a standard automatic metric\nfor factual consistency, factually grounded generation remains an open problem.\n  We study this problem for content transfer, in which generations extend a\nprompt, using information from factual grounding. Particularly, this domain\nallows us to introduce the notion of factual ablation for automatically\nmeasuring factual consistency: this captures the intuition that the model\nshould be less likely to produce an output given a less relevant grounding\ndocument. In practice, we measure this by presenting a model with two grounding\ndocuments, and the model should prefer to use the more factually relevant one.\nWe contribute two evaluation sets to measure this. Applying our new evaluation,\nwe propose multiple novel methods improving over strong baselines.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=probing+factually+grounded+content+transfer+with+factual+ablation&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Despite recent success, large neural models often generate factually\nincorrect text. Compounding this is the lack of a standard automatic evaluation\nfor factuality--it cannot be meaningfully improved if it cannot be measured.\nGrounded generation promises a path to solving both of these problems: models\ndraw on a reliable external document (grounding) for factual information,\nsimplifying the challenge of factuality. Measuring factuality is also\nsimplified--to factual consistency, testing whether the generation agrees with\nthe grounding, rather than all facts. Yet, without a standard automatic metric\nfor factual consistency, factually grounded generation remains an open problem.\n  We study this problem for content transfer, in which generations extend a\nprompt, using information from factual grounding. Particularly, this domain\nallows us to introduce the notion of factual ablation for automatically\nmeasuring factual consistency: this captures the intuition that the model\nshould be less likely to produce an output given a less relevant grounding\ndocument. In practice, we measure this by presenting a model with two grounding\ndocuments, and the model should prefer to use the more factually relevant one.\nWe contribute two evaluation sets to measure this. Applying our new evaluation,\nwe propose multiple novel methods improving over strong baselines."}, "authors": [{"name": "Peter West"}, {"name": "Chris Quirk"}, {"name": "Michel Galley"}, {"name": "Yejin Choi"}], "author_detail": {"name": "Yejin Choi"}, "author": "Yejin Choi", "links": [{"href": "http://arxiv.org/abs/2203.10133v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2203.10133v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}