{"id": "http://arxiv.org/abs/2212.09561v4", "guidislink": true, "link": "http://arxiv.org/abs/2212.09561v4", "updated": "2023-05-24T09:34:20Z", "updated_parsed": [2023, 5, 24, 9, 34, 20, 2, 144, 0], "published": "2022-12-19T15:51:52Z", "published_parsed": [2022, 12, 19, 15, 51, 52, 0, 353, 0], "title": "Large Language Models are Better Reasoners with Self-Verification", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+are+better+reasoners+with+self+verification&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Large Language Models are Better Reasoners with Self-Verification"}, "summary": "Recently, with the chain of thought (CoT) prompting, large language models\n(LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural\nlanguage processing tasks such as arithmetic, commonsense, and logical\nreasoning. However, LLMs with CoT require multi-step prompting and multi-token\nprediction, which is highly sensitive to individual mistakes and vulnerable to\nerror accumulation. The above issues make the LLMs need the ability to verify\nthe answers. In fact, after inferring conclusions in some thinking decision\ntasks, people often check them by re-verifying steps to avoid some mistakes. In\nthis paper, we propose and prove that LLMs also have similar self-verification\nabilities. We take the conclusion obtained by CoT as one of the conditions for\nsolving the original problem. By taking turns masking the original conditions\nand predicting their results, we calculate an explainable answer verification\nscore based on whether the re-predicted conditions are correct. Experimental\nresults demonstrate that the proposed method can improve the reasoning\nperformance on various arithmetic, commonsense, and logical reasoning datasets.\nOur code is publicly available at:\nhttps://github.com/WENGSYX/Self-Verification.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+are+better+reasoners+with+self+verification&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Recently, with the chain of thought (CoT) prompting, large language models\n(LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural\nlanguage processing tasks such as arithmetic, commonsense, and logical\nreasoning. However, LLMs with CoT require multi-step prompting and multi-token\nprediction, which is highly sensitive to individual mistakes and vulnerable to\nerror accumulation. The above issues make the LLMs need the ability to verify\nthe answers. In fact, after inferring conclusions in some thinking decision\ntasks, people often check them by re-verifying steps to avoid some mistakes. In\nthis paper, we propose and prove that LLMs also have similar self-verification\nabilities. We take the conclusion obtained by CoT as one of the conditions for\nsolving the original problem. By taking turns masking the original conditions\nand predicting their results, we calculate an explainable answer verification\nscore based on whether the re-predicted conditions are correct. Experimental\nresults demonstrate that the proposed method can improve the reasoning\nperformance on various arithmetic, commonsense, and logical reasoning datasets.\nOur code is publicly available at:\nhttps://github.com/WENGSYX/Self-Verification."}, "authors": [{"name": "Yixuan Weng"}, {"name": "Minjun Zhu"}, {"name": "Fei Xia"}, {"name": "Bin Li"}, {"name": "Shizhu He"}, {"name": "Kang Liu"}, {"name": "Jun Zhao"}], "author_detail": {"name": "Jun Zhao"}, "author": "Jun Zhao", "links": [{"href": "http://arxiv.org/abs/2212.09561v4", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2212.09561v4", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}