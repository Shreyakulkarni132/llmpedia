{"id": "http://arxiv.org/abs/2205.09712v1", "guidislink": true, "link": "http://arxiv.org/abs/2205.09712v1", "updated": "2022-05-19T17:25:28Z", "updated_parsed": [2022, 5, 19, 17, 25, 28, 3, 139, 0], "published": "2022-05-19T17:25:28Z", "published_parsed": [2022, 5, 19, 17, 25, 28, 3, 139, 0], "title": "Selection-Inference: Exploiting Large Language Models for Interpretable\n  Logical Reasoning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=selection+inference++exploiting+large+language+models+for+interpretable+logical+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Selection-Inference: Exploiting Large Language Models for Interpretable\n  Logical Reasoning"}, "summary": "Large language models (LLMs) have been shown to be capable of impressive\nfew-shot generalisation to new tasks. However, they still tend to perform\npoorly on multi-step logical reasoning problems. Here we carry out a\ncomprehensive evaluation of LLMs on 50 tasks that probe different aspects of\nlogical reasoning. We show that language models tend to perform fairly well at\nsingle step inference or entailment tasks, but struggle to chain together\nmultiple reasoning steps to solve more complex problems. In light of this, we\npropose a Selection-Inference (SI) framework that exploits pre-trained LLMs as\ngeneral processing modules, and alternates between selection and inference to\ngenerate a series of interpretable, casual reasoning steps leading to the final\nanswer. We show that a 7B parameter LLM used within the SI framework in a\n5-shot generalisation setting, with no fine-tuning, yields a performance\nimprovement of over 100% compared to an equivalent vanilla baseline on a suite\nof 10 logical reasoning tasks. The same model in the same setting even\noutperforms a significantly larger 280B parameter baseline on the same suite of\ntasks. Moreover, answers produced by the SI framework are accompanied by a\ncausal natural-language-based reasoning trace, which has important implications\nfor the safety and trustworthiness of the system.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=selection+inference++exploiting+large+language+models+for+interpretable+logical+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large language models (LLMs) have been shown to be capable of impressive\nfew-shot generalisation to new tasks. However, they still tend to perform\npoorly on multi-step logical reasoning problems. Here we carry out a\ncomprehensive evaluation of LLMs on 50 tasks that probe different aspects of\nlogical reasoning. We show that language models tend to perform fairly well at\nsingle step inference or entailment tasks, but struggle to chain together\nmultiple reasoning steps to solve more complex problems. In light of this, we\npropose a Selection-Inference (SI) framework that exploits pre-trained LLMs as\ngeneral processing modules, and alternates between selection and inference to\ngenerate a series of interpretable, casual reasoning steps leading to the final\nanswer. We show that a 7B parameter LLM used within the SI framework in a\n5-shot generalisation setting, with no fine-tuning, yields a performance\nimprovement of over 100% compared to an equivalent vanilla baseline on a suite\nof 10 logical reasoning tasks. The same model in the same setting even\noutperforms a significantly larger 280B parameter baseline on the same suite of\ntasks. Moreover, answers produced by the SI framework are accompanied by a\ncausal natural-language-based reasoning trace, which has important implications\nfor the safety and trustworthiness of the system."}, "authors": [{"name": "Antonia Creswell"}, {"name": "Murray Shanahan"}, {"name": "Irina Higgins"}], "author_detail": {"name": "Irina Higgins"}, "author": "Irina Higgins", "links": [{"href": "http://arxiv.org/abs/2205.09712v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2205.09712v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}