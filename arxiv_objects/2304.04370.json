{"id": "http://arxiv.org/abs/2304.04370v4", "guidislink": true, "link": "http://arxiv.org/abs/2304.04370v4", "updated": "2023-06-18T17:08:47Z", "updated_parsed": [2023, 6, 18, 17, 8, 47, 6, 169, 0], "published": "2023-04-10T03:55:35Z", "published_parsed": [2023, 4, 10, 3, 55, 35, 0, 100, 0], "title": "OpenAGI: When LLM Meets Domain Experts", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=openagi++when+llm+meets+domain+experts&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "OpenAGI: When LLM Meets Domain Experts"}, "summary": "Human intelligence excels at combining basic skills to solve complex tasks.\nThis capability is vital for Artificial Intelligence (AI) and should be\nembedded in comprehensive intelligent models, enabling them to harness expert\nmodels for complex task-solving towards Artificial General Intelligence (AGI).\nLarge Language Models (LLMs) show promising learning and reasoning abilities,\nand can effectively use external models to tackle complex problems. In this\nwork, we introduce OpenAGI, an open-source AGI research platform designed for\nmulti-step, real-world tasks. Specifically, OpenAGI uses a dual strategy,\nintegrating standard benchmark tasks for benchmarking and evaluation, and\nopen-ended tasks including more expandable models for creative problem-solving.\nTasks are presented as natural language queries to the LLM, which then selects\nand executes appropriate models. We also propose a Reinforcement Learning from\nTask Feedback (RLTF) mechanism that uses task results to improve the LLM's\nability, which creates a self-improving AI feedback loop. While we acknowledge\nthat AGI is a broad and multifaceted research challenge with no singularly\ndefined solution path, the integration of LLMs with domain-specific expert\nmodels, inspired by mirroring the blend of general and specialized intelligence\nin humans, offers a promising approach towards AGI. We are open-sourcing the\nOpenAGI project's code, dataset, benchmarks, evaluation methods, and demo to\nfoster community involvement in AGI advancement:\nhttps://github.com/agiresearch/OpenAGI.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=openagi++when+llm+meets+domain+experts&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Human intelligence excels at combining basic skills to solve complex tasks.\nThis capability is vital for Artificial Intelligence (AI) and should be\nembedded in comprehensive intelligent models, enabling them to harness expert\nmodels for complex task-solving towards Artificial General Intelligence (AGI).\nLarge Language Models (LLMs) show promising learning and reasoning abilities,\nand can effectively use external models to tackle complex problems. In this\nwork, we introduce OpenAGI, an open-source AGI research platform designed for\nmulti-step, real-world tasks. Specifically, OpenAGI uses a dual strategy,\nintegrating standard benchmark tasks for benchmarking and evaluation, and\nopen-ended tasks including more expandable models for creative problem-solving.\nTasks are presented as natural language queries to the LLM, which then selects\nand executes appropriate models. We also propose a Reinforcement Learning from\nTask Feedback (RLTF) mechanism that uses task results to improve the LLM's\nability, which creates a self-improving AI feedback loop. While we acknowledge\nthat AGI is a broad and multifaceted research challenge with no singularly\ndefined solution path, the integration of LLMs with domain-specific expert\nmodels, inspired by mirroring the blend of general and specialized intelligence\nin humans, offers a promising approach towards AGI. We are open-sourcing the\nOpenAGI project's code, dataset, benchmarks, evaluation methods, and demo to\nfoster community involvement in AGI advancement:\nhttps://github.com/agiresearch/OpenAGI."}, "authors": [{"name": "Yingqiang Ge"}, {"name": "Wenyue Hua"}, {"name": "Kai Mei"}, {"name": "Jianchao Ji"}, {"name": "Juntao Tan"}, {"name": "Shuyuan Xu"}, {"name": "Zelong Li"}, {"name": "Yongfeng Zhang"}], "author_detail": {"name": "Yongfeng Zhang"}, "author": "Yongfeng Zhang", "arxiv_comment": "22 pages, 11 figures, 7 tables", "links": [{"href": "http://arxiv.org/abs/2304.04370v4", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2304.04370v4", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}