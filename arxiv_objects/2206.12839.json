{"id": "http://arxiv.org/abs/2206.12839v3", "guidislink": true, "link": "http://arxiv.org/abs/2206.12839v3", "updated": "2023-06-05T18:43:50Z", "updated_parsed": [2023, 6, 5, 18, 43, 50, 0, 156, 0], "published": "2022-06-26T10:51:25Z", "published_parsed": [2022, 6, 26, 10, 51, 25, 6, 177, 0], "title": "Repository-Level Prompt Generation for Large Language Models of Code", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=repository+level+prompt+generation+for+large+language+models+of+code&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Repository-Level Prompt Generation for Large Language Models of Code"}, "summary": "With the success of large language models (LLMs) of code and their use as\ncode assistants (e.g. Codex used in GitHub Copilot), techniques for introducing\ndomain-specific knowledge in the prompt design process become important. In\nthis work, we propose a framework called Repo-Level Prompt Generator that\nlearns to generate example-specific prompts using prompt proposals. The prompt\nproposals take context from the entire repository, thereby incorporating both\nthe structure of the repository and the context from other relevant files (e.g.\nimports, parent class files). Our technique doesn't require any access to the\nweights of the LLM, making it applicable in cases where we only have black-box\naccess to the LLM. We conduct experiments on the task of single-line\ncode-autocompletion using code repositories taken from Google Code archives. We\ndemonstrate that an oracle constructed from our prompt proposals gives a\nremarkably high relative improvement of 36% over Codex, showing the quality of\nthese proposals. Further, we show that when we train a model to predict a\nprompt proposal, we can achieve significant performance gains over Codex and\nother baselines. We release our code, data, and trained checkpoints at:\n\\url{https://github.com/shrivastavadisha/repo_level_prompt_generation}.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=repository+level+prompt+generation+for+large+language+models+of+code&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "With the success of large language models (LLMs) of code and their use as\ncode assistants (e.g. Codex used in GitHub Copilot), techniques for introducing\ndomain-specific knowledge in the prompt design process become important. In\nthis work, we propose a framework called Repo-Level Prompt Generator that\nlearns to generate example-specific prompts using prompt proposals. The prompt\nproposals take context from the entire repository, thereby incorporating both\nthe structure of the repository and the context from other relevant files (e.g.\nimports, parent class files). Our technique doesn't require any access to the\nweights of the LLM, making it applicable in cases where we only have black-box\naccess to the LLM. We conduct experiments on the task of single-line\ncode-autocompletion using code repositories taken from Google Code archives. We\ndemonstrate that an oracle constructed from our prompt proposals gives a\nremarkably high relative improvement of 36% over Codex, showing the quality of\nthese proposals. Further, we show that when we train a model to predict a\nprompt proposal, we can achieve significant performance gains over Codex and\nother baselines. We release our code, data, and trained checkpoints at:\n\\url{https://github.com/shrivastavadisha/repo_level_prompt_generation}."}, "authors": [{"name": "Disha Shrivastava"}, {"name": "Hugo Larochelle"}, {"name": "Daniel Tarlow"}], "author_detail": {"name": "Daniel Tarlow"}, "author": "Daniel Tarlow", "arxiv_comment": "ICML 2023 (Camera-Ready version)", "arxiv_journal_ref": "ICML, 2023", "links": [{"href": "http://arxiv.org/abs/2206.12839v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.12839v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}