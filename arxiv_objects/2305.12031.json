{"id": "http://arxiv.org/abs/2305.12031v1", "guidislink": true, "link": "http://arxiv.org/abs/2305.12031v1", "updated": "2023-05-19T23:07:09Z", "updated_parsed": [2023, 5, 19, 23, 7, 9, 4, 139, 0], "published": "2023-05-19T23:07:09Z", "published_parsed": [2023, 5, 19, 23, 7, 9, 4, 139, 0], "title": "Clinical Camel: An Open-Source Expert-Level Medical Language Model with\n  Dialogue-Based Knowledge Encoding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=clinical+camel++an+open+source+expert+level+medical+language+model+with+dialogue+based+knowledge+encoding&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Clinical Camel: An Open-Source Expert-Level Medical Language Model with\n  Dialogue-Based Knowledge Encoding"}, "summary": "Large Language Models (LLMs) present immense potential in the medical field,\nyet concerns over data privacy, regulatory compliance, and model stability\nrestrict their widespread adoption. Although the distillation of\nhigh-performing closed-source LLMs has proven effective for general tasks,\ntheir application in healthcare is limited due to reduced domain knowledge and\nremnants of alignment behavior hindering clinical tasks. To address these\nchallenges, we propose Dialogue-Based Knowledge Encoding (DBKE). DBKE enhances\nmodels' implicit knowledge base and primes them for conversational recall,\naugmenting their conversational capabilities and enabling a soft alignment for\nsubsequent use cases. By transforming dense academic source text into synthetic\ndialogue, DBKE broadens the model's knowledge base and enables a soft alignment\nthat guides downstream behaviours. We present Clinical Camel, an open-source,\nhealthcare-focused conversational model, to showcase the effectiveness of DBKE.\nClinical Camel outperforms GPT-3.5 on the United States Medical Licensing\nExamination (USMLE) Step 1 and Step 3 with scores of 53.2 % and 58.2 %,\nrespectively, compared to GPT-3.5's scores of 36.1 % and 55.7 %. Clinical Camel\nadeptly handles multi-stage clinical case problems, provides adaptive\ncounseling, and generates clinical notes. However, it is prone to\nhallucinations, which pose a significant obstacle in safety-critical settings.\nThe performance of Clinical Camel underscores the importance of continued\nresearch and development of open-source models for the safe and effective\nintegration of LLMs in healthcare settings.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=clinical+camel++an+open+source+expert+level+medical+language+model+with+dialogue+based+knowledge+encoding&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large Language Models (LLMs) present immense potential in the medical field,\nyet concerns over data privacy, regulatory compliance, and model stability\nrestrict their widespread adoption. Although the distillation of\nhigh-performing closed-source LLMs has proven effective for general tasks,\ntheir application in healthcare is limited due to reduced domain knowledge and\nremnants of alignment behavior hindering clinical tasks. To address these\nchallenges, we propose Dialogue-Based Knowledge Encoding (DBKE). DBKE enhances\nmodels' implicit knowledge base and primes them for conversational recall,\naugmenting their conversational capabilities and enabling a soft alignment for\nsubsequent use cases. By transforming dense academic source text into synthetic\ndialogue, DBKE broadens the model's knowledge base and enables a soft alignment\nthat guides downstream behaviours. We present Clinical Camel, an open-source,\nhealthcare-focused conversational model, to showcase the effectiveness of DBKE.\nClinical Camel outperforms GPT-3.5 on the United States Medical Licensing\nExamination (USMLE) Step 1 and Step 3 with scores of 53.2 % and 58.2 %,\nrespectively, compared to GPT-3.5's scores of 36.1 % and 55.7 %. Clinical Camel\nadeptly handles multi-stage clinical case problems, provides adaptive\ncounseling, and generates clinical notes. However, it is prone to\nhallucinations, which pose a significant obstacle in safety-critical settings.\nThe performance of Clinical Camel underscores the importance of continued\nresearch and development of open-source models for the safe and effective\nintegration of LLMs in healthcare settings."}, "authors": [{"name": "Augustin Toma"}, {"name": "Patrick R. Lawler"}, {"name": "Jimmy Ba"}, {"name": "Rahul G. Krishnan"}, {"name": "Barry B. Rubin"}, {"name": "Bo Wang"}], "author_detail": {"name": "Bo Wang"}, "author": "Bo Wang", "arxiv_comment": "for model weights, see https://huggingface.co/wanglab/clinical-camel\n  for code, see https://github.com/bowang-lab/clinical-camel", "links": [{"href": "http://arxiv.org/abs/2305.12031v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2305.12031v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}