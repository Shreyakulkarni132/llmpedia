{"id": "http://arxiv.org/abs/2110.01691v3", "guidislink": true, "link": "http://arxiv.org/abs/2110.01691v3", "updated": "2022-03-17T20:16:38Z", "updated_parsed": [2022, 3, 17, 20, 16, 38, 3, 76, 0], "published": "2021-10-04T19:59:38Z", "published_parsed": [2021, 10, 4, 19, 59, 38, 0, 277, 0], "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining\n  Large Language Model Prompts", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=ai+chains++transparent+and+controllable+human+ai+interaction+by+chaining+large+language+model+prompts&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining\n  Large Language Model Prompts"}, "summary": "Although large language models (LLMs) have demonstrated impressive potential\non simple tasks, their breadth of scope, lack of transparency, and insufficient\ncontrollability can make them less effective when assisting humans on more\ncomplex tasks. In response, we introduce the concept of Chaining LLM steps\ntogether, where the output of one step becomes the input for the next, thus\naggregating the gains per step. We first define a set of LLM primitive\noperations useful for Chain construction, then present an interactive system\nwhere users can modify these Chains, along with their intermediate results, in\na modular way. In a 20-person user study, we found that Chaining not only\nimproved the quality of task outcomes, but also significantly enhanced system\ntransparency, controllability, and sense of collaboration. Additionally, we saw\nthat users developed new ways of interacting with LLMs through Chains: they\nleveraged sub-tasks to calibrate model expectations, compared and contrasted\nalternative strategies by observing parallel downstream effects, and debugged\nunexpected model outputs by \"unit-testing\" sub-components of a Chain. In two\ncase studies, we further explore how LLM Chains may be used in future\napplications", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=ai+chains++transparent+and+controllable+human+ai+interaction+by+chaining+large+language+model+prompts&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Although large language models (LLMs) have demonstrated impressive potential\non simple tasks, their breadth of scope, lack of transparency, and insufficient\ncontrollability can make them less effective when assisting humans on more\ncomplex tasks. In response, we introduce the concept of Chaining LLM steps\ntogether, where the output of one step becomes the input for the next, thus\naggregating the gains per step. We first define a set of LLM primitive\noperations useful for Chain construction, then present an interactive system\nwhere users can modify these Chains, along with their intermediate results, in\na modular way. In a 20-person user study, we found that Chaining not only\nimproved the quality of task outcomes, but also significantly enhanced system\ntransparency, controllability, and sense of collaboration. Additionally, we saw\nthat users developed new ways of interacting with LLMs through Chains: they\nleveraged sub-tasks to calibrate model expectations, compared and contrasted\nalternative strategies by observing parallel downstream effects, and debugged\nunexpected model outputs by \"unit-testing\" sub-components of a Chain. In two\ncase studies, we further explore how LLM Chains may be used in future\napplications"}, "authors": [{"name": "Tongshuang Wu"}, {"name": "Michael Terry"}, {"name": "Carrie J. Cai"}], "author_detail": {"name": "Carrie J. Cai"}, "author": "Carrie J. Cai", "links": [{"href": "http://arxiv.org/abs/2110.01691v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2110.01691v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}