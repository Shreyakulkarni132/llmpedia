{"id": "http://arxiv.org/abs/2206.14858v2", "guidislink": true, "link": "http://arxiv.org/abs/2206.14858v2", "updated": "2022-07-01T02:15:12Z", "updated_parsed": [2022, 7, 1, 2, 15, 12, 4, 182, 0], "published": "2022-06-29T18:54:49Z", "published_parsed": [2022, 6, 29, 18, 54, 49, 2, 180, 0], "title": "Solving Quantitative Reasoning Problems with Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=solving+quantitative+reasoning+problems+with+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Solving Quantitative Reasoning Problems with Language Models"}, "summary": "Language models have achieved remarkable performance on a wide range of tasks\nthat require natural language understanding. Nevertheless, state-of-the-art\nmodels have generally struggled with tasks that require quantitative reasoning,\nsuch as solving mathematics, science, and engineering problems at the college\nlevel. To help close this gap, we introduce Minerva, a large language model\npretrained on general natural language data and further trained on technical\ncontent. The model achieves state-of-the-art performance on technical\nbenchmarks without the use of external tools. We also evaluate our model on\nover two hundred undergraduate-level problems in physics, biology, chemistry,\neconomics, and other sciences that require quantitative reasoning, and find\nthat the model can correctly answer nearly a third of them.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=solving+quantitative+reasoning+problems+with+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Language models have achieved remarkable performance on a wide range of tasks\nthat require natural language understanding. Nevertheless, state-of-the-art\nmodels have generally struggled with tasks that require quantitative reasoning,\nsuch as solving mathematics, science, and engineering problems at the college\nlevel. To help close this gap, we introduce Minerva, a large language model\npretrained on general natural language data and further trained on technical\ncontent. The model achieves state-of-the-art performance on technical\nbenchmarks without the use of external tools. We also evaluate our model on\nover two hundred undergraduate-level problems in physics, biology, chemistry,\neconomics, and other sciences that require quantitative reasoning, and find\nthat the model can correctly answer nearly a third of them."}, "authors": [{"name": "Aitor Lewkowycz"}, {"name": "Anders Andreassen"}, {"name": "David Dohan"}, {"name": "Ethan Dyer"}, {"name": "Henryk Michalewski"}, {"name": "Vinay Ramasesh"}, {"name": "Ambrose Slone"}, {"name": "Cem Anil"}, {"name": "Imanol Schlag"}, {"name": "Theo Gutman-Solo"}, {"name": "Yuhuai Wu"}, {"name": "Behnam Neyshabur"}, {"name": "Guy Gur-Ari"}, {"name": "Vedant Misra"}], "author_detail": {"name": "Vedant Misra"}, "author": "Vedant Misra", "arxiv_comment": "12 pages, 5 figures + references and appendices", "links": [{"href": "http://arxiv.org/abs/2206.14858v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.14858v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}