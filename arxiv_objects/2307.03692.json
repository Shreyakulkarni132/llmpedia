{"id": "http://arxiv.org/abs/2307.03692v1", "guidislink": true, "link": "http://arxiv.org/abs/2307.03692v1", "updated": "2023-07-05T09:42:25Z", "updated_parsed": [2023, 7, 5, 9, 42, 25, 2, 186, 0], "published": "2023-07-05T09:42:25Z", "published_parsed": [2023, 7, 5, 9, 42, 25, 2, 186, 0], "title": "Becoming self-instruct: introducing early stopping criteria for minimal\n  instruct tuning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=becoming+self+instruct++introducing+early+stopping+criteria+for+minimal+instruct+tuning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Becoming self-instruct: introducing early stopping criteria for minimal\n  instruct tuning"}, "summary": "In this paper, we introduce the Instruction Following Score (IFS), a metric\nthat detects language models' ability to follow instructions. The metric has a\ndual purpose. First, IFS can be used to distinguish between base and instruct\nmodels. We benchmark publicly available base and instruct models, and show that\nthe ratio of well formatted responses to partial and full sentences can be an\neffective measure between those two model classes. Secondly, the metric can be\nused as an early stopping criteria for instruct tuning. We compute IFS for\nSupervised Fine-Tuning (SFT) of 7B and 13B LLaMA models, showing that models\nlearn to follow instructions relatively early in the training process, and the\nfurther finetuning can result in changes in the underlying base model\nsemantics. As an example of semantics change we show the objectivity of model\npredictions, as defined by an auxiliary metric ObjecQA. We show that in this\nparticular case, semantic changes are the steepest when the IFS tends to\nplateau. We hope that decomposing instruct tuning into IFS and semantic factors\nstarts a new trend in better controllable instruct tuning and opens\npossibilities for designing minimal instruct interfaces querying foundation\nmodels.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=becoming+self+instruct++introducing+early+stopping+criteria+for+minimal+instruct+tuning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "In this paper, we introduce the Instruction Following Score (IFS), a metric\nthat detects language models' ability to follow instructions. The metric has a\ndual purpose. First, IFS can be used to distinguish between base and instruct\nmodels. We benchmark publicly available base and instruct models, and show that\nthe ratio of well formatted responses to partial and full sentences can be an\neffective measure between those two model classes. Secondly, the metric can be\nused as an early stopping criteria for instruct tuning. We compute IFS for\nSupervised Fine-Tuning (SFT) of 7B and 13B LLaMA models, showing that models\nlearn to follow instructions relatively early in the training process, and the\nfurther finetuning can result in changes in the underlying base model\nsemantics. As an example of semantics change we show the objectivity of model\npredictions, as defined by an auxiliary metric ObjecQA. We show that in this\nparticular case, semantic changes are the steepest when the IFS tends to\nplateau. We hope that decomposing instruct tuning into IFS and semantic factors\nstarts a new trend in better controllable instruct tuning and opens\npossibilities for designing minimal instruct interfaces querying foundation\nmodels."}, "authors": [{"name": "Waseem AlShikh"}, {"name": "Manhal Daaboul"}, {"name": "Kirk Goddard"}, {"name": "Brock Imel"}, {"name": "Kiran Kamble"}, {"name": "Parikshith Kulkarni"}, {"name": "Melisa Russak"}], "author_detail": {"name": "Melisa Russak"}, "author": "Melisa Russak", "links": [{"href": "http://arxiv.org/abs/2307.03692v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2307.03692v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}