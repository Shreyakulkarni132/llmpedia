{"id": "http://arxiv.org/abs/2306.08568v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.08568v1", "updated": "2023-06-14T15:18:48Z", "updated_parsed": [2023, 6, 14, 15, 18, 48, 2, 165, 0], "published": "2023-06-14T15:18:48Z", "published_parsed": [2023, 6, 14, 15, 18, 48, 2, 165, 0], "title": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=wizardcoder++empowering+code+large+language+models+with+evol+instruct&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct"}, "summary": "Code Large Language Models (Code LLMs), such as StarCoder, have demonstrated\nexceptional performance in code-related tasks. However, most existing models\nare solely pre-trained on extensive raw code data without instruction\nfine-tuning. In this paper, we introduce WizardCoder, which empowers Code LLMs\nwith complex instruction fine-tuning, by adapting the Evol-Instruct method to\nthe domain of code. Through comprehensive experiments on four prominent code\ngeneration benchmarks, namely HumanEval, HumanEval+, MBPP, and DS-1000, we\nunveil the exceptional capabilities of our model. It surpasses all other\nopen-source Code LLMs by a substantial margin. Moreover, our model even\noutperforms the largest closed LLMs, Anthropic's Claude and Google's Bard, on\nHumanEval and HumanEval+. Our code, model weights, and data are public at\nhttps://github.com/nlpxucan/WizardLM", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=wizardcoder++empowering+code+large+language+models+with+evol+instruct&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Code Large Language Models (Code LLMs), such as StarCoder, have demonstrated\nexceptional performance in code-related tasks. However, most existing models\nare solely pre-trained on extensive raw code data without instruction\nfine-tuning. In this paper, we introduce WizardCoder, which empowers Code LLMs\nwith complex instruction fine-tuning, by adapting the Evol-Instruct method to\nthe domain of code. Through comprehensive experiments on four prominent code\ngeneration benchmarks, namely HumanEval, HumanEval+, MBPP, and DS-1000, we\nunveil the exceptional capabilities of our model. It surpasses all other\nopen-source Code LLMs by a substantial margin. Moreover, our model even\noutperforms the largest closed LLMs, Anthropic's Claude and Google's Bard, on\nHumanEval and HumanEval+. Our code, model weights, and data are public at\nhttps://github.com/nlpxucan/WizardLM"}, "authors": [{"name": "Ziyang Luo"}, {"name": "Can Xu"}, {"name": "Pu Zhao"}, {"name": "Qingfeng Sun"}, {"name": "Xiubo Geng"}, {"name": "Wenxiang Hu"}, {"name": "Chongyang Tao"}, {"name": "Jing Ma"}, {"name": "Qingwei Lin"}, {"name": "Daxin Jiang"}], "author_detail": {"name": "Daxin Jiang"}, "author": "Daxin Jiang", "arxiv_comment": "Large Language model, Code Generation, Code LLMs", "links": [{"href": "http://arxiv.org/abs/2306.08568v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.08568v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}