{"id": "http://arxiv.org/abs/2210.01293v2", "guidislink": true, "link": "http://arxiv.org/abs/2210.01293v2", "updated": "2023-06-02T17:25:19Z", "updated_parsed": [2023, 6, 2, 17, 25, 19, 4, 153, 0], "published": "2022-10-04T00:34:01Z", "published_parsed": [2022, 10, 4, 0, 34, 1, 1, 277, 0], "title": "ThinkSum: Probabilistic reasoning over sets using large language models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=thinksum++probabilistic+reasoning+over+sets+using+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "ThinkSum: Probabilistic reasoning over sets using large language models"}, "summary": "Large language models (LLMs) have a substantial capacity for high-level\nanalogical reasoning: reproducing patterns in linear text that occur in their\ntraining data (zero-shot evaluation) or in the provided context (few-shot\nin-context learning). However, recent studies show that even the more advanced\nLLMs fail in scenarios that require reasoning over multiple objects or facts\nand making sequences of logical deductions. We propose a two-stage\nprobabilistic inference paradigm, ThinkSum, which reasons over sets of objects\nor facts in a structured manner. In the first stage (Think - retrieval of\nassociations), a LLM is queried in parallel over a set of phrases extracted\nfrom the prompt or an auxiliary model call. In the second stage (Sum -\nprobabilistic inference or reasoning), the results of these queries are\naggregated to make the final prediction. We demonstrate the possibilities and\nadvantages of ThinkSum on the BIG-bench suite of LLM evaluation tasks,\nachieving improvements over the state of the art using GPT-family models on\nthirteen difficult tasks, often with far smaller model variants. We also\ncompare and contrast ThinkSum with other proposed modifications to direct\nprompting of LLMs, such as variants of chain-of-thought prompting. Our results\nsuggest that because the probabilistic inference in ThinkSum is performed\noutside of calls to the LLM, ThinkSum is less sensitive to prompt design,\nyields more interpretable predictions, and can be flexibly combined with latent\nvariable models to extract structured knowledge from LLMs. Overall, our\nproposed paradigm represents a promising approach for enhancing the reasoning\ncapabilities of LLMs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=thinksum++probabilistic+reasoning+over+sets+using+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Large language models (LLMs) have a substantial capacity for high-level\nanalogical reasoning: reproducing patterns in linear text that occur in their\ntraining data (zero-shot evaluation) or in the provided context (few-shot\nin-context learning). However, recent studies show that even the more advanced\nLLMs fail in scenarios that require reasoning over multiple objects or facts\nand making sequences of logical deductions. We propose a two-stage\nprobabilistic inference paradigm, ThinkSum, which reasons over sets of objects\nor facts in a structured manner. In the first stage (Think - retrieval of\nassociations), a LLM is queried in parallel over a set of phrases extracted\nfrom the prompt or an auxiliary model call. In the second stage (Sum -\nprobabilistic inference or reasoning), the results of these queries are\naggregated to make the final prediction. We demonstrate the possibilities and\nadvantages of ThinkSum on the BIG-bench suite of LLM evaluation tasks,\nachieving improvements over the state of the art using GPT-family models on\nthirteen difficult tasks, often with far smaller model variants. We also\ncompare and contrast ThinkSum with other proposed modifications to direct\nprompting of LLMs, such as variants of chain-of-thought prompting. Our results\nsuggest that because the probabilistic inference in ThinkSum is performed\noutside of calls to the LLM, ThinkSum is less sensitive to prompt design,\nyields more interpretable predictions, and can be flexibly combined with latent\nvariable models to extract structured knowledge from LLMs. Overall, our\nproposed paradigm represents a promising approach for enhancing the reasoning\ncapabilities of LLMs."}, "authors": [{"name": "Batu Ozturkler"}, {"name": "Nikolay Malkin"}, {"name": "Zhen Wang"}, {"name": "Nebojsa Jojic"}], "author_detail": {"name": "Nebojsa Jojic"}, "author": "Nebojsa Jojic", "arxiv_comment": "ACL 2023", "links": [{"href": "http://arxiv.org/abs/2210.01293v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2210.01293v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}