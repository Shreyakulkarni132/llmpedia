{"id": "http://arxiv.org/abs/2308.00113v1", "guidislink": true, "link": "http://arxiv.org/abs/2308.00113v1", "updated": "2023-07-26T17:56:36Z", "updated_parsed": [2023, 7, 26, 17, 56, 36, 2, 207, 0], "published": "2023-07-26T17:56:36Z", "published_parsed": [2023, 7, 26, 17, 56, 36, 2, 207, 0], "title": "Three Bricks to Consolidate Watermarks for Large Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=three+bricks+to+consolidate+watermarks+for+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Three Bricks to Consolidate Watermarks for Large Language Models"}, "summary": "The task of discerning between generated and natural texts is increasingly\nchallenging. In this context, watermarking emerges as a promising technique for\nascribing generated text to a specific model. It alters the sampling generation\nprocess so as to leave an invisible trace in the generated output, facilitating\nlater detection. This research consolidates watermarks for large language\nmodels based on three theoretical and empirical considerations. First, we\nintroduce new statistical tests that offer robust theoretical guarantees which\nremain valid even at low false-positive rates (less than 10$^{\\text{-6}}$).\nSecond, we compare the effectiveness of watermarks using classical benchmarks\nin the field of natural language processing, gaining insights into their\nreal-world applicability. Third, we develop advanced detection schemes for\nscenarios where access to the LLM is available, as well as multi-bit\nwatermarking.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=three+bricks+to+consolidate+watermarks+for+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "The task of discerning between generated and natural texts is increasingly\nchallenging. In this context, watermarking emerges as a promising technique for\nascribing generated text to a specific model. It alters the sampling generation\nprocess so as to leave an invisible trace in the generated output, facilitating\nlater detection. This research consolidates watermarks for large language\nmodels based on three theoretical and empirical considerations. First, we\nintroduce new statistical tests that offer robust theoretical guarantees which\nremain valid even at low false-positive rates (less than 10$^{\\text{-6}}$).\nSecond, we compare the effectiveness of watermarks using classical benchmarks\nin the field of natural language processing, gaining insights into their\nreal-world applicability. Third, we develop advanced detection schemes for\nscenarios where access to the LLM is available, as well as multi-bit\nwatermarking."}, "authors": [{"name": "Pierre Fernandez"}, {"name": "Antoine Chaffin"}, {"name": "Karim Tit"}, {"name": "Vivien Chappelier"}, {"name": "Teddy Furon"}], "author_detail": {"name": "Teddy Furon"}, "author": "Teddy Furon", "arxiv_comment": "Webpage at https://pierrefdz.github.io/publications/threebricks/", "links": [{"href": "http://arxiv.org/abs/2308.00113v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2308.00113v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}