{"id": "http://arxiv.org/abs/2211.13638v1", "guidislink": true, "link": "http://arxiv.org/abs/2211.13638v1", "updated": "2022-11-24T14:38:08Z", "updated_parsed": [2022, 11, 24, 14, 38, 8, 3, 328, 0], "published": "2022-11-24T14:38:08Z", "published_parsed": [2022, 11, 24, 14, 38, 8, 3, 328, 0], "title": "Prototypical Fine-tuning: Towards Robust Performance Under Varying Data\n  Sizes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=prototypical+fine+tuning++towards+robust+performance+under+varying+data+sizes&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Prototypical Fine-tuning: Towards Robust Performance Under Varying Data\n  Sizes"}, "summary": "In this paper, we move towards combining large parametric models with\nnon-parametric prototypical networks. We propose prototypical fine-tuning, a\nnovel prototypical framework for fine-tuning pretrained language models (LM),\nwhich automatically learns a bias to improve predictive performance for varying\ndata sizes, especially low-resource settings. Our prototypical fine-tuning\napproach can automatically adjust the model capacity according to the number of\ndata points and the model's inherent attributes. Moreover, we propose four\nprinciples for effective prototype fine-tuning towards the optimal solution.\nExperimental results across various datasets show that our work achieves\nsignificant performance improvements under various low-resource settings, as\nwell as comparable and usually better performances in high-resource scenarios.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=prototypical+fine+tuning++towards+robust+performance+under+varying+data+sizes&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "In this paper, we move towards combining large parametric models with\nnon-parametric prototypical networks. We propose prototypical fine-tuning, a\nnovel prototypical framework for fine-tuning pretrained language models (LM),\nwhich automatically learns a bias to improve predictive performance for varying\ndata sizes, especially low-resource settings. Our prototypical fine-tuning\napproach can automatically adjust the model capacity according to the number of\ndata points and the model's inherent attributes. Moreover, we propose four\nprinciples for effective prototype fine-tuning towards the optimal solution.\nExperimental results across various datasets show that our work achieves\nsignificant performance improvements under various low-resource settings, as\nwell as comparable and usually better performances in high-resource scenarios."}, "authors": [{"name": "Yiqiao Jin"}, {"name": "Xiting Wang"}, {"name": "Yaru Hao"}, {"name": "Yizhou Sun"}, {"name": "Xing Xie"}], "author_detail": {"name": "Xing Xie"}, "author": "Xing Xie", "arxiv_comment": "Published as a conference paper at AAAI 2023", "links": [{"href": "http://arxiv.org/abs/2211.13638v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2211.13638v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}