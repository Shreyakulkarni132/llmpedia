{"id": "http://arxiv.org/abs/2305.08845v1", "guidislink": true, "link": "http://arxiv.org/abs/2305.08845v1", "updated": "2023-05-15T17:57:39Z", "updated_parsed": [2023, 5, 15, 17, 57, 39, 0, 135, 0], "published": "2023-05-15T17:57:39Z", "published_parsed": [2023, 5, 15, 17, 57, 39, 0, 135, 0], "title": "Large Language Models are Zero-Shot Rankers for Recommender Systems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+are+zero+shot+rankers+for+recommender+systems&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Large Language Models are Zero-Shot Rankers for Recommender Systems"}, "summary": "Recently, large language models (LLMs) (e.g. GPT-4) have demonstrated\nimpressive general-purpose task-solving abilities, including the potential to\napproach recommendation tasks. Along this line of research, this work aims to\ninvestigate the capacity of LLMs that act as the ranking model for recommender\nsystems. To conduct our empirical study, we first formalize the recommendation\nproblem as a conditional ranking task, considering sequential interaction\nhistories as conditions and the items retrieved by the candidate generation\nmodel as candidates. We adopt a specific prompting approach to solving the\nranking task by LLMs: we carefully design the prompting template by including\nthe sequential interaction history, the candidate items, and the ranking\ninstruction. We conduct extensive experiments on two widely-used datasets for\nrecommender systems and derive several key findings for the use of LLMs in\nrecommender systems. We show that LLMs have promising zero-shot ranking\nabilities, even competitive to or better than conventional recommendation\nmodels on candidates retrieved by multiple candidate generators. We also\ndemonstrate that LLMs struggle to perceive the order of historical interactions\nand can be affected by biases like position bias, while these issues can be\nalleviated via specially designed prompting and bootstrapping strategies. The\ncode to reproduce this work is available at\nhttps://github.com/RUCAIBox/LLMRank.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+are+zero+shot+rankers+for+recommender+systems&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Recently, large language models (LLMs) (e.g. GPT-4) have demonstrated\nimpressive general-purpose task-solving abilities, including the potential to\napproach recommendation tasks. Along this line of research, this work aims to\ninvestigate the capacity of LLMs that act as the ranking model for recommender\nsystems. To conduct our empirical study, we first formalize the recommendation\nproblem as a conditional ranking task, considering sequential interaction\nhistories as conditions and the items retrieved by the candidate generation\nmodel as candidates. We adopt a specific prompting approach to solving the\nranking task by LLMs: we carefully design the prompting template by including\nthe sequential interaction history, the candidate items, and the ranking\ninstruction. We conduct extensive experiments on two widely-used datasets for\nrecommender systems and derive several key findings for the use of LLMs in\nrecommender systems. We show that LLMs have promising zero-shot ranking\nabilities, even competitive to or better than conventional recommendation\nmodels on candidates retrieved by multiple candidate generators. We also\ndemonstrate that LLMs struggle to perceive the order of historical interactions\nand can be affected by biases like position bias, while these issues can be\nalleviated via specially designed prompting and bootstrapping strategies. The\ncode to reproduce this work is available at\nhttps://github.com/RUCAIBox/LLMRank."}, "authors": [{"name": "Yupeng Hou"}, {"name": "Junjie Zhang"}, {"name": "Zihan Lin"}, {"name": "Hongyu Lu"}, {"name": "Ruobing Xie"}, {"name": "Julian McAuley"}, {"name": "Wayne Xin Zhao"}], "author_detail": {"name": "Wayne Xin Zhao"}, "author": "Wayne Xin Zhao", "links": [{"href": "http://arxiv.org/abs/2305.08845v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2305.08845v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}