{"id": "http://arxiv.org/abs/2205.10625v3", "guidislink": true, "link": "http://arxiv.org/abs/2205.10625v3", "updated": "2023-04-16T22:08:08Z", "updated_parsed": [2023, 4, 16, 22, 8, 8, 6, 106, 0], "published": "2022-05-21T15:34:53Z", "published_parsed": [2022, 5, 21, 15, 34, 53, 5, 141, 0], "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language\n  Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=least+to+most+prompting+enables+complex+reasoning+in+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Least-to-Most Prompting Enables Complex Reasoning in Large Language\n  Models"}, "summary": "Chain-of-thought prompting has demonstrated remarkable performance on various\nnatural language reasoning tasks. However, it tends to perform poorly on tasks\nwhich requires solving problems harder than the exemplars shown in the prompts.\nTo overcome this challenge of easy-to-hard generalization, we propose a novel\nprompting strategy, least-to-most prompting. The key idea in this strategy is\nto break down a complex problem into a series of simpler subproblems and then\nsolve them in sequence. Solving each subproblem is facilitated by the answers\nto previously solved subproblems. Our experimental results on tasks related to\nsymbolic manipulation, compositional generalization, and math reasoning reveal\nthat least-to-most prompting is capable of generalizing to more difficult\nproblems than those seen in the prompts. A notable finding is that when the\nGPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve\nthe compositional generalization benchmark SCAN in any split (including length\nsplit) with an accuracy of at least 99% using just 14 exemplars, compared to\nonly 16% accuracy with chain-of-thought prompting. This is particularly\nnoteworthy because neural-symbolic models in the literature that specialize in\nsolving SCAN are trained on the entire training set containing over 15,000\nexamples. We have included prompts for all the tasks in the Appendix.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=least+to+most+prompting+enables+complex+reasoning+in+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Chain-of-thought prompting has demonstrated remarkable performance on various\nnatural language reasoning tasks. However, it tends to perform poorly on tasks\nwhich requires solving problems harder than the exemplars shown in the prompts.\nTo overcome this challenge of easy-to-hard generalization, we propose a novel\nprompting strategy, least-to-most prompting. The key idea in this strategy is\nto break down a complex problem into a series of simpler subproblems and then\nsolve them in sequence. Solving each subproblem is facilitated by the answers\nto previously solved subproblems. Our experimental results on tasks related to\nsymbolic manipulation, compositional generalization, and math reasoning reveal\nthat least-to-most prompting is capable of generalizing to more difficult\nproblems than those seen in the prompts. A notable finding is that when the\nGPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve\nthe compositional generalization benchmark SCAN in any split (including length\nsplit) with an accuracy of at least 99% using just 14 exemplars, compared to\nonly 16% accuracy with chain-of-thought prompting. This is particularly\nnoteworthy because neural-symbolic models in the literature that specialize in\nsolving SCAN are trained on the entire training set containing over 15,000\nexamples. We have included prompts for all the tasks in the Appendix."}, "authors": [{"name": "Denny Zhou"}, {"name": "Nathanael Sch\u00e4rli"}, {"name": "Le Hou"}, {"name": "Jason Wei"}, {"name": "Nathan Scales"}, {"name": "Xuezhi Wang"}, {"name": "Dale Schuurmans"}, {"name": "Claire Cui"}, {"name": "Olivier Bousquet"}, {"name": "Quoc Le"}, {"name": "Ed Chi"}], "author_detail": {"name": "Ed Chi"}, "author": "Ed Chi", "arxiv_comment": "ICLR 2023", "links": [{"href": "http://arxiv.org/abs/2205.10625v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2205.10625v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}