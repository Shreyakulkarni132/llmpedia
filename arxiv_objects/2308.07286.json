{"id": "http://arxiv.org/abs/2308.07286v1", "guidislink": true, "link": "http://arxiv.org/abs/2308.07286v1", "updated": "2023-08-14T17:17:21Z", "updated_parsed": [2023, 8, 14, 17, 17, 21, 0, 226, 0], "published": "2023-08-14T17:17:21Z", "published_parsed": [2023, 8, 14, 17, 17, 21, 0, 226, 0], "title": "The Devil is in the Errors: Leveraging Large Language Models for\n  Fine-grained Machine Translation Evaluation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=the+devil+is+in+the+errors++leveraging+large+language+models+for+fine+grained+machine+translation+evaluation&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "The Devil is in the Errors: Leveraging Large Language Models for\n  Fine-grained Machine Translation Evaluation"}, "summary": "Automatic evaluation of machine translation (MT) is a critical tool driving\nthe rapid iterative development of MT systems. While considerable progress has\nbeen made on estimating a single scalar quality score, current metrics lack the\ninformativeness of more detailed schemes that annotate individual errors, such\nas Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap\nby proposing AutoMQM, a prompting technique which leverages the reasoning and\nin-context learning capabilities of large language models (LLMs) and asks them\nto identify and categorize errors in translations. We start by evaluating\nrecent LLMs, such as PaLM and PaLM-2, through simple score prediction\nprompting, and we study the impact of labeled data through in-context learning\nand finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that\nit improves performance compared to just prompting for scores (with\nparticularly large gains for larger models) while providing interpretability\nthrough error spans that align with human annotations.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=the+devil+is+in+the+errors++leveraging+large+language+models+for+fine+grained+machine+translation+evaluation&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Automatic evaluation of machine translation (MT) is a critical tool driving\nthe rapid iterative development of MT systems. While considerable progress has\nbeen made on estimating a single scalar quality score, current metrics lack the\ninformativeness of more detailed schemes that annotate individual errors, such\nas Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap\nby proposing AutoMQM, a prompting technique which leverages the reasoning and\nin-context learning capabilities of large language models (LLMs) and asks them\nto identify and categorize errors in translations. We start by evaluating\nrecent LLMs, such as PaLM and PaLM-2, through simple score prediction\nprompting, and we study the impact of labeled data through in-context learning\nand finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that\nit improves performance compared to just prompting for scores (with\nparticularly large gains for larger models) while providing interpretability\nthrough error spans that align with human annotations."}, "authors": [{"name": "Patrick Fernandes"}, {"name": "Daniel Deutsch"}, {"name": "Mara Finkelstein"}, {"name": "Parker Riley"}, {"name": "Andr\u00e9 F. T. Martins"}, {"name": "Graham Neubig"}, {"name": "Ankush Garg"}, {"name": "Jonathan H. Clark"}, {"name": "Markus Freitag"}, {"name": "Orhan Firat"}], "author_detail": {"name": "Orhan Firat"}, "author": "Orhan Firat", "arxiv_comment": "19 pages", "links": [{"href": "http://arxiv.org/abs/2308.07286v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2308.07286v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}