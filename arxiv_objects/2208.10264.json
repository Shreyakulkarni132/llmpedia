{"id": "http://arxiv.org/abs/2208.10264v5", "guidislink": true, "link": "http://arxiv.org/abs/2208.10264v5", "updated": "2023-07-09T18:27:27Z", "updated_parsed": [2023, 7, 9, 18, 27, 27, 6, 190, 0], "published": "2022-08-18T17:54:49Z", "published_parsed": [2022, 8, 18, 17, 54, 49, 3, 230, 0], "title": "Using Large Language Models to Simulate Multiple Humans and Replicate\n  Human Subject Studies", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=using+large+language+models+to+simulate+multiple+humans+and+replicate+human+subject+studies&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Using Large Language Models to Simulate Multiple Humans and Replicate\n  Human Subject Studies"}, "summary": "We introduce a new type of test, called a Turing Experiment (TE), for\nevaluating to what extent a given language model, such as GPT models, can\nsimulate different aspects of human behavior. A TE can also reveal consistent\ndistortions in a language model's simulation of a specific human behavior.\nUnlike the Turing Test, which involves simulating a single arbitrary\nindividual, a TE requires simulating a representative sample of participants in\nhuman subject research. We carry out TEs that attempt to replicate\nwell-established findings from prior studies. We design a methodology for\nsimulating TEs and illustrate its use to compare how well different language\nmodels are able to reproduce classic economic, psycholinguistic, and social\npsychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock\nExperiment, and Wisdom of Crowds. In the first three TEs, the existing findings\nwere replicated using recent models, while the last TE reveals a\n\"hyper-accuracy distortion\" present in some language models (including ChatGPT\nand GPT-4), which could affect downstream applications in education and the\narts.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=using+large+language+models+to+simulate+multiple+humans+and+replicate+human+subject+studies&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "We introduce a new type of test, called a Turing Experiment (TE), for\nevaluating to what extent a given language model, such as GPT models, can\nsimulate different aspects of human behavior. A TE can also reveal consistent\ndistortions in a language model's simulation of a specific human behavior.\nUnlike the Turing Test, which involves simulating a single arbitrary\nindividual, a TE requires simulating a representative sample of participants in\nhuman subject research. We carry out TEs that attempt to replicate\nwell-established findings from prior studies. We design a methodology for\nsimulating TEs and illustrate its use to compare how well different language\nmodels are able to reproduce classic economic, psycholinguistic, and social\npsychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock\nExperiment, and Wisdom of Crowds. In the first three TEs, the existing findings\nwere replicated using recent models, while the last TE reveals a\n\"hyper-accuracy distortion\" present in some language models (including ChatGPT\nand GPT-4), which could affect downstream applications in education and the\narts."}, "authors": [{"name": "Gati Aher"}, {"name": "Rosa I. Arriaga"}, {"name": "Adam Tauman Kalai"}], "author_detail": {"name": "Adam Tauman Kalai"}, "author": "Adam Tauman Kalai", "arxiv_comment": "Accepted for oral presentation at International Conference on Machine\n  Learning (ICML) 2023", "links": [{"href": "http://arxiv.org/abs/2208.10264v5", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2208.10264v5", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}