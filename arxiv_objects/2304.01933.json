{"id": "http://arxiv.org/abs/2304.01933v2", "guidislink": true, "link": "http://arxiv.org/abs/2304.01933v2", "updated": "2023-05-08T03:41:00Z", "updated_parsed": [2023, 5, 8, 3, 41, 0, 0, 128, 0], "published": "2023-04-04T16:31:37Z", "published_parsed": [2023, 4, 4, 16, 31, 37, 1, 94, 0], "title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of\n  Large Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=llm+adapters++an+adapter+family+for+parameter+efficient+fine+tuning+of+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of\n  Large Language Models"}, "summary": "The success of large language models (LLMs), like GPT-3 and ChatGPT, has led\nto the development of numerous cost-effective and accessible alternatives that\nare created by fine-tuning open-access LLMs with task-specific data (e.g.,\nChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning\nmethods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly\none of the most attractive topics, as it only requires fine-tuning a few\nexternal parameters instead of the entire LLMs while achieving comparable or\neven better performance. To enable further research on PEFT methods of LLMs,\nthis paper presents LLM-Adapters, an easy-to-use framework that integrates\nvarious adapters into LLMs and can execute these adapter-based PEFT methods of\nLLMs for different tasks. The framework includes state-of-the-art open-access\nLLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such\nas Series adapter, Parallel adapter, and LoRA. The framework is designed to be\nresearch-friendly, efficient, modular, and extendable, allowing the integration\nof new adapters and the evaluation of them with new and larger-scale LLMs.\nFurthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we\nconduct experiments on six math reasoning datasets. The results demonstrate\nthat using adapter-based PEFT in smaller-scale LLMs (7B) with few extra\ntrainable parameters yields comparable, and in some cases superior, performance\nto that of powerful LLMs (175B) in zero-shot inference on simple math reasoning\ndatasets. Overall, we provide a promising framework for fine-tuning large LLMs\non downstream tasks. We believe the proposed LLMs-Adapters will advance\nadapter-based PEFT research, facilitate the deployment of research pipelines,\nand enable practical applications to real-world systems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=llm+adapters++an+adapter+family+for+parameter+efficient+fine+tuning+of+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "The success of large language models (LLMs), like GPT-3 and ChatGPT, has led\nto the development of numerous cost-effective and accessible alternatives that\nare created by fine-tuning open-access LLMs with task-specific data (e.g.,\nChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning\nmethods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly\none of the most attractive topics, as it only requires fine-tuning a few\nexternal parameters instead of the entire LLMs while achieving comparable or\neven better performance. To enable further research on PEFT methods of LLMs,\nthis paper presents LLM-Adapters, an easy-to-use framework that integrates\nvarious adapters into LLMs and can execute these adapter-based PEFT methods of\nLLMs for different tasks. The framework includes state-of-the-art open-access\nLLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such\nas Series adapter, Parallel adapter, and LoRA. The framework is designed to be\nresearch-friendly, efficient, modular, and extendable, allowing the integration\nof new adapters and the evaluation of them with new and larger-scale LLMs.\nFurthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we\nconduct experiments on six math reasoning datasets. The results demonstrate\nthat using adapter-based PEFT in smaller-scale LLMs (7B) with few extra\ntrainable parameters yields comparable, and in some cases superior, performance\nto that of powerful LLMs (175B) in zero-shot inference on simple math reasoning\ndatasets. Overall, we provide a promising framework for fine-tuning large LLMs\non downstream tasks. We believe the proposed LLMs-Adapters will advance\nadapter-based PEFT research, facilitate the deployment of research pipelines,\nand enable practical applications to real-world systems."}, "authors": [{"name": "Zhiqiang Hu"}, {"name": "Yihuai Lan"}, {"name": "Lei Wang"}, {"name": "Wanyu Xu"}, {"name": "Ee-Peng Lim"}, {"name": "Roy Ka-Wei Lee"}, {"name": "Lidong Bing"}, {"name": "Xing Xu"}, {"name": "Soujanya Poria"}], "author_detail": {"name": "Soujanya Poria"}, "author": "Soujanya Poria", "arxiv_comment": "Technical Report. The code of our framework can be found at\n  https://github.com/AGI-Edgerunners/LLM-Adapters. We will keep all of the code\n  open-source and continue to update the framework with new adapters, LLMs, and\n  tasks", "links": [{"href": "http://arxiv.org/abs/2304.01933v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2304.01933v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}