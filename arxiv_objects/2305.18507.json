{"id": "http://arxiv.org/abs/2305.18507v1", "guidislink": true, "link": "http://arxiv.org/abs/2305.18507v1", "updated": "2023-05-29T15:14:09Z", "updated_parsed": [2023, 5, 29, 15, 14, 9, 0, 149, 0], "published": "2023-05-29T15:14:09Z", "published_parsed": [2023, 5, 29, 15, 14, 9, 0, 149, 0], "title": "Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large\n  Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=code+prompting++a+neural+symbolic+method+for+complex+reasoning+in+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large\n  Language Models"}, "summary": "Large language models (LLMs) have scaled up to unlock a wide range of complex\nreasoning tasks with the aid of various prompting methods. However, current\nprompting methods generate natural language intermediate steps to help\nreasoning, which can cause imperfect task reduction and confusion. To mitigate\nsuch limitations, we explore code prompting, a neural symbolic prompting method\nwith both zero-shot and few-shot versions which triggers code as intermediate\nsteps. We conduct experiments on 7 widely-used benchmarks involving symbolic\nreasoning and arithmetic reasoning. Code prompting generally outperforms\nchain-of-thought (CoT) prompting. To further understand the performance and\nlimitations of code prompting, we perform extensive ablation studies and error\nanalyses, and identify several exclusive advantages of using symbolic\npromptings compared to natural language. We also consider the ensemble of code\nprompting and CoT prompting to combine the strengths of both. Finally, we show\nthrough experiments how code annotations and their locations affect code\nprompting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=code+prompting++a+neural+symbolic+method+for+complex+reasoning+in+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large language models (LLMs) have scaled up to unlock a wide range of complex\nreasoning tasks with the aid of various prompting methods. However, current\nprompting methods generate natural language intermediate steps to help\nreasoning, which can cause imperfect task reduction and confusion. To mitigate\nsuch limitations, we explore code prompting, a neural symbolic prompting method\nwith both zero-shot and few-shot versions which triggers code as intermediate\nsteps. We conduct experiments on 7 widely-used benchmarks involving symbolic\nreasoning and arithmetic reasoning. Code prompting generally outperforms\nchain-of-thought (CoT) prompting. To further understand the performance and\nlimitations of code prompting, we perform extensive ablation studies and error\nanalyses, and identify several exclusive advantages of using symbolic\npromptings compared to natural language. We also consider the ensemble of code\nprompting and CoT prompting to combine the strengths of both. Finally, we show\nthrough experiments how code annotations and their locations affect code\nprompting."}, "authors": [{"name": "Yi Hu"}, {"name": "Haotong Yang"}, {"name": "Zhouchen Lin"}, {"name": "Muhan Zhang"}], "author_detail": {"name": "Muhan Zhang"}, "author": "Muhan Zhang", "links": [{"href": "http://arxiv.org/abs/2305.18507v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2305.18507v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}