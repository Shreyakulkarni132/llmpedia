{"id": "http://arxiv.org/abs/2306.13421v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.13421v1", "updated": "2023-06-23T10:18:02Z", "updated_parsed": [2023, 6, 23, 10, 18, 2, 4, 174, 0], "published": "2023-06-23T10:18:02Z", "published_parsed": [2023, 6, 23, 10, 18, 2, 4, 174, 0], "title": "Long-range Language Modeling with Self-retrieval", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=long+range+language+modeling+with+self+retrieval&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Long-range Language Modeling with Self-retrieval"}, "summary": "Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=long+range+language+modeling+with+self+retrieval&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines."}, "authors": [{"name": "Ohad Rubin"}, {"name": "Jonathan Berant"}], "author_detail": {"name": "Jonathan Berant"}, "author": "Jonathan Berant", "links": [{"href": "http://arxiv.org/abs/2306.13421v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.13421v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}