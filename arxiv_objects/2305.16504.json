{"id": "http://arxiv.org/abs/2305.16504v1", "guidislink": true, "link": "http://arxiv.org/abs/2305.16504v1", "updated": "2023-05-25T22:10:20Z", "updated_parsed": [2023, 5, 25, 22, 10, 20, 3, 145, 0], "published": "2023-05-25T22:10:20Z", "published_parsed": [2023, 5, 25, 22, 10, 20, 3, 145, 0], "title": "On the Tool Manipulation Capability of Open-source Large Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=on+the+tool+manipulation+capability+of+open+source+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "On the Tool Manipulation Capability of Open-source Large Language Models"}, "summary": "Recent studies on software tool manipulation with large language models\n(LLMs) mostly rely on closed model APIs. The industrial adoption of these\nmodels is substantially constrained due to the security and robustness risks in\nexposing information to closed LLM API services. In this paper, we ask can we\nenhance open-source LLMs to be competitive to leading closed LLM APIs in tool\nmanipulation, with practical amount of human supervision. By analyzing common\ntool manipulation failures, we first demonstrate that open-source LLMs may\nrequire training with usage examples, in-context demonstration and generation\nstyle regulation to resolve failures. These insights motivate us to revisit\nclassical methods in LLM literature, and demonstrate that we can adapt them as\nmodel alignment with programmatic data generation, system prompts and\nin-context demonstration retrievers to enhance open-source LLMs for tool\nmanipulation. To evaluate these techniques, we create the ToolBench, a tool\nmanipulation benchmark consisting of diverse software tools for real-world\ntasks. We demonstrate that our techniques can boost leading open-source LLMs by\nup to 90% success rate, showing capabilities competitive to OpenAI GPT-4 in 4\nout of 8 ToolBench tasks. We show that such enhancement typically requires\nabout one developer day to curate data for each tool, rendering a recipe with\npractical amount of human supervision.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=on+the+tool+manipulation+capability+of+open+source+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "Recent studies on software tool manipulation with large language models\n(LLMs) mostly rely on closed model APIs. The industrial adoption of these\nmodels is substantially constrained due to the security and robustness risks in\nexposing information to closed LLM API services. In this paper, we ask can we\nenhance open-source LLMs to be competitive to leading closed LLM APIs in tool\nmanipulation, with practical amount of human supervision. By analyzing common\ntool manipulation failures, we first demonstrate that open-source LLMs may\nrequire training with usage examples, in-context demonstration and generation\nstyle regulation to resolve failures. These insights motivate us to revisit\nclassical methods in LLM literature, and demonstrate that we can adapt them as\nmodel alignment with programmatic data generation, system prompts and\nin-context demonstration retrievers to enhance open-source LLMs for tool\nmanipulation. To evaluate these techniques, we create the ToolBench, a tool\nmanipulation benchmark consisting of diverse software tools for real-world\ntasks. We demonstrate that our techniques can boost leading open-source LLMs by\nup to 90% success rate, showing capabilities competitive to OpenAI GPT-4 in 4\nout of 8 ToolBench tasks. We show that such enhancement typically requires\nabout one developer day to curate data for each tool, rendering a recipe with\npractical amount of human supervision."}, "authors": [{"name": "Qiantong Xu"}, {"name": "Fenglu Hong"}, {"name": "Bo Li"}, {"name": "Changran Hu"}, {"name": "Zhengyu Chen"}, {"name": "Jian Zhang"}], "author_detail": {"name": "Jian Zhang"}, "author": "Jian Zhang", "links": [{"href": "http://arxiv.org/abs/2305.16504v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2305.16504v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}