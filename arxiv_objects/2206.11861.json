{"id": "http://arxiv.org/abs/2206.11861v2", "guidislink": true, "link": "http://arxiv.org/abs/2206.11861v2", "updated": "2022-06-26T12:19:46Z", "updated_parsed": [2022, 6, 26, 12, 19, 46, 6, 177, 0], "published": "2022-06-03T11:00:43Z", "published_parsed": [2022, 6, 3, 11, 0, 43, 4, 154, 0], "title": "Automatic Generation of Programming Exercises and Code Explanations\n  using Large Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=automatic+generation+of+programming+exercises+and+code+explanations+using+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Automatic Generation of Programming Exercises and Code Explanations\n  using Large Language Models"}, "summary": "This article explores the natural language generation capabilities of large\nlanguage models with application to the production of two types of learning\nresources common in programming courses. Using OpenAI Codex as the large\nlanguage model, we create programming exercises (including sample solutions and\ntest cases) and code explanations, assessing these qualitatively and\nquantitatively. Our results suggest that the majority of the automatically\ngenerated content is both novel and sensible, and in some cases ready to use as\nis. When creating exercises we find that it is remarkably easy to influence\nboth the programming concepts and the contextual themes they contain, simply by\nsupplying keywords as input to the model. Our analysis suggests that there is\nsignificant value in massive generative machine learning models as a tool for\ninstructors, although there remains a need for some oversight to ensure the\nquality of the generated content before it is delivered to students. We further\ndiscuss the implications of OpenAI Codex and similar tools for introductory\nprogramming education and highlight future research streams that have the\npotential to improve the quality of the educational experience for both\nteachers and students alike.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=automatic+generation+of+programming+exercises+and+code+explanations+using+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "This article explores the natural language generation capabilities of large\nlanguage models with application to the production of two types of learning\nresources common in programming courses. Using OpenAI Codex as the large\nlanguage model, we create programming exercises (including sample solutions and\ntest cases) and code explanations, assessing these qualitatively and\nquantitatively. Our results suggest that the majority of the automatically\ngenerated content is both novel and sensible, and in some cases ready to use as\nis. When creating exercises we find that it is remarkably easy to influence\nboth the programming concepts and the contextual themes they contain, simply by\nsupplying keywords as input to the model. Our analysis suggests that there is\nsignificant value in massive generative machine learning models as a tool for\ninstructors, although there remains a need for some oversight to ensure the\nquality of the generated content before it is delivered to students. We further\ndiscuss the implications of OpenAI Codex and similar tools for introductory\nprogramming education and highlight future research streams that have the\npotential to improve the quality of the educational experience for both\nteachers and students alike."}, "authors": [{"name": "Sami Sarsa"}, {"name": "Paul Denny"}, {"name": "Arto Hellas"}, {"name": "Juho Leinonen"}], "author_detail": {"name": "Juho Leinonen"}, "author": "Juho Leinonen", "arxiv_doi": "10.1145/3501385.3543957", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1145/3501385.3543957", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2206.11861v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.11861v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "18 pages, 1 figure, accepted in ICER", "arxiv_primary_category": {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}