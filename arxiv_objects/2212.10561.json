{"id": "http://arxiv.org/abs/2212.10561v3", "guidislink": true, "link": "http://arxiv.org/abs/2212.10561v3", "updated": "2023-05-28T21:12:31Z", "updated_parsed": [2023, 5, 28, 21, 12, 31, 6, 148, 0], "published": "2022-12-20T18:59:23Z", "published_parsed": [2022, 12, 20, 18, 59, 23, 1, 354, 0], "title": "Parsel: Algorithmic Reasoning with Language Models by Composing\n  Decompositions", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=parsel++algorithmic+reasoning+with+language+models+by+composing+decompositions&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Parsel: Algorithmic Reasoning with Language Models by Composing\n  Decompositions"}, "summary": "Despite recent success in large language model (LLM) reasoning, LLMs struggle\nwith hierarchical multi-step reasoning tasks like generating complex programs.\nFor these tasks, humans often start with a high-level algorithmic design and\nimplement each part gradually. We introduce Parsel, a framework enabling\nautomatic implementation and validation of complex algorithms with code LLMs.\nWith Parsel, we automatically decompose algorithmic tasks into hierarchical\nnatural language function descriptions and then search over combinations of\npossible function implementations using tests. We show that Parsel can be used\nacross domains requiring hierarchical reasoning, including program synthesis\nand robotic planning. We find that, using Parsel, LLMs solve more\ncompetition-level problems in the APPS dataset, resulting in pass rates over\n75\\% higher than prior results from directly sampling AlphaCode and Codex,\nwhile often using a smaller sample budget. Moreover, with automatically\ngenerated tests, we find that Parsel can improve the state-of-the-art pass@1\nperformance on HumanEval from 67\\% to 85\\%. We also find that LLM-generated\nrobotic plans using Parsel are more than twice as likely to be considered\naccurate than directly generated plans. Lastly, we explore how Parsel addresses\nLLM limitations and discuss how Parsel may be useful for human programmers. We\nrelease our code at https://github.com/ezelikman/parsel", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=parsel++algorithmic+reasoning+with+language+models+by+composing+decompositions&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Despite recent success in large language model (LLM) reasoning, LLMs struggle\nwith hierarchical multi-step reasoning tasks like generating complex programs.\nFor these tasks, humans often start with a high-level algorithmic design and\nimplement each part gradually. We introduce Parsel, a framework enabling\nautomatic implementation and validation of complex algorithms with code LLMs.\nWith Parsel, we automatically decompose algorithmic tasks into hierarchical\nnatural language function descriptions and then search over combinations of\npossible function implementations using tests. We show that Parsel can be used\nacross domains requiring hierarchical reasoning, including program synthesis\nand robotic planning. We find that, using Parsel, LLMs solve more\ncompetition-level problems in the APPS dataset, resulting in pass rates over\n75\\% higher than prior results from directly sampling AlphaCode and Codex,\nwhile often using a smaller sample budget. Moreover, with automatically\ngenerated tests, we find that Parsel can improve the state-of-the-art pass@1\nperformance on HumanEval from 67\\% to 85\\%. We also find that LLM-generated\nrobotic plans using Parsel are more than twice as likely to be considered\naccurate than directly generated plans. Lastly, we explore how Parsel addresses\nLLM limitations and discuss how Parsel may be useful for human programmers. We\nrelease our code at https://github.com/ezelikman/parsel"}, "authors": [{"name": "Eric Zelikman"}, {"name": "Qian Huang"}, {"name": "Gabriel Poesia"}, {"name": "Noah D. Goodman"}, {"name": "Nick Haber"}], "author_detail": {"name": "Nick Haber"}, "author": "Nick Haber", "arxiv_comment": "humaneval results, clarity", "links": [{"href": "http://arxiv.org/abs/2212.10561v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2212.10561v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}