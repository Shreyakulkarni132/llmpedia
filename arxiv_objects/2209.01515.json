{"id": "http://arxiv.org/abs/2209.01515v3", "guidislink": true, "link": "http://arxiv.org/abs/2209.01515v3", "updated": "2023-06-01T02:36:32Z", "updated_parsed": [2023, 6, 1, 2, 36, 32, 3, 152, 0], "published": "2022-09-04T01:29:53Z", "published_parsed": [2022, 9, 4, 1, 29, 53, 6, 247, 0], "title": "Do Large Language Models know what humans know?", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=do+large+language+models+know+what+humans+know+&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Do Large Language Models know what humans know?"}, "summary": "Humans can attribute beliefs to others. However, it is unknown to what extent\nthis ability results from an innate biological endowment or from experience\naccrued through child development, particularly exposure to language describing\nothers' mental states. We test the viability of the language exposure\nhypothesis by assessing whether models exposed to large quantities of human\nlanguage display sensitivity to the implied knowledge states of characters in\nwritten passages. In pre-registered analyses, we present a linguistic version\nof the False Belief Task to both human participants and a Large Language Model,\nGPT-3. Both are sensitive to others' beliefs, but while the language model\nsignificantly exceeds chance behavior, it does not perform as well as the\nhumans, nor does it explain the full extent of their behavior -- despite being\nexposed to more language than a human would in a lifetime. This suggests that\nwhile statistical learning from language exposure may in part explain how\nhumans develop the ability to reason about the mental states of others, other\nmechanisms are also responsible.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=do+large+language+models+know+what+humans+know+&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Humans can attribute beliefs to others. However, it is unknown to what extent\nthis ability results from an innate biological endowment or from experience\naccrued through child development, particularly exposure to language describing\nothers' mental states. We test the viability of the language exposure\nhypothesis by assessing whether models exposed to large quantities of human\nlanguage display sensitivity to the implied knowledge states of characters in\nwritten passages. In pre-registered analyses, we present a linguistic version\nof the False Belief Task to both human participants and a Large Language Model,\nGPT-3. Both are sensitive to others' beliefs, but while the language model\nsignificantly exceeds chance behavior, it does not perform as well as the\nhumans, nor does it explain the full extent of their behavior -- despite being\nexposed to more language than a human would in a lifetime. This suggests that\nwhile statistical learning from language exposure may in part explain how\nhumans develop the ability to reason about the mental states of others, other\nmechanisms are also responsible."}, "authors": [{"name": "Sean Trott"}, {"name": "Cameron Jones"}, {"name": "Tyler Chang"}, {"name": "James Michaelov"}, {"name": "Benjamin Bergen"}], "author_detail": {"name": "Benjamin Bergen"}, "author": "Benjamin Bergen", "links": [{"href": "http://arxiv.org/abs/2209.01515v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2209.01515v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}