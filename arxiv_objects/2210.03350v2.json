{"id": "http://arxiv.org/abs/2210.03350v2", "guidislink": true, "link": "http://arxiv.org/abs/2210.03350v2", "updated": "2023-05-23T00:57:12Z", "updated_parsed": [2023, 5, 23, 0, 57, 12, 1, 143, 0], "published": "2022-10-07T06:50:23Z", "published_parsed": [2022, 10, 7, 6, 50, 23, 4, 280, 0], "title": "Measuring and Narrowing the Compositionality Gap in Language Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=measuring+and+narrowing+the+compositionality+gap+in+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Measuring and Narrowing the Compositionality Gap in Language Models"}, "summary": "We investigate the ability of language models to perform compositional\nreasoning tasks where the overall solution depends on correctly composing the\nanswers to sub-problems. We measure how often models can correctly answer all\nsub-problems but not generate the overall solution, a ratio we call the\ncompositionality gap. We evaluate this ratio by asking multi-hop questions with\nanswers that require composing multiple facts unlikely to have been observed\ntogether during pretraining. In the GPT-3 family of models, as model size\nincreases we show that the single-hop question answering performance improves\nfaster than the multi-hop performance does, therefore the compositionality gap\ndoes not decrease. This surprising result suggests that while more powerful\nmodels memorize and recall more factual knowledge, they show no corresponding\nimprovement in their ability to perform this kind of compositional reasoning.\n  We then demonstrate how elicitive prompting (such as chain of thought)\nnarrows the compositionality gap by reasoning explicitly instead of implicitly.\nWe present a new method, self-ask, that further improves on chain of thought.\nIn our method, the model explicitly asks itself (and then answers) follow-up\nquestions before answering the initial question. We finally show that\nself-ask's structured prompting lets us easily plug in a search engine to\nanswer the follow-up questions, which additionally improves accuracy.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=measuring+and+narrowing+the+compositionality+gap+in+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "We investigate the ability of language models to perform compositional\nreasoning tasks where the overall solution depends on correctly composing the\nanswers to sub-problems. We measure how often models can correctly answer all\nsub-problems but not generate the overall solution, a ratio we call the\ncompositionality gap. We evaluate this ratio by asking multi-hop questions with\nanswers that require composing multiple facts unlikely to have been observed\ntogether during pretraining. In the GPT-3 family of models, as model size\nincreases we show that the single-hop question answering performance improves\nfaster than the multi-hop performance does, therefore the compositionality gap\ndoes not decrease. This surprising result suggests that while more powerful\nmodels memorize and recall more factual knowledge, they show no corresponding\nimprovement in their ability to perform this kind of compositional reasoning.\n  We then demonstrate how elicitive prompting (such as chain of thought)\nnarrows the compositionality gap by reasoning explicitly instead of implicitly.\nWe present a new method, self-ask, that further improves on chain of thought.\nIn our method, the model explicitly asks itself (and then answers) follow-up\nquestions before answering the initial question. We finally show that\nself-ask's structured prompting lets us easily plug in a search engine to\nanswer the follow-up questions, which additionally improves accuracy."}, "authors": [{"name": "Ofir Press"}, {"name": "Muru Zhang"}, {"name": "Sewon Min"}, {"name": "Ludwig Schmidt"}, {"name": "Noah A. Smith"}, {"name": "Mike Lewis"}], "author_detail": {"name": "Mike Lewis"}, "author": "Mike Lewis", "links": [{"href": "http://arxiv.org/abs/2210.03350v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2210.03350v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}