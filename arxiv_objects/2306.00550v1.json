{"id": "http://arxiv.org/abs/2306.00550v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.00550v1", "updated": "2023-06-01T11:11:39Z", "updated_parsed": [2023, 6, 1, 11, 11, 39, 3, 152, 0], "published": "2023-06-01T11:11:39Z", "published_parsed": [2023, 6, 1, 11, 11, 39, 3, 152, 0], "title": "Chain-Of-Thought Prompting Under Streaming Batch: A Case Study", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=chain+of+thought+prompting+under+streaming+batch++a+case+study&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Chain-Of-Thought Prompting Under Streaming Batch: A Case Study"}, "summary": "Recently, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities. Chain-of-Thought (CoT) has been proposed as a way of assisting\nLLMs in performing complex reasoning. However, developing effective prompts can\nbe a challenging and labor-intensive task. Many studies come out of some way to\nautomatically construct CoT from test data. Most of them assume that all test\ndata is visible before testing and only select a small subset to generate\nrationales, which is an unrealistic assumption. In this paper, we present a\ncase study on how to construct and optimize chain-of-thought prompting using\nbatch data in streaming settings.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=chain+of+thought+prompting+under+streaming+batch++a+case+study&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Recently, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities. Chain-of-Thought (CoT) has been proposed as a way of assisting\nLLMs in performing complex reasoning. However, developing effective prompts can\nbe a challenging and labor-intensive task. Many studies come out of some way to\nautomatically construct CoT from test data. Most of them assume that all test\ndata is visible before testing and only select a small subset to generate\nrationales, which is an unrealistic assumption. In this paper, we present a\ncase study on how to construct and optimize chain-of-thought prompting using\nbatch data in streaming settings."}, "authors": [{"name": "Yuxin Tang"}], "author_detail": {"name": "Yuxin Tang"}, "author": "Yuxin Tang", "links": [{"href": "http://arxiv.org/abs/2306.00550v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.00550v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}