{"id": "http://arxiv.org/abs/2202.03371v1", "guidislink": true, "link": "http://arxiv.org/abs/2202.03371v1", "updated": "2022-02-07T17:40:43Z", "updated_parsed": [2022, 2, 7, 17, 40, 43, 0, 38, 0], "published": "2022-02-07T17:40:43Z", "published_parsed": [2022, 2, 7, 17, 40, 43, 0, 38, 0], "title": "Cedille: A large autoregressive French language model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=cedille++a+large+autoregressive+french+language+model&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Cedille: A large autoregressive French language model"}, "summary": "Scaling up the size and training of autoregressive language models has\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\nmultilingual capabilities, zero-shot learning for languages other than English\nremain largely unexplored. Here, we introduce Cedille, a large open source\nauto-regressive language model, specifically trained for the French language.\nOur results show that Cedille outperforms existing French language models and\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\nthese models, showing that Cedille marks an improvement in language model\nsafety thanks to dataset filtering.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=cedille++a+large+autoregressive+french+language+model&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Scaling up the size and training of autoregressive language models has\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\nmultilingual capabilities, zero-shot learning for languages other than English\nremain largely unexplored. Here, we introduce Cedille, a large open source\nauto-regressive language model, specifically trained for the French language.\nOur results show that Cedille outperforms existing French language models and\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\nthese models, showing that Cedille marks an improvement in language model\nsafety thanks to dataset filtering."}, "authors": [{"name": "Martin M\u00fcller"}, {"name": "Florian Laurent"}], "author_detail": {"name": "Florian Laurent"}, "author": "Florian Laurent", "arxiv_comment": "8 pages, 1 figure, 7 tables", "links": [{"href": "http://arxiv.org/abs/2202.03371v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2202.03371v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T50", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}