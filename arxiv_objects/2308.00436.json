{"id": "http://arxiv.org/abs/2308.00436v2", "guidislink": true, "link": "http://arxiv.org/abs/2308.00436v2", "updated": "2023-08-02T08:45:40Z", "updated_parsed": [2023, 8, 2, 8, 45, 40, 2, 214, 0], "published": "2023-08-01T10:31:36Z", "published_parsed": [2023, 8, 1, 10, 31, 36, 1, 213, 0], "title": "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step\n  Reasoning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=selfcheck++using+llms+to+zero+shot+check+their+own+step+by+step+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step\n  Reasoning"}, "summary": "The recent progress in large language models (LLMs), especially the invention\nof chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning\nproblems. However, even the strongest LLMs are still struggling with more\ncomplicated problems that require non-linear thinking and multi-step reasoning.\nIn this work, we explore whether LLMs have the ability to recognize their own\nerrors, without resorting to external resources. In particular, we investigate\nwhether they can be used to identify individual errors within a step-by-step\nreasoning. To this end, we propose a zero-shot verification scheme to recognize\nsuch errors. We then use this verification scheme to improve question-answering\nperformance, by using it to perform weighted voting on different generated\nanswers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and\nfind that it successfully recognizes errors and, in turn, increases final\npredictive performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=selfcheck++using+llms+to+zero+shot+check+their+own+step+by+step+reasoning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=40", "value": "The recent progress in large language models (LLMs), especially the invention\nof chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning\nproblems. However, even the strongest LLMs are still struggling with more\ncomplicated problems that require non-linear thinking and multi-step reasoning.\nIn this work, we explore whether LLMs have the ability to recognize their own\nerrors, without resorting to external resources. In particular, we investigate\nwhether they can be used to identify individual errors within a step-by-step\nreasoning. To this end, we propose a zero-shot verification scheme to recognize\nsuch errors. We then use this verification scheme to improve question-answering\nperformance, by using it to perform weighted voting on different generated\nanswers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and\nfind that it successfully recognizes errors and, in turn, increases final\npredictive performance."}, "authors": [{"name": "Ning Miao"}, {"name": "Yee Whye Teh"}, {"name": "Tom Rainforth"}], "author_detail": {"name": "Tom Rainforth"}, "author": "Tom Rainforth", "links": [{"href": "http://arxiv.org/abs/2308.00436v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2308.00436v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}