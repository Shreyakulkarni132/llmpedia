{"id": "http://arxiv.org/abs/2305.09993v1", "guidislink": true, "link": "http://arxiv.org/abs/2305.09993v1", "updated": "2023-05-17T06:35:43Z", "updated_parsed": [2023, 5, 17, 6, 35, 43, 2, 137, 0], "published": "2023-05-17T06:35:43Z", "published_parsed": [2023, 5, 17, 6, 35, 43, 2, 137, 0], "title": "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs\n  Sampling", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=reprompting++automated+chain+of+thought+prompt+inference+through+gibbs+sampling&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs\n  Sampling"}, "summary": "We introduce Reprompting, an iterative sampling algorithm that searches for\nthe Chain-of-Thought (CoT) recipes for a given task without human intervention.\nThrough Gibbs sampling, we infer CoT recipes that work consistently well for a\nset of training samples. Our method iteratively samples new recipes using\npreviously sampled solutions as parent prompts to solve other training\nproblems. On five Big-Bench Hard tasks that require multi-step reasoning,\nReprompting achieves consistently better performance than the zero-shot,\nfew-shot, and human-written CoT baselines. Reprompting can also facilitate\ntransfer of knowledge from a stronger model to a weaker model leading to\nsubstantially improved performance of the weaker model. Overall, Reprompting\nbrings up to +17 point improvements over the previous state-of-the-art method\nthat uses human-written CoT prompts.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=reprompting++automated+chain+of+thought+prompt+inference+through+gibbs+sampling&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "We introduce Reprompting, an iterative sampling algorithm that searches for\nthe Chain-of-Thought (CoT) recipes for a given task without human intervention.\nThrough Gibbs sampling, we infer CoT recipes that work consistently well for a\nset of training samples. Our method iteratively samples new recipes using\npreviously sampled solutions as parent prompts to solve other training\nproblems. On five Big-Bench Hard tasks that require multi-step reasoning,\nReprompting achieves consistently better performance than the zero-shot,\nfew-shot, and human-written CoT baselines. Reprompting can also facilitate\ntransfer of knowledge from a stronger model to a weaker model leading to\nsubstantially improved performance of the weaker model. Overall, Reprompting\nbrings up to +17 point improvements over the previous state-of-the-art method\nthat uses human-written CoT prompts."}, "authors": [{"name": "Weijia Xu"}, {"name": "Andrzej Banburski-Fahey"}, {"name": "Nebojsa Jojic"}], "author_detail": {"name": "Nebojsa Jojic"}, "author": "Nebojsa Jojic", "links": [{"href": "http://arxiv.org/abs/2305.09993v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2305.09993v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}