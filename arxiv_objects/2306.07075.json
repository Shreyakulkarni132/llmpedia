{"id": "http://arxiv.org/abs/2306.07075v1", "guidislink": true, "link": "http://arxiv.org/abs/2306.07075v1", "updated": "2023-06-12T12:40:48Z", "updated_parsed": [2023, 6, 12, 12, 40, 48, 0, 163, 0], "published": "2023-06-12T12:40:48Z", "published_parsed": [2023, 6, 12, 12, 40, 48, 0, 163, 0], "title": "Large Language Models as Tax Attorneys: A Case Study in Legal\n  Capabilities Emergence", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+as+tax+attorneys++a+case+study+in+legal+capabilities+emergence&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large Language Models as Tax Attorneys: A Case Study in Legal\n  Capabilities Emergence"}, "summary": "Better understanding of Large Language Models' (LLMs) legal analysis\nabilities can contribute to improving the efficiency of legal services,\ngoverning artificial intelligence, and leveraging LLMs to identify\ninconsistencies in law. This paper explores LLM capabilities in applying tax\nlaw. We choose this area of law because it has a structure that allows us to\nset up automated validation pipelines across thousands of examples, requires\nlogical reasoning and maths skills, and enables us to test LLM capabilities in\na manner relevant to real-world economic lives of citizens and companies. Our\nexperiments demonstrate emerging legal understanding capabilities, with\nimproved performance in each subsequent OpenAI model release. We experiment\nwith retrieving and utilising the relevant legal authority to assess the impact\nof providing additional legal context to LLMs. Few-shot prompting, presenting\nexamples of question-answer pairs, is also found to significantly enhance the\nperformance of the most advanced model, GPT-4. The findings indicate that LLMs,\nparticularly when combined with prompting enhancements and the correct legal\ntexts, can perform at high levels of accuracy but not yet at expert tax lawyer\nlevels. As LLMs continue to advance, their ability to reason about law\nautonomously could have significant implications for the legal profession and\nAI governance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=large+language+models+as+tax+attorneys++a+case+study+in+legal+capabilities+emergence&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Better understanding of Large Language Models' (LLMs) legal analysis\nabilities can contribute to improving the efficiency of legal services,\ngoverning artificial intelligence, and leveraging LLMs to identify\ninconsistencies in law. This paper explores LLM capabilities in applying tax\nlaw. We choose this area of law because it has a structure that allows us to\nset up automated validation pipelines across thousands of examples, requires\nlogical reasoning and maths skills, and enables us to test LLM capabilities in\na manner relevant to real-world economic lives of citizens and companies. Our\nexperiments demonstrate emerging legal understanding capabilities, with\nimproved performance in each subsequent OpenAI model release. We experiment\nwith retrieving and utilising the relevant legal authority to assess the impact\nof providing additional legal context to LLMs. Few-shot prompting, presenting\nexamples of question-answer pairs, is also found to significantly enhance the\nperformance of the most advanced model, GPT-4. The findings indicate that LLMs,\nparticularly when combined with prompting enhancements and the correct legal\ntexts, can perform at high levels of accuracy but not yet at expert tax lawyer\nlevels. As LLMs continue to advance, their ability to reason about law\nautonomously could have significant implications for the legal profession and\nAI governance."}, "authors": [{"name": "John J. Nay"}, {"name": "David Karamardian"}, {"name": "Sarah B. Lawsky"}, {"name": "Wenting Tao"}, {"name": "Meghana Bhat"}, {"name": "Raghav Jain"}, {"name": "Aaron Travis Lee"}, {"name": "Jonathan H. Choi"}, {"name": "Jungo Kasai"}], "author_detail": {"name": "Jungo Kasai"}, "author": "Jungo Kasai", "links": [{"href": "http://arxiv.org/abs/2306.07075v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2306.07075v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CY", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}