{"id": "http://arxiv.org/abs/2307.14936v1", "guidislink": true, "link": "http://arxiv.org/abs/2307.14936v1", "updated": "2023-07-27T15:28:29Z", "updated_parsed": [2023, 7, 27, 15, 28, 29, 3, 208, 0], "published": "2023-07-27T15:28:29Z", "published_parsed": [2023, 7, 27, 15, 28, 29, 3, 208, 0], "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking\n  Feedback", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=pangu+coder2++boosting+large+language+models+for+code+with+ranking+feedback&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking\n  Feedback"}, "summary": "Large Language Models for Code (Code LLM) are flourishing. New and powerful\nmodels are released on a weekly basis, demonstrating remarkable performance on\nthe code generation task. Various approaches have been proposed to boost the\ncode generation performance of pre-trained Code LLMs, such as supervised\nfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we\npropose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework,\nwhich can effectively and efficiently boost pre-trained large language models\nfor code generation. Under this framework, we present PanGu-Coder2, which\nachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through\nan extensive evaluation on CoderEval and LeetCode benchmarks, we show that\nPanGu-Coder2 consistently outperforms all previous Code LLMs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=pangu+coder2++boosting+large+language+models+for+code+with+ranking+feedback&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=20", "value": "Large Language Models for Code (Code LLM) are flourishing. New and powerful\nmodels are released on a weekly basis, demonstrating remarkable performance on\nthe code generation task. Various approaches have been proposed to boost the\ncode generation performance of pre-trained Code LLMs, such as supervised\nfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we\npropose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework,\nwhich can effectively and efficiently boost pre-trained large language models\nfor code generation. Under this framework, we present PanGu-Coder2, which\nachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through\nan extensive evaluation on CoderEval and LeetCode benchmarks, we show that\nPanGu-Coder2 consistently outperforms all previous Code LLMs."}, "authors": [{"name": "Bo Shen"}, {"name": "Jiaxin Zhang"}, {"name": "Taihong Chen"}, {"name": "Daoguang Zan"}, {"name": "Bing Geng"}, {"name": "An Fu"}, {"name": "Muhan Zeng"}, {"name": "Ailun Yu"}, {"name": "Jichuan Ji"}, {"name": "Jingyang Zhao"}, {"name": "Yuenan Guo"}, {"name": "Qianxiang Wang"}], "author_detail": {"name": "Qianxiang Wang"}, "author": "Qianxiang Wang", "arxiv_comment": "Preprint", "links": [{"href": "http://arxiv.org/abs/2307.14936v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2307.14936v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}