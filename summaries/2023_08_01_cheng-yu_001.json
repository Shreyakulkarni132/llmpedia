{"Published": "2023-08-01", "Title": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models", "Authors": "Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister", "Summary": "Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage. Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen. Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide. As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable. Our work provides an alternative to demonstrations: tool documentation. We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations. We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities. First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts. Second, on a newly collected realistic tool-use dataset with hundreds of available tool APIs, we show that tool documentation is significantly more valuable than demonstrations, with zero-shot documentation significantly outperforming few-shot without documentation. Third, we highlight the benefits of tool documentations by tackling image generation and video tracking using just-released unseen state-of-the-art models as tools. Finally, we highlight the possibility of using tool documentation to automatically enable new applications: by using nothing more than the documentation of GroundingDino, Stable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the just-released Grounded-SAM and Track Anything models.", "main_contribution": {"headline": "Tool Documentation Outperforms Demonstrations for Teaching LLMs New Tools", "description": "The paper presents a novel approach to teaching Large Language Models (LLMs) how to use new tools, advocating for the use of tool documentation over demonstrations. The authors argue that demonstrations are hard to acquire and can lead to biased usage if the wrong demonstration is chosen. In contrast, tool documentation, which provides descriptions of individual tool usage, is shown to be more effective. The authors substantiate their claim with empirical findings across six tasks in both vision and language modalities, showing that zero-shot prompts with only tool documentation can elicit proper tool usage and achieve performance on par with few-shot prompts."}, "takeaways": {"headline": "Tool Documentation Can Enable Zero-Shot Learning and New Applications for LLMs", "description": "The paper's findings suggest that tool documentation can be a powerful resource for teaching LLMs how to use new tools, potentially enabling zero-shot learning and the development of new applications. By using tool documentation, LLMs can understand and apply the functionalities of new tools without needing demonstrations. This approach could significantly streamline the process of integrating new tools into LLM systems and open up new possibilities for their application.", "example": "For instance, given the documentation of a new tool, an LLM could be trained to understand its functionalities and apply it to relevant tasks. This could be done by feeding the LLM the tool documentation as input and then prompting it to generate a description of how the tool could be used in a specific context."}, "category": "TRAINING", "novelty_analysis": "The paper presents a novel approach to teaching LLMs how to use new tools, shifting the focus from demonstrations to tool documentation. This represents a significant departure from traditional methods and could have far-reaching implications for how LLMs are trained and used.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, discussing the methodology and empirical findings of the authors' research. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a basic understanding of LLMs and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an interesting and novel approach to teaching LLMs. The empirical findings are compelling and the potential implications of the research are exciting, making the paper an enjoyable read for those interested in LLMs and machine learning.", "enjoyable_score": 3}