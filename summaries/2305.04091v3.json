{"Published": "2023-05-26", "Title": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models", "Authors": "Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng Lim", "Summary": "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with \"Let's think step by step\" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting. We evaluate our proposed prompting strategy on ten datasets across three reasoning problems. The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought Prompting, and has comparable performance with 8-shot CoT prompting on the math reasoning problem. The code can be found at https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.", "main_contribution": {"headline": "Plan-and-Solve (PS) Prompting improves zero-shot reasoning in LLMs", "description": "The paper introduces Plan-and-Solve (PS) Prompting, a novel method to enhance the reasoning capabilities of Large Language Models (LLMs) in zero-shot scenarios. PS Prompting addresses the issue of missing-step errors in reasoning tasks by dividing the entire task into smaller subtasks and then executing them according to a devised plan. To further improve the quality of generated reasoning steps and address calculation errors, the authors extend PS prompting to PS+ prompting, which provides more detailed instructions. The proposed method consistently outperforms Zero-shot-CoT prompting across all datasets and shows comparable performance with 8-shot CoT prompting on math reasoning problems."}, "takeaways": {"headline": "PS Prompting offers a structured approach to improve LLM reasoning", "description": "The Plan-and-Solve (PS) Prompting technique provides a structured approach to improve the reasoning capabilities of LLMs, especially in zero-shot scenarios. By dividing complex tasks into smaller subtasks and providing detailed instructions, PS Prompting can significantly enhance the accuracy of LLMs in reasoning tasks. This method can be particularly useful in applications where LLMs are required to perform complex reasoning tasks, such as in decision-making systems, problem-solving applications, or advanced chatbots.", "example": "For instance, in a chatbot application, PS Prompting can be used to improve the bot's ability to understand and respond to complex user queries. A query like 'What are the steps to bake a cake?' can be divided into smaller subtasks like 'Gather ingredients', 'Preheat the oven', 'Mix ingredients', etc., and the bot can then provide detailed instructions for each subtask."}, "category": "PROMPTING", "novelty_analysis": "The introduction of Plan-and-Solve (PS) Prompting represents a significant advancement in the field of LLM prompting techniques. The method's ability to improve the reasoning capabilities of LLMs in zero-shot scenarios by dividing tasks into smaller subtasks and providing detailed instructions is a novel approach.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it introduces a new prompting technique and discusses its implementation in detail. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a basic understanding of LLMs and prompting techniques.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel and intriguing contribution to the field of LLM prompting techniques. The practical implications of the proposed method and its potential to improve the reasoning capabilities of LLMs make the paper an interesting read.", "enjoyable_score": 3}