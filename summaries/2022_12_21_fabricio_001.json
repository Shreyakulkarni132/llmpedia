{"Published": "2022-12-21", "Title": "Crowd Score: A Method for the Evaluation of Jokes using Large Language Model AI Voters as Judges", "Authors": "Fabricio Goes, Zisen Zhou, Piotr Sawicki, Marek Grzes, Daniel G. Brown", "Summary": "This paper presents the Crowd Score, a novel method to assess the funniness of jokes using large language models (LLMs) as AI judges. Our method relies on inducing different personalities into the LLM and aggregating the votes of the AI judges into a single score to rate jokes. We validate the votes using an auditing technique that checks if the explanation for a particular vote is reasonable using the LLM. We tested our methodology on 52 jokes in a crowd of four AI voters with different humour types: affiliative, self-enhancing, aggressive and self-defeating. Our results show that few-shot prompting leads to better results than zero-shot for the voting question. Personality induction showed that aggressive and self-defeating voters are significantly more inclined to find more jokes funny of a set of aggressive/self-defeating jokes than the affiliative and self-enhancing voters. The Crowd Score follows the same trend as human judges by assigning higher scores to jokes that are also considered funnier by human judges. We believe that our methodology could be applied to other creative domains such as story, poetry, slogans, etc. It could both help the adoption of a flexible and accurate standard approach to compare different work in the CC community under a common metric and by minimizing human participation in assessing creative artefacts, it could accelerate the prototyping of creative artefacts and reduce the cost of hiring human participants to rate creative artefacts.", "main_contribution": {"headline": "Crowd Score: A Novel Method for Evaluating Jokes Using AI Judges", "description": "The paper introduces Crowd Score, a unique method for assessing the funniness of jokes using large language models (LLMs) as AI judges. The authors induce different personalities into the LLM and aggregate the votes of the AI judges into a single score to rate jokes. The votes are validated using an auditing technique that checks if the explanation for a particular vote is reasonable using the LLM. The methodology was tested on 52 jokes with four AI voters having different humour types: affiliative, self-enhancing, aggressive, and self-defeating. The results showed that few-shot prompting leads to better results than zero-shot for the voting question."}, "takeaways": {"headline": "Crowd Score Methodology Offers a New Approach to Evaluating Creative Content", "description": "The Crowd Score methodology presents a novel way of using LLMs to evaluate creative content, in this case, jokes. By inducing different personalities into the LLM and using an auditing technique to validate the votes, the authors demonstrate a unique approach to using AI for content evaluation. This methodology could be applied to other creative domains such as story, poetry, slogans, etc., potentially reducing the cost of hiring human participants to rate creative artefacts and accelerating the prototyping of creative artefacts.", "example": "For instance, to evaluate a set of poems, one could induce different literary tastes into the LLM (e.g., romantic, modernist, postmodernist, etc.) and use the Crowd Score methodology to aggregate the AI judges' votes into a single score for each poem."}, "category": "USE CASES", "novelty_analysis": "The Crowd Score methodology is a novel approach to using LLMs for content evaluation. The idea of inducing different personalities into the LLM and using an auditing technique to validate the votes is a unique contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, discussing the methodology of inducing different personalities into the LLM and using an auditing technique to validate the votes. However, it does not delve into complex mathematical theories or algorithms, making it accessible to a wider audience.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents a novel and intriguing contribution to the field of LLMs. The idea of using AI to evaluate jokes is both interesting and entertaining, making the paper an enjoyable read.", "enjoyable_score": 3}