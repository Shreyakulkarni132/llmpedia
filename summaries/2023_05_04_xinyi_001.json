{"Published": "2023-05-04", "Title": "Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning", "Authors": "Xinyi Wang, Wanrong Zhu, Michael Saxon, Mark Steyvers, William Yang Wang", "Summary": "In recent years, pre-trained large language models have demonstrated remarkable efficiency in achieving an inference-time few-shot learning capability known as in-context learning. However, existing literature has highlighted the sensitivity of this capability to the selection of few-shot demonstrations. The underlying mechanisms by which this capability arises from regular language model pretraining objectives remain poorly understood. In this study, we aim to examine the in-context learning phenomenon through a Bayesian lens, viewing large language models as topic models that implicitly infer task-related information from demonstrations. On this premise, we propose an algorithm for selecting optimal demonstrations from a set of annotated data and demonstrate a significant 12.5% improvement relative to the random selection baseline, averaged over eight GPT2 and GPT3 models on eight different real-world text classification datasets. Our empirical findings support our hypothesis that large language models implicitly infer a latent concept variable.", "main_contribution": {"headline": "Large Language Models as Implicit Topic Models for Optimal Demonstration Selection", "description": "The paper presents a novel perspective on Large Language Models (LLMs), viewing them as implicit topic models that infer task-related information from demonstrations. The authors propose an algorithm for selecting optimal demonstrations from a set of annotated data. This approach significantly improves the performance of in-context learning, a few-shot learning capability of LLMs, by 12.5% compared to random selection. The study provides empirical evidence supporting the hypothesis that LLMs implicitly infer a latent concept variable, contributing to our understanding of the mechanisms underlying in-context learning."}, "takeaways": {"headline": "Optimal demonstration selection can significantly improve LLM performance", "description": "The paper's findings suggest that the selection of demonstrations can significantly impact the performance of LLMs in in-context learning. The proposed algorithm for optimal demonstration selection can be used to enhance the efficiency of LLMs in real-world text classification tasks. This approach can be particularly useful in applications where the number of demonstrations is limited, and their selection is crucial for the model's performance.", "example": "For instance, in a sentiment analysis task, instead of randomly selecting demonstration examples, the proposed algorithm can be used to select the most optimal demonstrations from a set of annotated data. This could lead to a more accurate classification of sentiments in the test input."}, "category": "BEHAVIOR", "novelty_analysis": "The paper provides a novel perspective on LLMs as implicit topic models and proposes an innovative algorithm for optimal demonstration selection. These contributions significantly enhance our understanding of the mechanisms underlying in-context learning in LLMs and offer practical solutions to improve their performance.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it delves into the mechanisms of in-context learning in LLMs and proposes a new algorithm for demonstration selection. However, the concepts are explained clearly, making it accessible to readers with a basic understanding of LLMs and Bayesian inference.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an intriguing perspective on LLMs. The empirical evidence supporting the authors' hypothesis and the practical implications of their findings make the paper an engaging read.", "enjoyable_score": 3}