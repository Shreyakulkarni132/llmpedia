{"Published": "2023-05-04", "Title": "Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning", "Authors": "Xinyi Wang, Wanrong Zhu, Michael Saxon, Mark Steyvers, William Yang Wang", "Summary": "In recent years, pre-trained large language models have demonstrated remarkable efficiency in achieving an inference-time few-shot learning capability known as in-context learning. However, existing literature has highlighted the sensitivity of this capability to the selection of few-shot demonstrations. The underlying mechanisms by which this capability arises from regular language model pretraining objectives remain poorly understood. In this study, we aim to examine the in-context learning phenomenon through a Bayesian lens, viewing large language models as topic models that implicitly infer task-related information from demonstrations. On this premise, we propose an algorithm for selecting optimal demonstrations from a set of annotated data and demonstrate a significant 12.5% improvement relative to the random selection baseline, averaged over eight GPT2 and GPT3 models on eight different real-world text classification datasets. Our empirical findings support our hypothesis that large language models implicitly infer a latent concept variable.", "main_contribution": {"headline": "Large Language Models as Implicit Topic Models for Optimal Demonstration Selection", "description": "This paper presents a novel perspective on Large Language Models (LLMs), viewing them as implicit topic models that infer task-related information from demonstrations. The authors propose an algorithm for selecting optimal demonstrations from a set of annotated data. This approach significantly improves the performance of in-context learning, a few-shot learning capability of LLMs, by 12.5% compared to the random selection baseline. The study's empirical findings support the hypothesis that LLMs implicitly infer a latent concept variable, shedding light on the mechanisms behind in-context learning."}, "takeaways": {"headline": "Optimal demonstration selection can enhance in-context learning in LLMs", "description": "The paper's findings suggest that the selection of demonstrations can significantly impact the performance of in-context learning in LLMs. The proposed algorithm for optimal demonstration selection can be used to improve the efficiency of LLMs in various real-world text classification tasks. This approach can help LLM practitioners to better understand and leverage the in-context learning capabilities of LLMs, potentially leading to more accurate and efficient models.", "example": "For instance, given a set of annotated data for a sentiment analysis task, the proposed algorithm can be used to select the most effective demonstrations for in-context learning. This could lead to more accurate sentiment predictions by the LLM."}, "category": "TRAINING", "novelty_analysis": "The paper presents a novel perspective on LLMs as implicit topic models and proposes a new algorithm for optimal demonstration selection. These contributions provide fresh insights into the mechanisms behind in-context learning in LLMs, marking a significant advancement in the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, discussing the underlying mechanisms of in-context learning in LLMs and proposing a new algorithm for optimal demonstration selection. However, the concepts are explained clearly and should be accessible to readers with a background in machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an intriguing perspective on LLMs, making it an interesting read. The empirical findings and the proposed algorithm provide valuable insights into the capabilities of LLMs, adding to the paper's appeal.", "enjoyable_score": 2}