{"Published": "2023-06-13", "Title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks", "Authors": "Veniamin Veselovsky, Manoel Horta Ribeiro, Robert West", "Summary": "Large language models (LLMs) are remarkable data annotators. They can be used to generate high-fidelity supervised training data, as well as survey and experimental data. With the widespread adoption of LLMs, human gold--standard annotations are key to understanding the capabilities of LLMs and the validity of their results. However, crowdsourcing, an important, inexpensive way to obtain human annotations, may itself be impacted by LLMs, as crowd workers have financial incentives to use LLMs to increase their productivity and income. To investigate this concern, we conducted a case study on the prevalence of LLM usage by crowd workers. We reran an abstract summarization task from the literature on Amazon Mechanical Turk and, through a combination of keystroke detection and synthetic text classification, estimate that 33-46% of crowd workers used LLMs when completing the task. Although generalization to other, less LLM-friendly tasks is unclear, our results call for platforms, researchers, and crowd workers to find new ways to ensure that human data remain human, perhaps using the methodology proposed here as a stepping stone. Code/data: https://github.com/epfl-dlab/GPTurk", "main_contribution": "The paper investigates the extent to which crowd workers use Large Language Models (LLMs) to complete their tasks. The authors conducted a case study by rerunning an abstract summarization task on Amazon Mechanical Turk. They used a combination of keystroke detection and synthetic text classification to estimate the prevalence of LLM usage among crowd workers. The results indicate that 33-46% of crowd workers used LLMs when completing the task.", "takeaways": "The findings of this study are significant as they reveal the extent to which LLMs are being used in crowdsourcing platforms. This has implications for the validity of human gold-standard data, as the use of LLMs by crowd workers could potentially compromise the human nature of the data. The authors call for new ways to ensure that human data remain human, suggesting that their methodology could serve as a stepping stone.", "novelty_analysis": "The novelty of this paper lies in its investigation of the prevalence of LLM usage among crowd workers. While the use of LLMs in various tasks has been extensively studied, this paper provides new insights into how these models are being used in the context of crowdsourcing platforms.", "novelty_score": 2, "category": "BEHAVIOR", "technical_analysis": "The paper is somewhat technical, as it involves the use of keystroke detection and synthetic text classification to estimate the prevalence of LLM usage. However, the authors provide clear explanations of their methodology, making it accessible to readers with a basic understanding of LLMs and crowdsourcing platforms.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting investigation into the use of LLMs by crowd workers. The findings are significant and have practical implications for researchers and practitioners who rely on crowdsourcing platforms. However, the technical nature of the paper may make it less enjoyable for readers without a background in the field.", "enjoyable_score": 2}