{"Published": "2023-07-09", "Title": "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies", "Authors": "Gati Aher, Rosa I. Arriaga, Adam Tauman Kalai", "Summary": "We introduce a new type of test, called a Turing Experiment (TE), for evaluating to what extent a given language model, such as GPT models, can simulate different aspects of human behavior. A TE can also reveal consistent distortions in a language model's simulation of a specific human behavior. Unlike the Turing Test, which involves simulating a single arbitrary individual, a TE requires simulating a representative sample of participants in human subject research. We carry out TEs that attempt to replicate well-established findings from prior studies. We design a methodology for simulating TEs and illustrate its use to compare how well different language models are able to reproduce classic economic, psycholinguistic, and social psychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock Experiment, and Wisdom of Crowds. In the first three TEs, the existing findings were replicated using recent models, while the last TE reveals a \"hyper-accuracy distortion\" present in some language models (including ChatGPT and GPT-4), which could affect downstream applications in education and the arts.", "main_contribution": "The paper introduces the concept of Turing Experiments (TEs), a new type of test for evaluating the ability of language models to simulate different aspects of human behavior. TEs are designed to replicate well-established findings from prior studies, and the paper presents a methodology for simulating these experiments. The authors use TEs to compare how well different language models can reproduce classic economic, psycholinguistic, and social psychology experiments.", "takeaways": "The introduction of TEs provides a new way to evaluate the simulation capabilities of language models, which can be particularly useful for applications that require accurate models of human behavior. The methodology presented allows for the systematic evaluation of which aspects of human behavior a language model can faithfully simulate and which it systematically distorts. The findings from the TEs conducted in this study can inform the development and application of language models in various fields, including education and the arts.", "novelty_analysis": "The concept of Turing Experiments is a novel approach to evaluating language models, moving beyond the traditional Turing Test to focus on the simulation of a representative sample of participants in human subject research. This approach allows for a more nuanced understanding of the capabilities and limitations of language models in simulating human behavior.", "novelty_score": 3, "category": "BEHAVIOR", "technical_analysis": "The paper is somewhat technical, as it introduces a new methodology for evaluating language models and applies it to a range of classic experiments. However, the concepts are explained clearly and should be accessible to those with a background in AI and language models.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel and interesting approach to evaluating language models. The application of this approach to a range of classic experiments makes for an engaging read.", "enjoyable_score": 3}