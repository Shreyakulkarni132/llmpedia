{"Published": "2023-02-01", "Title": "Faithful Chain-of-Thought Reasoning", "Authors": "Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, Chris Callison-Burch", "Summary": "While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a faithful-by-construction framework that decomposes a reasoning task into two stages: Translation (Natural Language query $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning chain $\\rightarrow$ answer), using an LM and a deterministic solver respectively. We demonstrate the efficacy of our approach on 10 reasoning datasets from 4 diverse domains. It outperforms traditional CoT prompting on 9 out of the 10 datasets, with an average accuracy gain of 4.4 on Math Word Problems, 1.9 on Planning, 4.0 on Multi-hop Question Answering (QA), and 18.1 on Logical Inference, under greedy decoding. Together with self-consistency decoding, we achieve new state-of-the-art few-shot performance on 7 out of the 10 datasets, showing a strong synergy between faithfulness and accuracy.", "main_contribution": {"headline": "Faithful CoT: A framework ensuring faithfulness in Chain-of-Thought reasoning", "description": "The paper introduces Faithful CoT, a novel framework that ensures the faithfulness of the reasoning chain in Chain-of-Thought (CoT) prompting. The framework decomposes a reasoning task into two stages: Translation (Natural Language query to symbolic reasoning chain) and Problem Solving (reasoning chain to answer). The Translation stage uses a Large Language Model (LLM), while the Problem Solving stage uses a deterministic solver. This approach ensures that the reasoning chain accurately represents the reasoning process behind the model's prediction, thereby enhancing the interpretability of the model's output."}, "takeaways": {"headline": "Faithful CoT improves interpretability and accuracy in reasoning tasks", "description": "The Faithful CoT framework can be used to improve the interpretability and accuracy of LLMs in complex reasoning tasks. By ensuring that the reasoning chain accurately represents the model's reasoning process, it can help avoid misleading interpretations of the model's output. This can be particularly useful in high-stake applications where the accuracy and interpretability of the model's output are crucial. The framework also demonstrated superior performance on various reasoning tasks, indicating its potential for improving the performance of LLMs in these tasks.", "example": "For instance, in a legal AI application, an LLM can use the Faithful CoT framework to generate a reasoning chain for a legal decision. This reasoning chain can then be used to understand how the model arrived at the decision, thereby improving the interpretability of the model's output."}, "category": "PROMPTING", "novelty_analysis": "The introduction of the Faithful CoT framework represents a significant advancement in the field of Chain-of-Thought (CoT) prompting. By ensuring the faithfulness of the reasoning chain, it addresses a fundamental limitation of existing CoT methods and enhances the interpretability of the model's output.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it introduces a new framework and discusses its implementation in detail. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a basic understanding of LLMs and CoT prompting.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents a novel and intriguing contribution to the field of CoT prompting. The introduction of the Faithful CoT framework and its potential implications make the paper an interesting read.", "enjoyable_score": 3}