{"Published": "2023-06-22", "Title": "Demystifying GPT Self-Repair for Code Generation", "Authors": "Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, Armando Solar-Lezama", "Summary": "Large Language Models (LLMs) have shown remarkable aptitude in code generation but still struggle on challenging programming tasks. Self-repair -- in which the model debugs and fixes mistakes in its own code -- has recently become a popular way to boost performance in these settings. However, only very limited studies on how and when self-repair works effectively exist in the literature, and one might wonder to what extent a model is really capable of providing accurate feedback on why the code is wrong when that code was generated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's ability to perform self-repair on APPS, a challenging dataset consisting of diverse coding challenges. To do so, we first establish a new evaluation strategy dubbed pass@t that measures the pass rate of the tasks against the total number of tokens sampled from the model, enabling a fair comparison to purely sampling-based approaches. With this evaluation strategy, we find that the effectiveness of self-repair is only seen in GPT-4. We also observe that self-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback on the programs generated by GPT-3.5 and using expert human programmers to give feedback on the programs generated by GPT-4, we unlock significant performance gains.", "main_contribution": {"headline": "New Evaluation Strategy and Insights into LLM Self-Repair for Code Generation", "description": "The paper introduces a new evaluation strategy, pass@t, for assessing the performance of Large Language Models (LLMs) in code generation tasks. This strategy measures the pass rate of tasks against the total number of tokens sampled from the model, providing a fair comparison to purely sampling-based approaches. The authors apply this strategy to analyze the self-repair capabilities of GPT-3.5 and GPT-4 on a challenging dataset, APPS. They find that self-repair is effective only in GPT-4 and is bottlenecked by the feedback stage. By using GPT-4 to provide feedback on programs generated by GPT-3.5 and expert human programmers to provide feedback on programs generated by GPT-4, they achieve significant performance improvements."}, "takeaways": {"headline": "Self-repair in LLMs can be enhanced with expert feedback", "description": "The paper's findings suggest that the self-repair capabilities of LLMs can be significantly improved by using more advanced models or expert human programmers to provide feedback. This insight can be used to enhance the performance of LLMs in code generation tasks, particularly in challenging scenarios. The new evaluation strategy, pass@t, can also be used to more accurately assess the performance of LLMs in these tasks, providing a more nuanced understanding of their capabilities.", "example": "For instance, if an LLM generates a faulty program, instead of using the same model to provide feedback and attempt self-repair, a more advanced model or an expert human programmer could be used to provide feedback. This feedback could then be used by the original model to generate a fixed version of the program, potentially improving the success rate."}, "category": "BEHAVIOR", "novelty_analysis": "The paper presents a novel evaluation strategy for assessing the performance of LLMs in code generation tasks, and provides new insights into the self-repair capabilities of these models. While the concept of self-repair in LLMs is not new, the authors' approach to enhancing this capability through expert feedback is a unique contribution.", "novelty_score": 2, "technical_analysis": "The paper is somewhat technical, as it delves into the details of the new evaluation strategy and the self-repair process in LLMs. However, it does not involve complex mathematical theories or algorithms, making it accessible to readers with a basic understanding of LLMs and code generation.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting exploration of the self-repair capabilities of LLMs. The introduction of a new evaluation strategy and the insights into how self-repair can be enhanced make it an engaging read for those interested in the application of LLMs in code generation.", "enjoyable_score": 2}