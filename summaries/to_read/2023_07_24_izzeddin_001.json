{"Published": "2023-07-24", "Title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis", "Authors": "Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, Aleksandra Faust", "Summary": "Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web navigation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that can complete the tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via generated Python programs from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our recipe improves the success on a real website by over 50%, and that HTML-T5 is the best model to solve HTML-based tasks; achieving 14.9% higher success rate than prior SoTA on the MiniWoB web navigation benchmark and better accuracy on offline task planning evaluation.", "main_contribution": {"headline": "WebAgent: An LLM-driven agent for real-world web navigation", "description": "The paper introduces WebAgent, a Large Language Model (LLM)-driven agent designed to perform tasks on real-world websites following natural language instructions. WebAgent addresses the challenges of open domainness, limited context length, and lack of inductive bias on HTML that have hampered the performance of LLMs on real-world websites. It achieves this by decomposing instructions into canonical sub-instructions, summarizing long HTML documents into task-relevant snippets, and acting on websites via Python programs generated from these snippets. The authors use Flan-U-PaLM for grounded code generation and HTML-T5, a new pre-trained LLM for long HTML documents, for planning and summarization."}, "takeaways": {"headline": "WebAgent provides a practical approach to real-world web navigation with LLMs", "description": "WebAgent offers a practical solution for LLM practitioners looking to apply LLMs to real-world web navigation. By decomposing instructions, summarizing HTML documents, and generating Python programs, WebAgent provides a structured approach to handling the complexities of real-world websites. Practitioners can leverage these techniques to improve the performance of their LLMs in similar tasks. The use of Flan-U-PaLM and HTML-T5 also provides insights into effective models for grounded code generation and long HTML document handling.", "example": "For instance, to navigate a real-world website, WebAgent would first decompose the given instruction into sub-instructions. It would then summarize the website's HTML document into relevant snippets. Finally, it would generate a Python program from these snippets to perform the required actions on the website."}, "category": "USE CASES", "novelty_analysis": "WebAgent presents a novel approach to real-world web navigation using LLMs. It introduces new techniques for instruction decomposition, HTML document summarization, and Python program generation, marking a significant advancement in the field.", "novelty_score": 3, "technical_analysis": "The paper is quite technical, delving into the details of how WebAgent decomposes instructions, summarizes HTML documents, and generates Python programs. It also discusses the use of Flan-U-PaLM and HTML-T5, requiring a solid understanding of LLMs and their applications.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and presents an interesting and novel approach to real-world web navigation using LLMs. However, the technical nature of the content may make it a challenging read for those without a strong background in LLMs.", "enjoyable_score": 2}