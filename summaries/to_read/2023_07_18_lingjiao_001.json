{"Published": "2023-07-18", "Title": "How is ChatGPT's behavior changing over time?", "Authors": "Lingjiao Chen, Matei Zaharia, James Zou", "Summary": "GPT-3.5 and GPT-4 are the two most widely used large language model (LLM) services. However, when and how these models are updated over time is opaque. Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on four diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous questions, 3) generating code and 4) visual reasoning. We find that the performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time. For example, GPT-4 (March 2023) was very good at identifying prime numbers (accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions (accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5 (March 2023) in this task. GPT-4 was less willing to answer sensitive questions in June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes in code generation in June than in March. Overall, our findings shows that the behavior of the same LLM service can change substantially in a relatively short amount of time, highlighting the need for continuous monitoring of LLM quality.", "main_contribution": {"headline": "Performance and behavior of LLMs can vary greatly over time", "description": "The paper investigates the changes in behavior and performance of two widely used Large Language Models (LLMs), GPT-3.5 and GPT-4, over a short period of time. The authors evaluate the March 2023 and June 2023 versions of these models on four diverse tasks: solving math problems, answering sensitive/dangerous questions, generating code, and visual reasoning. The findings reveal significant variations in the performance and behavior of these models over time, emphasizing the need for continuous monitoring of LLM quality."}, "takeaways": {"headline": "Continuous monitoring of LLMs is crucial due to their changing behavior", "description": "The paper highlights the importance of continuous monitoring of LLMs due to their changing behavior and performance over time. This is crucial for practitioners who integrate LLMs into larger workflows, as sudden changes in LLM responses can potentially disrupt downstream pipelines. The paper also raises questions about the transparency of updates to these models, which can affect their reproducibility and stability.", "example": "For instance, if an LLM is used in a pipeline for generating code, and the model's behavior changes over time leading to more formatting mistakes, it could disrupt the entire pipeline. Therefore, continuous monitoring and adjustment of the LLM's integration into the pipeline would be necessary."}, "category": "BEHAVIOR", "novelty_analysis": "The paper provides a unique perspective on the temporal changes in the behavior and performance of widely used LLMs. While previous works have evaluated LLMs, this paper is novel in its focus on the longitudinal drifts of these models over time.", "novelty_score": 3, "technical_analysis": "The paper is not overly technical. It presents an empirical study of the behavior of LLMs over time, without delving into the technical details of the models themselves. The findings are presented in a clear and understandable manner.", "technical_score": 1, "enjoyable_analysis": "The paper is well-structured and presents an interesting perspective on the temporal changes in LLMs. The findings are insightful and have practical implications for practitioners working with LLMs, making it an enjoyable read.", "enjoyable_score": 3}