{"Published": "2023-06-10", "Title": "Boosting Language Models Reasoning with Chain-of-Knowledge Prompting", "Authors": "Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, Ming Gao", "Summary": "Recently, Chain-of-Thought (CoT) prompting has delivered success on complex reasoning tasks, which aims at designing a simple prompt like ``Let's think step by step'' or multiple in-context exemplars with well-designed rationales to elicit Large Language Models (LLMs) to generate intermediate reasoning steps. However, the generated rationales often come with mistakes, making unfactual and unfaithful reasoning chains. To mitigate this brittleness, we propose a novel Chain-of-Knowledge (CoK) prompting, where we aim at eliciting LLMs to generate explicit pieces of knowledge evidence in the form of structure triple. This is inspired by our human behaviors, i.e., we can draw a mind map or knowledge map as the reasoning evidence in the brain before answering a complex question. Benefiting from CoK, we additionally introduce a F^2-Verification method to estimate the reliability of the reasoning chains in terms of factuality and faithfulness. For the unreliable response, the wrong evidence can be indicated to prompt the LLM to rethink. Extensive experiments demonstrate that our method can further improve the performance of commonsense, factual, symbolic, and arithmetic reasoning tasks.", "main_contribution": "The paper introduces a novel Chain-of-Knowledge (CoK) prompting method to improve the reasoning capabilities of Large Language Models (LLMs). The CoK prompting method encourages LLMs to generate explicit pieces of knowledge evidence in the form of structure triple, inspired by human behaviors of drawing a mind map or knowledge map before answering a complex question. The paper also introduces a F^2-Verification method to estimate the reliability of the reasoning chains in terms of factuality and faithfulness, and prompts the LLM to rethink if the response is unreliable.", "takeaways": "The CoK prompting method and the F^2-Verification method can significantly improve the performance of LLMs on commonsense, factual, symbolic, and arithmetic reasoning tasks. These methods can help mitigate the brittleness of LLMs in generating unfactual and unfaithful reasoning chains, thereby enhancing the reliability and accuracy of LLMs in complex reasoning tasks.", "novelty_analysis": "The paper presents a novel approach to improve the reasoning capabilities of LLMs by introducing the CoK prompting method and the F^2-Verification method. These methods represent a significant advancement in the field of LLM prompting, particularly in the context of complex reasoning tasks.", "novelty_score": 3, "category": "PROMPTING", "technical_analysis": "The paper is somewhat technical, introducing new methods and discussing their implementation in LLMs. However, the concepts are explained clearly and can be understood by someone with a background in computer science or AI research.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel and interesting contribution to the field of LLM prompting. However, the technical content may be challenging for some readers.", "enjoyable_score": 2}