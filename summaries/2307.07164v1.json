{"Published": "2023-07-14", "Title": "Learning to Retrieve In-Context Examples for Large Language Models", "Authors": "Liang Wang, Nan Yang, Furu Wei", "Summary": "Large language models (LLMs) have demonstrated their ability to learn in-context, allowing them to perform various tasks based on a few input-output examples. However, the effectiveness of in-context learning is heavily reliant on the quality of the selected examples. In this paper, we propose a novel framework to iteratively train dense retrievers that can identify high-quality in-context examples for LLMs. Our framework initially trains a reward model based on LLM feedback to evaluate the quality of candidate examples, followed by knowledge distillation to train a bi-encoder based dense retriever. Our experiments on a suite of 30 tasks demonstrate that our framework significantly enhances in-context learning performance. Furthermore, we show the generalization ability of our framework to unseen tasks during training. An in-depth analysis reveals that our model improves performance by retrieving examples with similar patterns, and the gains are consistent across LLMs of varying sizes.", "main_contribution": {"headline": "LLM-R: A novel framework for retrieving high-quality in-context examples for LLMs", "description": "The paper introduces a new framework, LLM-R (LLM Retriever), designed to iteratively train dense retrievers to identify high-quality in-context examples for Large Language Models (LLMs). The framework begins by training a reward model based on LLM feedback to evaluate the quality of candidate examples. It then uses knowledge distillation to train a bi-encoder based dense retriever. The framework is iterative, allowing for continuous improvement of the dense retriever. The authors demonstrate that LLM-R significantly enhances in-context learning performance and generalizes well to unseen tasks during training."}, "takeaways": {"headline": "LLM-R framework improves in-context learning and generalizes to unseen tasks", "description": "The LLM-R framework presents a promising approach for improving the effectiveness of in-context learning in LLMs. By iteratively training dense retrievers to identify high-quality examples, the framework can enhance the performance of LLMs across a variety of tasks. This could be particularly useful in scenarios where labeled data is scarce or expensive to obtain. The framework's ability to generalize to unseen tasks also suggests its potential for broad applicability.", "example": "For instance, an LLM practitioner could use the LLM-R framework to improve the performance of an LLM in a task such as question answering. The framework would iteratively train a dense retriever to identify high-quality examples for the LLM to learn from, thereby enhancing its ability to answer questions accurately."}, "category": "TRAINING", "novelty_analysis": "The paper introduces a novel framework for improving the effectiveness of in-context learning in LLMs. While the concept of using dense retrievers to identify high-quality examples is not new, the iterative approach and the use of a reward model based on LLM feedback represent significant advancements in the field.", "novelty_score": 2, "technical_analysis": "The paper is somewhat technical, as it delves into the details of the LLM-R framework and its components. However, it does not require advanced mathematical knowledge and can be understood by someone with a background in machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting approach to improving in-context learning in LLMs. The clear explanation of the LLM-R framework and its potential applications make it an engaging read for those interested in the field.", "enjoyable_score": 2}