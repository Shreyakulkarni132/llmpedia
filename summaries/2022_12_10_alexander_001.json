{"Published": "2022-12-10", "Title": "Structured information extraction from complex scientific text with fine-tuned large language models", "Authors": "Alexander Dunn, John Dagdelen, Nicholas Walker, Sanghoon Lee, Andrew S. Rosen, Gerbrand Ceder, Kristin Persson, Anubhav Jain", "Summary": "Intelligently extracting and linking complex scientific information from unstructured text is a challenging endeavor particularly for those inexperienced with natural language processing. Here, we present a simple sequence-to-sequence approach to joint named entity recognition and relation extraction for complex hierarchical information in scientific text. The approach leverages a pre-trained large language model (LLM), GPT-3, that is fine-tuned on approximately 500 pairs of prompts (inputs) and completions (outputs). Information is extracted either from single sentences or across sentences in abstracts/passages, and the output can be returned as simple English sentences or a more structured format, such as a list of JSON objects. We demonstrate that LLMs trained in this way are capable of accurately extracting useful records of complex scientific knowledge for three representative tasks in materials chemistry: linking dopants with their host materials, cataloging metal-organic frameworks, and general chemistry/phase/morphology/application information extraction. This approach represents a simple, accessible, and highly-flexible route to obtaining large databases of structured knowledge extracted from unstructured text. An online demo is available at http://www.matscholar.com/info-extraction.", "main_contribution": "The paper presents a sequence-to-sequence approach to joint named entity recognition and relation extraction for complex hierarchical information in scientific text. This approach leverages a pre-trained large language model, GPT-3, fine-tuned on approximately 500 pairs of prompts and completions. The model can extract information from single sentences or across sentences in abstracts/passages, and the output can be returned as simple English sentences or a more structured format, such as a list of JSON objects.", "takeaways": "The presented approach provides a simple, accessible, and highly-flexible route to obtaining large databases of structured knowledge extracted from unstructured text. It demonstrates the potential of LLMs in accurately extracting useful records of complex scientific knowledge, which can be particularly beneficial in fields like materials chemistry. The practical implications for LLM practitioners include the ability to extract and structure complex scientific information from unstructured text, which can be used to build large databases of structured knowledge.", "novelty_analysis": "The novelty of this paper lies in its application of a sequence-to-sequence approach to joint named entity recognition and relation extraction for complex hierarchical information in scientific text using a fine-tuned GPT-3 model. While the use of LLMs for information extraction is not new, the specific application and the demonstrated tasks in materials chemistry represent a novel contribution.", "novelty_score": 2, "category": "FINE-TUNING", "technical_analysis": "The paper is somewhat technical as it discusses the fine-tuning of a large language model and its application in extracting complex scientific information. It requires some understanding of natural language processing and machine learning concepts.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting application of LLMs in the field of materials chemistry. However, the technical nature of the content and the specific focus on materials chemistry might limit its appeal to a broader audience.", "enjoyable_score": 2}