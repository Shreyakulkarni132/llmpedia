{"Published": "2023-04-16", "Title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models", "Authors": "Denny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, Ed Chi", "Summary": "Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99% using just 14 exemplars, compared to only 16% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.", "main_contribution": {"headline": "Least-to-Most Prompting Enhances Problem-Solving Capabilities of LLMs", "description": "The paper introduces a novel prompting strategy, least-to-most prompting, to improve the problem-solving capabilities of Large Language Models (LLMs). This strategy breaks down complex problems into simpler subproblems and solves them sequentially, using the answers to previously solved subproblems to facilitate the process. The authors demonstrate that this approach enables LLMs to generalize to more difficult problems than those seen in the prompts, outperforming the chain-of-thought prompting approach, particularly in tasks related to symbolic manipulation, compositional generalization, and math reasoning."}, "takeaways": {"headline": "Least-to-Most Prompting Offers a New Approach to Tackle Complex Problems with LLMs", "description": "The least-to-most prompting strategy provides a new way for LLM practitioners to tackle complex problems. By breaking down problems into simpler subproblems and solving them sequentially, this approach can help LLMs generalize to more difficult problems. This could be particularly useful in tasks that require complex reasoning or symbolic manipulation. Practitioners could use this strategy to improve the performance of their LLMs in a variety of tasks.", "example": "For instance, to solve a complex math problem, an LLM could use least-to-most prompting to break the problem down into simpler subproblems. It could then solve each subproblem in sequence, using the answers to previously solved subproblems to facilitate the process. This could result in a more accurate and efficient solution than if the LLM tried to solve the entire problem at once."}, "category": "PROMPTING", "novelty_analysis": "The introduction of the least-to-most prompting strategy represents a significant advancement in the field of LLM prompting. This approach provides a new way for LLMs to tackle complex problems and generalize to more difficult tasks, marking a notable departure from previous prompting strategies.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it introduces a new prompting strategy and demonstrates its effectiveness in a variety of tasks. However, the authors explain the strategy clearly and provide ample experimental results to support their claims, making the paper accessible to readers with a basic understanding of LLMs and prompting.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents a novel and intriguing contribution to the field of LLM prompting. The introduction of the least-to-most prompting strategy and the demonstration of its effectiveness in a variety of tasks make the paper an interesting and enjoyable read.", "enjoyable_score": 3}