{"Published": "2023-05-24", "Title": "Large Language Models are Better Reasoners with Self-Verification", "Authors": "Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Kang Liu, Jun Zhao", "Summary": "Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities. We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By taking turns masking the original conditions and predicting their results, we calculate an explainable answer verification score based on whether the re-predicted conditions are correct. Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: https://github.com/WENGSYX/Self-Verification.", "main_contribution": {"headline": "Self-Verification Enhances Reasoning Abilities of Large Language Models", "description": "The paper introduces a self-verification mechanism for Large Language Models (LLMs) that improves their reasoning abilities. The authors propose a method where the conclusion obtained by the Chain of Thought (CoT) is taken as a condition for solving the original problem. The original conditions are then masked and their results predicted, and an answer verification score is calculated based on the correctness of the re-predicted conditions. This method is shown to improve the reasoning performance of LLMs on various arithmetic, commonsense, and logical reasoning datasets."}, "takeaways": {"headline": "Self-Verification Can Improve LLM Reasoning Performance", "description": "The self-verification method proposed in this paper can be used to enhance the reasoning abilities of LLMs. By using the conclusion of the CoT as a condition and then masking and re-predicting the original conditions, a verification score can be calculated. This score can be used to assess the correctness of the model's reasoning and improve its performance. This method could be particularly useful in applications where reasoning is critical, such as in decision-making systems or complex problem-solving tasks.", "example": "For instance, in a decision-making system, an LLM could use the self-verification method to improve its reasoning. After generating a conclusion using CoT, the model would mask the original conditions and re-predict their results. The correctness of these re-predicted conditions would then be used to calculate a verification score, which could be used to assess and improve the model's reasoning."}, "category": "BEHAVIOR", "novelty_analysis": "The paper presents a novel approach to improving the reasoning abilities of LLMs by introducing a self-verification mechanism. This mechanism, which uses the conclusion of the CoT as a condition and then masks and re-predicts the original conditions, is a unique contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it introduces a new method for improving the reasoning abilities of LLMs and provides a detailed explanation of how this method works. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a basic understanding of LLMs and reasoning processes.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an interesting and novel approach to improving the reasoning abilities of LLMs. The introduction of the self-verification mechanism and the demonstration of its effectiveness in improving reasoning performance make the paper an engaging read.", "enjoyable_score": 3}