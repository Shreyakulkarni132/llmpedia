{"Published": "2023-05-22", "Title": "Inspecting and Editing Knowledge Representations in Language Models", "Authors": "Evan Hernandez, Belinda Z. Li, Jacob Andreas", "Summary": "Neural language models (LMs) represent facts about the world described by text. Sometimes these facts derive from training data (in most LMs, a representation of the word \"banana\" encodes the fact that bananas are fruits). Sometimes facts derive from input text itself (a representation of the sentence \"I poured out the bottle\" encodes the fact that the bottle became empty). We describe REMEDI, a method for learning to map statements in natural language to fact encodings in an LM's internal representation system. REMEDI encodings can be used as knowledge editors: when added to LM hidden representations, they modify downstream generation to be consistent with new facts. REMEDI encodings may also be used as probes: when compared to LM representations, they reveal which properties LMs already attribute to mentioned entities, in some cases making it possible to predict when LMs will generate outputs that conflict with background knowledge or input text. REMEDI thus links work on probing, prompting, and LM editing, and offers steps toward general tools for fine-grained inspection and control of knowledge in LMs.", "main_contribution": {"headline": "REMEDI: A method for inspecting and editing knowledge representations in LMs", "description": "The paper introduces REMEDI (REpresentation MEDIation), a technique for inspecting and editing the knowledge representations in Language Models (LMs). REMEDI learns to map natural language statements to fact encodings in an LM's internal representation system. These encodings can be used as knowledge editors, modifying the LM's downstream generation to align with new facts. They can also be used as probes to reveal the properties LMs attribute to entities, and to predict when LMs might generate outputs that conflict with background knowledge or input text. This technique provides a step towards fine-grained inspection and control of knowledge in LMs."}, "takeaways": {"headline": "REMEDI offers a new approach to inspecting and controlling LMs' knowledge", "description": "REMEDI provides a new way for LLM practitioners to inspect and control the knowledge representations in LMs. By learning to map natural language statements to fact encodings, REMEDI can modify the LM's downstream generation to be consistent with new facts. This can be particularly useful in applications where the LM's output needs to be controlled or guided. Additionally, REMEDI can be used to probe the LM's representations, revealing the properties it attributes to entities and predicting when it might generate conflicting outputs. This can help in understanding and improving the LM's behavior.", "example": "For instance, if an LLM is generating text about a specific entity (e.g., 'John'), a REMEDI encoding (e.g., 'is a lawyer') can be added to the LM's representation of 'John' to ensure that the generated text is consistent with the fact that John is a lawyer. Similarly, REMEDI encodings can be compared to the LM's representations to reveal what properties the LM attributes to 'John' and to predict when it might generate outputs that conflict with the fact that John is a lawyer."}, "category": "BEHAVIOR", "novelty_analysis": "The introduction of REMEDI represents a novel approach to inspecting and editing the knowledge representations in LMs. While previous work has explored probing and editing LMs, REMEDI combines these tasks in a unified framework and provides a method for learning to map natural language statements to fact encodings in an LM's internal representation system.", "novelty_score": 3, "technical_analysis": "The paper is quite technical, as it introduces a new method for inspecting and editing knowledge representations in LMs, and provides a detailed description of how REMEDI works. It requires a good understanding of LMs and their internal representation systems to fully grasp the concepts presented.", "technical_score": 3, "enjoyable_analysis": "The paper is well-written and presents a novel and intriguing contribution to the field of LLMs. However, the technical nature of the content might make it a challenging read for those without a strong background in LMs.", "enjoyable_score": 2}