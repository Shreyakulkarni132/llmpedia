{"Published": "2023-05-25", "Title": "On the Tool Manipulation Capability of Open-source Large Language Models", "Authors": "Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, Jian Zhang", "Summary": "Recent studies on software tool manipulation with large language models (LLMs) mostly rely on closed model APIs. The industrial adoption of these models is substantially constrained due to the security and robustness risks in exposing information to closed LLM API services. In this paper, we ask can we enhance open-source LLMs to be competitive to leading closed LLM APIs in tool manipulation, with practical amount of human supervision. By analyzing common tool manipulation failures, we first demonstrate that open-source LLMs may require training with usage examples, in-context demonstration and generation style regulation to resolve failures. These insights motivate us to revisit classical methods in LLM literature, and demonstrate that we can adapt them as model alignment with programmatic data generation, system prompts and in-context demonstration retrievers to enhance open-source LLMs for tool manipulation. To evaluate these techniques, we create the ToolBench, a tool manipulation benchmark consisting of diverse software tools for real-world tasks. We demonstrate that our techniques can boost leading open-source LLMs by up to 90% success rate, showing capabilities competitive to OpenAI GPT-4 in 4 out of 8 ToolBench tasks. We show that such enhancement typically requires about one developer day to curate data for each tool, rendering a recipe with practical amount of human supervision.", "main_contribution": {"headline": "Enhancing Open-source LLMs for Tool Manipulation with Practical Human Supervision", "description": "The paper presents a method to enhance open-source Large Language Models (LLMs) for tool manipulation, making them competitive with closed LLM APIs. The authors identify that open-source LLMs require training with usage examples, in-context demonstration, and generation style regulation to resolve common tool manipulation failures. They revisit classical methods in LLM literature and adapt them as model alignment with programmatic data generation, system prompts, and in-context demonstration retrievers. The authors also introduce ToolBench, a benchmark for evaluating these techniques, and demonstrate that their approach can boost open-source LLMs by up to 90% success rate."}, "takeaways": {"headline": "Open-source LLMs can be enhanced for tool manipulation with practical human supervision", "description": "The paper provides a practical approach to enhance open-source LLMs for tool manipulation, making them competitive with closed LLM APIs. This approach involves training with usage examples, in-context demonstration, and generation style regulation. The authors also introduce a benchmark, ToolBench, for evaluating these techniques. This approach can be used to improve the performance of open-source LLMs in real-world tasks, with the added benefit of reducing security and robustness risks associated with closed LLM APIs.", "example": "For instance, an open-source LLM can be trained with usage examples and in-context demonstrations to improve its ability to manipulate a software tool. The performance can be evaluated using the ToolBench benchmark. This approach can be used to enhance the LLM's performance in real-world tasks, such as automating software operations through natural language instructions."}, "category": "FINE-TUNING", "novelty_analysis": "The paper presents a novel approach to enhance open-source LLMs for tool manipulation, making them competitive with closed LLM APIs. The introduction of the ToolBench benchmark for evaluating these techniques is also a significant contribution. However, the approach is based on revisiting and adapting classical methods in LLM literature, which reduces its novelty.", "novelty_score": 2, "technical_analysis": "The paper is somewhat technical, as it discusses the enhancement of open-source LLMs for tool manipulation and introduces a benchmark for evaluating these techniques. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and organized, presenting a practical approach to enhance open-source LLMs for tool manipulation. The introduction of the ToolBench benchmark and the demonstration of the approach's effectiveness make the paper interesting and enjoyable to read.", "enjoyable_score": 3}