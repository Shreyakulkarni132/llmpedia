{"Published": "2023-05-22", "Title": "Are Emergent Abilities of Large Language Models a Mirage?", "Authors": "Rylan Schaeffer, Brando Miranda, Sanmi Koyejo", "Summary": "Recent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due to the researcher's choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities; (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.", "main_contribution": {"headline": "Emergent abilities in LLMs may be a result of metric choice, not model scaling", "description": "The paper challenges the notion that emergent abilities in Large Language Models (LLMs) are a result of model scaling. Instead, it proposes that these abilities may be an artifact of the researcher's choice of metric. The authors argue that nonlinear or discontinuous metrics can produce apparent emergent abilities, while linear or continuous metrics yield smooth, predictable changes in model performance. This hypothesis is tested and confirmed using the InstructGPT/GPT-3 family and BIG-Bench tasks, and by demonstrating how metric choice can produce seemingly emergent abilities in vision tasks across diverse deep networks."}, "takeaways": {"headline": "Choice of metric can influence perceived emergent abilities in LLMs", "description": "The paper's findings suggest that the choice of metric can significantly influence the perceived emergent abilities in LLMs. This insight can help practitioners better understand and interpret the performance of their models. It also highlights the importance of careful metric selection in evaluating model performance. Practitioners should be aware that emergent abilities might not be a fundamental property of scaling AI models, but rather a result of the metrics used for evaluation.", "example": "For instance, if a practitioner is evaluating an LLM's performance on a task and observes a sudden improvement (an 'emergent ability'), they should consider whether this is due to a fundamental change in the model's behavior or simply a result of the chosen metric. If the latter, they might want to re-evaluate using a different, perhaps more linear, metric."}, "category": "BEHAVIOR", "novelty_analysis": "The paper presents a novel perspective on the emergent abilities of LLMs, challenging the prevailing belief that these abilities are a result of model scaling. The authors' proposition that these abilities may be an artifact of metric choice is a fresh and significant contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it delves into the mathematical explanation of the authors' hypothesis and presents detailed analyses to test this hypothesis. However, the concepts are explained clearly, making it accessible to readers with a basic understanding of machine learning and metrics.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an intriguing argument that challenges conventional wisdom in the field. The clear presentation of the hypothesis, the detailed analyses, and the implications of the findings make it an engaging read.", "enjoyable_score": 3}