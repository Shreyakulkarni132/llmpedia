{"Published": "2023-05-22", "Title": "Are Emergent Abilities of Large Language Models a Mirage?", "Authors": "Rylan Schaeffer, Brando Miranda, Sanmi Koyejo", "Summary": "Recent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due to the researcher's choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities; (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.", "main_contribution": {"headline": "Emergent abilities in LLMs may be an artifact of metric choice", "description": "The paper challenges the notion of emergent abilities in Large Language Models (LLMs), suggesting that these abilities may not be a fundamental property of scaling AI models. The authors propose that emergent abilities could be an artifact of the researcher's choice of metric rather than due to fundamental changes in model behavior with scale. They argue that nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, predictable changes in model performance. This hypothesis is tested and confirmed using the InstructGPT/GPT-3 family and BIG-Bench tasks."}, "takeaways": {"headline": "Choice of metric can influence perceived emergent abilities in LLMs", "description": "The paper suggests that the choice of metric can significantly influence the perceived emergent abilities in LLMs. This insight can help practitioners be more critical and cautious when interpreting the performance of LLMs, especially when scaling up models. It also highlights the importance of choosing appropriate metrics that align with the specific goals of a task or application. Practitioners should consider using linear or continuous metrics to observe smooth, predictable changes in model performance, rather than being misled by apparent emergent abilities produced by nonlinear or discontinuous metrics.", "example": "For instance, if a practitioner is working on a task with the GPT-3 model and observes a sudden improvement in performance at a larger scale, they should consider whether this is due to a fundamental change in the model's behavior or simply an artifact of the chosen metric. By switching to a linear or continuous metric, they might observe a smoother, more predictable change in performance."}, "category": "BEHAVIOR", "novelty_analysis": "The paper presents a novel perspective on the concept of emergent abilities in LLMs, challenging the prevailing understanding and suggesting that these abilities may be an artifact of metric choice rather than a fundamental property of model scaling.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, presenting a mathematical model to explain the alternative explanation for emergent abilities and conducting several analyses to test this hypothesis. However, the concepts are explained clearly, making it accessible to readers with a basic understanding of AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an intriguing challenge to the prevailing understanding of emergent abilities in LLMs. The clear explanation of concepts and thorough testing of the hypothesis make it an engaging read.", "enjoyable_score": 3}