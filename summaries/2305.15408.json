{"Published": "2023-06-28", "Title": "Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective", "Authors": "Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang", "Summary": "Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the expressivity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language format. Moreover, we show LLMs with CoT are capable of solving a general class of decision-making problems known as Dynamic Programming, thus justifying its power in tackling complex real-world tasks. Finally, extensive experiments on four tasks show that, while Transformers always fail to predict the answers directly, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations.", "main_contribution": {"headline": "Theoretical insights into Chain-of-Thought prompting's impact on LLMs", "description": "This paper provides a theoretical examination of the Chain-of-Thought (CoT) prompting technique's impact on Large Language Models (LLMs), particularly in mathematical and decision-making tasks. The authors demonstrate that bounded-depth Transformers struggle to directly produce correct answers for basic arithmetic or equation tasks unless the model size grows super-polynomially with respect to the input length. However, they prove that autoregressive Transformers of constant size can solve these tasks by generating CoT derivations. They also show that LLMs with CoT can solve a general class of decision-making problems known as Dynamic Programming, thus justifying its power in tackling complex real-world tasks."}, "takeaways": {"headline": "CoT prompting enhances LLMs' performance in complex tasks", "description": "The paper's findings suggest that the CoT prompting technique can significantly enhance the performance of LLMs in complex tasks, particularly those involving mathematics or reasoning. By generating CoT derivations, even autoregressive Transformers of constant size can solve these tasks. This insight could be valuable for LLM practitioners working on complex problem-solving tasks, as it suggests that using CoT prompting could lead to better results. However, it's important to note that sufficient CoT demonstrations are required for the model to learn to generate correct solutions step-by-step.", "example": "For instance, when working on a complex mathematical task, an LLM practitioner could use CoT prompting to guide the model to generate intermediate derivations, which could lead to the correct final answer. This could be done by adding special phrases such as 'let's think step by step' or by giving few-shot CoT demonstrations."}, "category": "PROMPTING", "novelty_analysis": "The paper provides a theoretical examination of the CoT prompting technique's impact on LLMs, which is a novel approach. While the CoT prompting technique itself is not new, the authors' theoretical analysis of its impact on LLMs' performance in complex tasks is a significant contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is highly technical, as it involves a theoretical analysis of the CoT prompting technique's impact on LLMs. It requires a deep understanding of LLMs, Transformers, and the CoT prompting technique, as well as a strong background in mathematics and decision-making problems.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and provides valuable insights into the CoT prompting technique's impact on LLMs. However, its highly technical nature and focus on theoretical analysis may make it less enjoyable for readers without a strong background in the field.", "enjoyable_score": 2}