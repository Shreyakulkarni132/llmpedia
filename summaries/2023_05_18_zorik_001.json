{"Published": "2023-05-18", "Title": "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models", "Authors": "Zorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen Elkind, Idan Szpektor", "Summary": "Factual consistency evaluation is often conducted using Natural Language Inference (NLI) models, yet these models exhibit limited success in evaluating summaries. Previous work improved such models with synthetic training data. However, the data is typically based on perturbed human-written summaries, which often differ in their characteristics from real model-generated summaries and have limited coverage of possible factual errors. Alternatively, large language models (LLMs) have recently shown promising results in directly evaluating generative tasks, but are too computationally expensive for practical use. Motivated by these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM. Unlike prior work, TrueTeacher does not rely on human-written summaries, and is multilingual by nature. Experiments on the TRUE benchmark show that a student model trained using our data, substantially outperforms both the state-of-the-art model with similar capacity, and the LLM teacher. In a systematic study, we compare TrueTeacher to existing synthetic data generation methods and demonstrate its superiority and robustness to domain-shift. Using the the mFACE dataset, we also show that our method generalizes to multilingual scenarios. Finally, we release a large-scale synthetic dataset with 1.4M examples generated using TrueTeacher.", "main_contribution": {"headline": "TrueTeacher: A novel method for generating synthetic data for factual consistency evaluation", "description": "The paper introduces TrueTeacher, a new method for generating synthetic data to train models for factual consistency evaluation. Unlike previous methods that rely on human-written summaries, TrueTeacher uses a Large Language Model (LLM) to annotate diverse model-generated summaries. This approach is multilingual and does not suffer from the limitations of human-written summaries, such as style differences and limited coverage of factual errors. The authors demonstrate that a student model trained using TrueTeacher's data outperforms both the state-of-the-art model and the LLM teacher."}, "takeaways": {"headline": "TrueTeacher offers a robust and scalable approach to factual consistency evaluation", "description": "TrueTeacher's method of generating synthetic data using LLMs can significantly improve the performance of models used for factual consistency evaluation. This approach is particularly useful for LLM practitioners working on tasks that require the evaluation of factual consistency, such as summarization. The multilingual nature of TrueTeacher also makes it applicable to a wide range of languages and domains. Furthermore, the authors have released a large-scale synthetic dataset with 1.4M examples generated using TrueTeacher, which can be used for further research and development.", "example": "For instance, an LLM practitioner working on a multilingual summarization task can use the TrueTeacher method to generate synthetic data for training a model to evaluate the factual consistency of the generated summaries. This can lead to more accurate and reliable summarization results."}, "category": "TRAINING", "novelty_analysis": "TrueTeacher presents a novel approach to generating synthetic data for factual consistency evaluation. Unlike previous methods, it uses an LLM to annotate model-generated summaries, which overcomes the limitations of human-written summaries. This approach is also multilingual, making it applicable to a wide range of languages and domains.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it introduces a new method for generating synthetic data and provides a detailed comparison of this method with existing ones. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel and interesting approach to a challenging problem. The comparison with existing methods and the presentation of experimental results make it an engaging read for those interested in the field of LLMs and factual consistency evaluation.", "enjoyable_score": 2}