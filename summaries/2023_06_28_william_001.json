{"Published": "2023-06-28", "Title": "Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language", "Authors": "William Berrios, Gautam Mittal, Tristan Thrush, Douwe Kiela, Amanpreet Singh", "Summary": "We propose LENS, a modular approach for tackling computer vision problems by leveraging the power of large language models (LLMs). Our system uses a language model to reason over outputs from a set of independent and highly descriptive vision modules that provide exhaustive information about an image. We evaluate the approach on pure computer vision settings such as zero- and few-shot object recognition, as well as on vision and language problems. LENS can be applied to any off-the-shelf LLM and we find that the LLMs with LENS perform highly competitively with much bigger and much more sophisticated systems, without any multimodal training whatsoever. We open-source our code at https://github.com/ContextualAI/lens and provide an interactive demo.", "main_contribution": {"headline": "LENS: A Modular Approach for Vision Tasks Using Large Language Models", "description": "The paper introduces LENS (Large Language Models ENhanced to See), a modular approach that leverages large language models (LLMs) to tackle computer vision problems. LENS uses a language model to reason over outputs from a set of independent vision modules that provide exhaustive information about an image. The approach is evaluated on pure computer vision settings such as zero- and few-shot object recognition, as well as on vision and language problems. LENS can be applied to any off-the-shelf LLM and the authors find that the LLMs with LENS perform highly competitively with much bigger and much more sophisticated systems, without any multimodal training. The approach eliminates the need for extra multimodal pretraining stages or data, bridging the gap between the modalities at zero cost."}, "takeaways": {"headline": "LENS Enables Vision Capabilities in LLMs Without Additional Training", "description": "LENS provides a practical way to add vision capabilities to any off-the-shelf LLM without requiring additional training or data. It uses a set of independent vision modules to extract rich textual information from images, which is then fed into the LLM to perform object recognition and vision and language tasks. This approach allows practitioners to leverage the latest advancements in both computer vision and natural language processing out of the box, maximizing the benefits derived from these fields. The open-source code and interactive demo provided by the authors make it easy for practitioners to apply LENS in their own projects.", "example": "For instance, given an image of a dog on a surfboard, LENS can extract information such as tags (e.g., 'surfing', 'surfer', 'dog'), attributes (e.g., 'pug dog with double-coated fur', 'surfboard with leash attached to the tail'), and captions (e.g., 'a dog is sitting on a surf board in the water'). This information can then be fed into an LLM to answer questions about the image, such as 'What is the breed of the dog?' and 'What is the dog doing?'."}, "category": "USE CASES", "novelty_analysis": "LENS presents a novel approach to leveraging the power of LLMs for computer vision tasks. While previous methods have used LLMs for vision-related tasks, LENS is unique in its use of independent vision modules to extract detailed textual information from images, which is then fed into the LLM. This approach eliminates the need for additional multimodal pretraining stages or data, making it a significant contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it delves into the specifics of how LENS uses vision modules to extract textual information from images and how this information is used by the LLM. However, the authors do a good job of explaining these concepts in a clear and understandable way, making the paper accessible to readers with a basic understanding of LLMs and computer vision.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and clearly written, making it an enjoyable read. The authors provide a thorough explanation of the LENS approach and its benefits, and they support their claims with experimental results. The inclusion of an interactive demo also adds to the paper's appeal, as it allows readers to see LENS in action.", "enjoyable_score": 3}