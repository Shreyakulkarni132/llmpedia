{"Published": "2023-06-13", "Title": "Questioning the Survey Responses of Large Language Models", "Authors": "Ricardo Dominguez-Olmedo, Moritz Hardt, Celestine Mendler-D\u00fcnner", "Summary": "As large language models increase in capability, researchers have started to conduct surveys of all kinds on these models with varying scientific motivations. In this work, we examine what we can learn from a model's survey responses on the basis of the well-established American Community Survey (ACS) by the U.S. Census Bureau. Evaluating more than a dozen different models, varying in size from a few hundred million to ten billion parameters, hundreds of thousands of times each on questions from the ACS, we systematically establish two dominant patterns. First, smaller models have a significant position and labeling bias, for example, towards survey responses labeled with the letter \"A\". This A-bias diminishes, albeit slowly, as model size increases. Second, when adjusting for this labeling bias through randomized answer ordering, models still do not trend toward US population statistics or those of any cognizable population. Rather, models across the board trend toward uniformly random aggregate statistics over survey responses. This pattern is robust to various different ways of prompting the model, including what is the de-facto standard. Our findings demonstrate that aggregate statistics of a language model's survey responses lack the signals found in human populations. This absence of statistical signal cautions about the use of survey responses from large language models at present time.", "main_contribution": {"headline": "Large Language Models' Survey Responses Do Not Resemble Human Populations", "description": "The paper investigates the survey responses of large language models (LLMs) using the American Community Survey (ACS) by the U.S. Census Bureau. The authors find two dominant patterns: smaller models exhibit a significant position and labeling bias, and even after adjusting for this bias, models do not trend toward US population statistics or those of any recognizable population. Instead, they trend toward uniformly random aggregate statistics over survey responses. This suggests that the aggregate statistics of a language model's survey responses lack the signals found in human populations."}, "takeaways": {"headline": "LLMs' Survey Responses Lack Human-Like Statistical Signals", "description": "The findings caution against using survey responses from LLMs as they do not resemble those of human populations. This is important for practitioners who might be considering using LLMs for survey-based tasks or applications. The study also highlights the need for further research to understand and potentially correct these biases in LLMs. The findings could also be used to improve the design and training of future models to better mimic human-like responses in surveys.", "example": "For instance, if an LLM is being used to simulate human responses in a survey-based application, the practitioner should be aware that the model's responses may not accurately represent a human population. Instead, they may need to implement additional measures to adjust for the model's inherent biases."}, "category": "BEHAVIOR", "novelty_analysis": "The paper presents a novel investigation into the survey responses of LLMs, revealing significant biases and a lack of resemblance to human population statistics. This is a unique contribution to the understanding of LLM behavior in the context of survey responses.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, requiring a basic understanding of language models and survey methodology. However, it does not delve into complex mathematical theories or algorithms, making it accessible to a wider audience with a basic understanding of AI and ML.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting investigation into the behavior of LLMs. The findings are intriguing and have significant implications for the use of LLMs in survey-based applications, making it an engaging read for practitioners in the field.", "enjoyable_score": 2}