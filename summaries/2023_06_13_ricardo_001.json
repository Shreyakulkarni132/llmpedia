{"Published": "2023-06-13", "Title": "Questioning the Survey Responses of Large Language Models", "Authors": "Ricardo Dominguez-Olmedo, Moritz Hardt, Celestine Mendler-D\u00fcnner", "Summary": "As large language models increase in capability, researchers have started to conduct surveys of all kinds on these models with varying scientific motivations. In this work, we examine what we can learn from a model's survey responses on the basis of the well-established American Community Survey (ACS) by the U.S. Census Bureau. Evaluating more than a dozen different models, varying in size from a few hundred million to ten billion parameters, hundreds of thousands of times each on questions from the ACS, we systematically establish two dominant patterns. First, smaller models have a significant position and labeling bias, for example, towards survey responses labeled with the letter \"A\". This A-bias diminishes, albeit slowly, as model size increases. Second, when adjusting for this labeling bias through randomized answer ordering, models still do not trend toward US population statistics or those of any cognizable population. Rather, models across the board trend toward uniformly random aggregate statistics over survey responses. This pattern is robust to various different ways of prompting the model, including what is the de-facto standard. Our findings demonstrate that aggregate statistics of a language model's survey responses lack the signals found in human populations. This absence of statistical signal cautions about the use of survey responses from large language models at present time.", "main_contribution": "The paper investigates the responses of large language models (LLMs) to survey questions, specifically those from the American Community Survey (ACS) by the U.S. Census Bureau. The authors find two dominant patterns: smaller models exhibit a significant position and labeling bias, and even when adjusting for this bias, models do not trend toward US population statistics or those of any recognizable population. Instead, they trend toward uniformly random aggregate statistics over survey responses. These findings suggest that the aggregate statistics of a language model's survey responses lack the signals found in human populations.", "takeaways": "The findings of this paper caution against the use of survey responses from large language models, as they do not accurately reflect the statistics of human populations. This has implications for researchers and practitioners who may be considering using LLMs for survey-based tasks or for generating population-level insights. The observed biases and trends also highlight the need for further research into understanding and mitigating these issues.", "novelty_analysis": "The paper presents a novel investigation into the survey responses of LLMs, a topic that has not been extensively studied before. The findings challenge the assumption that LLMs can accurately reflect human population statistics in their responses, providing new insights into the limitations of these models.", "novelty_score": 3, "category": "BEHAVIOR", "technical_analysis": "The paper is somewhat technical, as it involves a detailed analysis of the responses of LLMs to survey questions. However, the concepts and methodologies used are well-explained and should be understandable to someone with a background in AI or machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting investigation into the behavior of LLMs. The findings are insightful and have important implications for the use of these models in survey-based tasks, making it an engaging read for those interested in the field.", "enjoyable_score": 3}