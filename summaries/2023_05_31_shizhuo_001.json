{"Published": "2023-05-31", "Title": "Getting More out of Large Language Models for Proofs", "Authors": "Shizhuo Dylan Zhang, Talia Ringer, Emily First", "Summary": "Large language models have the potential to simplify formal theorem proving and make it more accessible. But how to get the most out of these models is still an open question. To answer this question, we take a step back and explore the failure cases of these models using common prompting-based techniques. Our talk will discuss these failure cases and what they can teach us about how to get more out of these models.", "main_contribution": "The paper investigates the failure cases of large language models (LLMs) in formal theorem proving, specifically using GPT-3.5 Turbo and GPT-4 to prove theorems in Coq. The authors conduct a fine-grained analysis of model outputs, focusing on how these outputs commonly go wrong. Based on their findings, they recommend allowing the model to prompt the proof assistant for more information and giving the model access to proof states to improve the performance of LLMs in theorem proving.", "takeaways": "The paper provides valuable insights into the limitations of LLMs in formal theorem proving and offers practical recommendations to overcome these limitations. By allowing the model to request more information and access proof states, practitioners can potentially improve the performance of LLMs in theorem proving tasks. These findings can guide the development of more effective LLM-based theorem proving systems.", "novelty_analysis": "While the use of LLMs in theorem proving is not new, the paper's focus on understanding failure cases and deriving practical recommendations based on these failures provides a unique perspective. The detailed analysis of model outputs and the proposed solutions to common failure cases contribute to the existing body of knowledge on LLMs and theorem proving.", "novelty_score": 2, "category": "BEHAVIOR", "technical_analysis": "The paper is somewhat technical, requiring a basic understanding of large language models and formal theorem proving. However, the authors provide clear explanations and examples, making the content accessible to readers with a computer science background.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and provides a clear analysis of the limitations of LLMs in theorem proving. The focus on failure cases and the practical recommendations make the paper interesting and insightful. However, the technical nature of the content may limit its appeal to a broader audience.", "enjoyable_score": 2}