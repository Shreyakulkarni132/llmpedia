{"Published": "2023-05-07", "Title": "Shortcut Learning of Large Language Models in Natural Language Understanding", "Authors": "Mengnan Du, Fengxiang He, Na Zou, Dacheng Tao, Xia Hu", "Summary": "Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However, these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly affected their generalizability and adversarial robustness. In this paper, we provide a review of recent developments that address the shortcut learning and robustness challenge of LLMs. We first introduce the concepts of shortcut learning of language models. We then introduce methods to identify shortcut learning behavior in language models, characterize the reasons for shortcut learning, as well as introduce mitigation solutions. Finally, we discuss key research challenges and potential research directions in order to advance the field of LLMs.", "main_contribution": "The paper provides a comprehensive review of the recent developments that address the shortcut learning and robustness challenge of Large Language Models (LLMs). It introduces the concept of shortcut learning in language models, discusses methods to identify such behavior, and characterizes the reasons behind it. The paper also presents mitigation solutions to address shortcut learning and discusses key research challenges and potential research directions to advance the field of LLMs.", "takeaways": "The paper offers valuable insights into the issues of dataset bias and artifacts that LLMs might rely on as shortcuts for prediction, affecting their generalizability and adversarial robustness. The review of methods to identify and mitigate shortcut learning behavior can guide practitioners in improving the robustness of their models. The discussion on research challenges and potential directions can help shape future research in the field.", "novelty_analysis": "While the paper does not introduce a new algorithm or technique, it provides a comprehensive review of the recent developments in the field of shortcut learning in LLMs. The novelty lies in the synthesis of the current knowledge and the identification of future research directions.", "novelty_score": 2, "category": "BEHAVIOR", "technical_analysis": "The paper is somewhat technical as it discusses the concept of shortcut learning in LLMs, the methods to identify such behavior, and the reasons behind it. However, it does not delve into the technical details of the algorithms or techniques used.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and provides a comprehensive review of the field, making it an enjoyable read for those interested in the behavior of LLMs and their robustness. However, the lack of a new algorithm or technique might make it less exciting for some readers.", "enjoyable_score": 2}