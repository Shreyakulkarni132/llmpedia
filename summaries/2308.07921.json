{"Published": "2023-08-15", "Title": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification", "Authors": "Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, Hongsheng Li", "Summary": "Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has brought significant advancements in addressing math reasoning problems. In particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter, shows remarkable performance on challenging math datasets. In this paper, we explore the effect of code on enhancing LLMs' reasoning capability by introducing different constraints on the \\textit{Code Usage Frequency} of GPT-4 Code Interpreter. We found that its success can be largely attributed to its powerful skills in generating and executing code, evaluating the output of code execution, and rectifying its solution when receiving unreasonable outputs. Based on this insight, we propose a novel and effective prompting method, explicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further boost the mathematical reasoning potential of GPT-4 Code Interpreter. This method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to use code to self-verify its answers. In instances where the verification state registers as ``False'', the model shall automatically amend its solution, analogous to our approach of rectifying errors during a mathematics examination. Furthermore, we recognize that the states of the verification result indicate the confidence of a solution, which can improve the effectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we achieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$ 84.3\\%)}.", "main_contribution": {"headline": "Boosting Mathematical Reasoning in LLMs with Code-based Self-Verification", "description": "This paper explores the impact of code usage on the reasoning capabilities of Large Language Models (LLMs), specifically focusing on OpenAI's GPT-4 Code Interpreter. The authors introduce the concept of Code Usage Frequency and find that the model's success in solving math problems is largely due to its ability to generate and execute code, evaluate the output, and rectify its solution when receiving unreasonable outputs. Based on these insights, they propose a novel prompting method, explicit code-based self-verification (CSV), which encourages the model to use code to self-verify its answers. This method significantly boosts the mathematical reasoning potential of GPT-4 Code Interpreter, achieving an impressive zero-shot accuracy on the MATH dataset."}, "takeaways": {"headline": "Code-based Self-Verification Enhances LLMs' Mathematical Reasoning", "description": "The paper demonstrates that the use of code-based self-verification can significantly improve the mathematical reasoning capabilities of LLMs. This approach not only enhances the accuracy of the model's solutions but also improves the effectiveness of majority voting by integrating the verification states. The authors' method can be particularly useful for practitioners working on complex mathematical reasoning tasks with LLMs. The proposed method is also beneficial for creating high-quality datasets that can help improve the mathematical capabilities of open-source LLMs.", "example": "For example, when solving a complex mathematical problem, an LLM equipped with the proposed CSV method would generate a solution, then use code to verify the correctness of the solution. If the verification result is 'False', the model would automatically adjust its solution, similar to how we correct errors during a math examination. This process significantly improves the accuracy of the model's solutions."}, "category": "PROMPTING", "novelty_analysis": "The paper presents a novel approach to enhancing the mathematical reasoning capabilities of LLMs by introducing the concept of Code Usage Frequency and proposing a new prompting method, explicit code-based self-verification. This method leverages the model's ability to generate and execute code, evaluate the output, and rectify its solution, leading to significant improvements in accuracy on the MATH dataset.", "novelty_score": 3, "technical_analysis": "The paper is highly technical, delving into the inner workings of GPT-4 Code Interpreter and presenting a detailed analysis of how code usage impacts the model's reasoning capabilities. It introduces new concepts such as Code Usage Frequency and explicit code-based self-verification, and provides a thorough explanation of the proposed method and its implementation.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and presents a clear narrative, making it an engaging read for those interested in the application of LLMs in mathematical reasoning. The authors' systematic analysis of code usage and their innovative approach to boosting the model's performance provide valuable insights and make the paper a compelling read.", "enjoyable_score": 3}