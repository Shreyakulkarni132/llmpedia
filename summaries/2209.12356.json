{"Published": "2023-05-23", "Title": "News Summarization and Evaluation in the Era of GPT-3", "Authors": "Tanya Goyal, Junyi Jessy Li, Greg Durrett", "Summary": "The recent success of prompting large language models like GPT-3 has led to a paradigm shift in NLP research. In this paper, we study its impact on text summarization, focusing on the classic benchmark domain of news summarization. First, we investigate how GPT-3 compares against fine-tuned models trained on large summarization datasets. We show that not only do humans overwhelmingly prefer GPT-3 summaries, prompted using only a task description, but these also do not suffer from common dataset-specific issues such as poor factuality. Next, we study what this means for evaluation, particularly the role of gold standard test sets. Our experiments show that both reference-based and reference-free automatic metrics cannot reliably evaluate GPT-3 summaries. Finally, we evaluate models on a setting beyond generic summarization, specifically keyword-based summarization, and show how dominant fine-tuning approaches compare to prompting.   To support further research, we release: (a) a corpus of 10K generated summaries from fine-tuned and prompt-based models across 4 standard summarization benchmarks, (b) 1K human preference judgments comparing different systems for generic- and keyword-based summarization.", "main_contribution": {"headline": "GPT-3 outperforms fine-tuned models in news summarization", "description": "This paper presents a comprehensive study of the impact of GPT-3, a large language model, on text summarization, specifically focusing on news summarization. The authors show that GPT-3, when prompted with only a task description, generates summaries that are preferred by humans over those produced by fine-tuned models trained on large summarization datasets. Furthermore, GPT-3 summaries do not suffer from common dataset-specific issues such as poor factuality. The paper also highlights the limitations of both reference-based and reference-free automatic metrics in evaluating GPT-3 summaries."}, "takeaways": {"headline": "GPT-3 offers superior performance in news summarization tasks", "description": "The findings of this paper suggest that GPT-3 can be effectively used for news summarization tasks, producing summaries that are preferred by humans and do not suffer from dataset-specific issues. This indicates that GPT-3 could be a valuable tool for practitioners working on text summarization tasks, particularly in the news domain. However, the paper also highlights the need for more reliable evaluation metrics for GPT-3 summaries.", "example": "For instance, an LLM practitioner working on a news summarization application could use GPT-3 and prompt it with a task description to generate summaries. However, they should be aware of the limitations of current automatic metrics in evaluating these summaries and consider incorporating human evaluation in their workflow."}, "category": "USE CASES", "novelty_analysis": "The paper provides a systematic study of the impact of GPT-3 on text summarization, which has not been extensively studied before. The findings that GPT-3 outperforms fine-tuned models in news summarization and that current automatic metrics are not reliable for evaluating GPT-3 summaries are novel contributions.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it involves a detailed study of GPT-3's performance on text summarization tasks and an evaluation of different metrics. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a background in NLP and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents interesting findings about GPT-3's performance on text summarization tasks. However, the discussion on the limitations of automatic metrics might be less engaging for readers not interested in evaluation metrics.", "enjoyable_score": 2}