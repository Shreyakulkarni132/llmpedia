{"Published": "2023-07-05", "Title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes", "Authors": "Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, Tomas Pfister", "Summary": "Deploying large language models (LLMs) is challenging because they are memory inefficient and compute-intensive for practical applications. In reaction, researchers train smaller task-specific models by either finetuning with human labels or distilling using LLM-generated labels. However, finetuning and distillation require large amounts of training data to achieve comparable performance to LLMs. We introduce Distilling step-by-step, a new mechanism that (a) trains smaller models that outperform LLMs, and (b) achieves so by leveraging less training data needed by finetuning or distillation. Our method extracts LLM rationales as additional supervision for training small models within a multi-task framework. We present three findings across 4 NLP benchmarks: First, compared to both finetuning and distillation, our mechanism achieves better performance with much fewer labeled/unlabeled training examples. Second, compared to few-shot prompted LLMs, we achieve better performance using substantially smaller model sizes. Third, we reduce both the model size and the amount of data required to outperform LLMs; our finetuned 770M T5 model outperforms the few-shot prompted 540B PaLM model using only 80% of available data on a benchmark, whereas standard finetuning the same T5 model struggles to match even by using 100% of the dataset. We release the code at: https://github.com/google-research/distilling-step-by-step .", "main_contribution": {"headline": "Distilling Step-by-Step: A New Mechanism for Training Smaller, More Efficient Language Models", "description": "The paper introduces a novel mechanism, Distilling step-by-step, for training smaller language models that outperform larger language models (LLMs) while using less training data. This method leverages the rationales generated by LLMs as additional supervision for training smaller models within a multi-task framework. The authors demonstrate that their mechanism achieves better performance with fewer labeled/unlabeled training examples compared to both finetuning and distillation. Furthermore, they show that their method can achieve better performance using substantially smaller model sizes compared to few-shot prompted LLMs. The authors also demonstrate that their method reduces both the model size and the amount of data required to outperform LLMs."}, "takeaways": {"headline": "Efficient Training of Smaller Language Models with Comparable Performance to LLMs", "description": "The Distilling step-by-step mechanism provides a new approach to training smaller language models that can outperform larger models while using less training data. This approach can be particularly beneficial for applications that require low latency performance and cannot afford the computational requirements of larger models. The authors' findings suggest that this method can be used to improve the efficiency of language model training, reducing both the computational resources required and the amount of training data needed. This could potentially lead to significant cost savings in the deployment of language models in practical applications.", "example": "For example, a smaller model trained using the Distilling step-by-step mechanism could be used in a real-time chatbot application, where low latency is crucial. The smaller model would require less computational resources and less training data, making it more cost-effective to deploy."}, "category": "TRAINING", "novelty_analysis": "The paper presents a novel mechanism for training smaller language models that outperform larger models while using less training data. This represents a significant advancement in the field of language model training, providing a new approach that can improve efficiency and reduce costs.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it introduces a new mechanism for training language models and presents detailed experimental results. However, the authors explain their method and findings clearly, making the paper accessible to readers with a basic understanding of language models and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an interesting and novel approach to language model training. The authors' findings are clearly presented and have significant practical implications, making the paper an engaging read for those interested in the field of language models.", "enjoyable_score": 2}