{"Published": "2023-05-24", "Title": "Gorilla: Large Language Model Connected with Massive APIs", "Authors": "Shishir G. Patil, Tianjun Zhang, Xin Wang, Joseph E. Gonzalez", "Summary": "Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis. However, their potential to effectively use tools via API calls remains unfulfilled. This is a challenging task even for today's state-of-the-art LLMs such as GPT-4, largely due to their inability to generate accurate input arguments and their tendency to hallucinate the wrong usage of an API call. We release Gorilla, a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls. When combined with a document retriever, Gorilla demonstrates a strong capability to adapt to test-time document changes, enabling flexible user updates or version changes. It also substantially mitigates the issue of hallucination, commonly encountered when prompting LLMs directly. To evaluate the model's ability, we introduce APIBench, a comprehensive dataset consisting of HuggingFace, TorchHub, and TensorHub APIs. The successful integration of the retrieval system with Gorilla demonstrates the potential for LLMs to use tools more accurately, keep up with frequently updated documentation, and consequently increase the reliability and applicability of their outputs. Gorilla's code, model, data, and demo are available at https://gorilla.cs.berkeley.edu", "main_contribution": {"headline": "Gorilla: A Fine-tuned LLaMA-based Model for Accurate API Calls", "description": "The paper introduces Gorilla, a fine-tuned LLaMA-based model that outperforms GPT-4 in generating accurate API calls. The authors address the challenge of LLMs' inability to effectively use tools via API calls due to their tendency to generate inaccurate input arguments and hallucinate wrong API usage. Gorilla, when combined with a document retriever, adapts to test-time document changes, enabling flexible user updates or version changes. It also significantly reduces the issue of hallucination, a common problem when prompting LLMs directly. The authors introduce APIBench, a comprehensive dataset of HuggingFace, TorchHub, and TensorHub APIs, to evaluate Gorilla's performance."}, "takeaways": {"headline": "Gorilla Enhances LLMs' Ability to Accurately Use Tools via API Calls", "description": "Gorilla's successful integration with a retrieval system demonstrates the potential for LLMs to use tools more accurately and keep up with frequently updated documentation, thereby increasing the reliability and applicability of their outputs. The model's ability to adapt to changes in API documentation and understand and reason about constraints is particularly noteworthy. This work opens up new possibilities for LLMs to interact with APIs, potentially covering a wide range of applications.", "example": "For instance, given a user prompt like 'Help me find an API to convert the spoken language in a recorded audio to text using Torch Hub', Gorilla can accurately suggest a fully-qualified API call, such as 'asr_model = torch.hub.load('snakers4/silero-models', 'silero_sst'); result = asr_model.transcribe(audio_path)'."}, "category": "FINE-TUNING", "novelty_analysis": "The introduction of Gorilla, a fine-tuned LLaMA-based model specifically designed for generating accurate API calls, represents a significant advancement in the field. The model's ability to adapt to test-time document changes and understand constraints is particularly novel. The introduction of APIBench, a comprehensive dataset for evaluating the model's performance, also adds to the novelty of the work.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, discussing the methodology behind Gorilla, the construction of APIBench, and the use of AST sub-tree matching for evaluation. However, the concepts are explained in a clear and accessible manner, making it understandable for readers with a background in AI and ML.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting and novel approach to enhancing the capabilities of LLMs. The clear explanation of the methodology and the presentation of results make it an engaging read for those interested in the application of LLMs.", "enjoyable_score": 3}