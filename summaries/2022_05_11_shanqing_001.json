{"Published": "2022-05-11", "Title": "Context-Aware Abbreviation Expansion Using Large Language Models", "Authors": "Shanqing Cai, Subhashini Venugopalan, Katrin Tomanek, Ajit Narayanan, Meredith Ringel Morris, Michael P. Brenner", "Summary": "Motivated by the need for accelerating text entry in augmentative and alternative communication (AAC) for people with severe motor impairments, we propose a paradigm in which phrases are abbreviated aggressively as primarily word-initial letters. Our approach is to expand the abbreviations into full-phrase options by leveraging conversation context with the power of pretrained large language models (LLMs). Through zero-shot, few-shot, and fine-tuning experiments on four public conversation datasets, we show that for replies to the initial turn of a dialog, an LLM with 64B parameters is able to exactly expand over 70% of phrases with abbreviation length up to 10, leading to an effective keystroke saving rate of up to about 77% on these exact expansions. Including a small amount of context in the form of a single conversation turn more than doubles abbreviation expansion accuracies compared to having no context, an effect that is more pronounced for longer phrases. Additionally, the robustness of models against typo noise can be enhanced through fine-tuning on noisy data.", "main_contribution": {"headline": "Context-aware abbreviation expansion using LLMs for efficient text entry", "description": "The paper introduces a novel approach to accelerate text entry, especially for people with severe motor impairments, by aggressively abbreviating phrases as primarily word-initial letters and expanding them using pretrained large language models (LLMs). The LLMs leverage the conversation context to accurately expand the abbreviations into full-phrase options. The paper demonstrates that an LLM with 64B parameters can accurately expand over 70% of phrases with abbreviation length up to 10, leading to an effective keystroke saving rate of up to 77%. The paper also shows that including a small amount of context in the form of a single conversation turn more than doubles abbreviation expansion accuracies compared to having no context."}, "takeaways": {"headline": "LLMs can be used for efficient text entry through context-aware abbreviation expansion", "description": "The paper's approach of using LLMs for context-aware abbreviation expansion can be applied to build systems that require efficient text entry, such as augmentative and alternative communication (AAC) systems for people with severe motor impairments. The approach can also be used to build systems that require efficient text entry on devices where typing is difficult, such as mobile phones. The paper also provides insights on how to enhance the robustness of models against typo noise through fine-tuning on noisy data.", "example": "For instance, an AAC system can be built where the user inputs abbreviated phrases. These phrases are then expanded into full-phrase options by an LLM that leverages the conversation context. The system can also be fine-tuned on noisy data to enhance its robustness against typo noise."}, "category": "USE CASES", "novelty_analysis": "The paper presents a novel application of LLMs for efficient text entry through context-aware abbreviation expansion. The approach is particularly innovative in its application to AAC systems for people with severe motor impairments, a field where efficient text entry is crucial.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it discusses the use of LLMs for context-aware abbreviation expansion and provides experimental results. However, it does not delve into complex mathematical theories or algorithms, making it accessible to a wider audience.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents a novel and intriguing application of LLMs. It balances technical details with easily digestible information and an interesting practical application, making it an enjoyable read.", "enjoyable_score": 3}