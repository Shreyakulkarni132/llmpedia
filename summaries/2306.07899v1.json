{"Published": "2023-06-13", "Title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks", "Authors": "Veniamin Veselovsky, Manoel Horta Ribeiro, Robert West", "Summary": "Large language models (LLMs) are remarkable data annotators. They can be used to generate high-fidelity supervised training data, as well as survey and experimental data. With the widespread adoption of LLMs, human gold--standard annotations are key to understanding the capabilities of LLMs and the validity of their results. However, crowdsourcing, an important, inexpensive way to obtain human annotations, may itself be impacted by LLMs, as crowd workers have financial incentives to use LLMs to increase their productivity and income. To investigate this concern, we conducted a case study on the prevalence of LLM usage by crowd workers. We reran an abstract summarization task from the literature on Amazon Mechanical Turk and, through a combination of keystroke detection and synthetic text classification, estimate that 33-46% of crowd workers used LLMs when completing the task. Although generalization to other, less LLM-friendly tasks is unclear, our results call for platforms, researchers, and crowd workers to find new ways to ensure that human data remain human, perhaps using the methodology proposed here as a stepping stone. Code/data: https://github.com/epfl-dlab/GPTurk", "main_contribution": {"headline": "Crowd workers widely use LLMs for text production tasks", "description": "The paper investigates the prevalence of Large Language Models (LLMs) usage by crowd workers, specifically on Amazon Mechanical Turk. The authors reran an abstract summarization task and used a combination of keystroke detection and synthetic text classification to estimate the extent of LLM usage. The study found that 33-46% of crowd workers used LLMs when completing the task. This finding raises concerns about the validity of human gold-standard data and calls for new ways to ensure that human data remain human."}, "takeaways": {"headline": "LLMs are widely used by crowd workers, impacting the validity of human gold-standard data", "description": "The widespread use of LLMs by crowd workers has implications for the validity of human gold-standard data. LLM practitioners and researchers need to be aware of this when using crowdsourced data for training or validation. The methodology used in this study, combining keystroke detection and synthetic text classification, could be a useful tool for detecting LLM usage in other contexts.", "example": "For instance, when collecting data for training an LLM, one could use a similar methodology to ensure that the data is genuinely human-generated and not produced by another LLM. This could involve monitoring keystrokes and using a synthetic-real classifier to detect LLM-generated text."}, "category": "BEHAVIOR", "novelty_analysis": "The paper presents a novel investigation into the use of LLMs by crowd workers. While the use of LLMs is not new, the extent of their use in this context and the potential implications for the validity of human gold-standard data is a novel contribution.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it involves the use of keystroke detection and synthetic text classification. However, the concepts are explained clearly and should be accessible to someone with a background in computer science or AI.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an interesting investigation into the use of LLMs by crowd workers. The implications of the findings are thought-provoking and relevant to anyone working with LLMs or crowdsourced data.", "enjoyable_score": 3}