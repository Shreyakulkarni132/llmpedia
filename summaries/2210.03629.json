{"Published": "2023-03-10", "Title": "ReAct: Synergizing Reasoning and Acting in Language Models", "Authors": "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao", "Summary": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io", "main_contribution": {"headline": "ReAct: A novel approach to synergize reasoning and acting in LLMs", "description": "The paper introduces ReAct, a novel approach that synergizes reasoning and acting in Large Language Models (LLMs). Unlike previous studies that have treated reasoning and acting as separate topics, ReAct interleaves these two aspects, allowing for a greater synergy. Reasoning traces help the model induce, track, and update action plans and handle exceptions, while actions allow the model to interface with external sources to gather additional information. The authors demonstrate the effectiveness of ReAct across a diverse set of language and decision-making tasks, showing improved performance over state-of-the-art baselines and enhanced human interpretability and trustworthiness."}, "takeaways": {"headline": "ReAct enhances LLMs' reasoning and acting capabilities for diverse tasks", "description": "ReAct presents a new way of leveraging LLMs for tasks that require both reasoning and acting. By interleaving these two aspects, ReAct can generate more human-like and interpretable task-solving trajectories. This approach can be particularly useful in tasks such as question answering and fact verification where the model needs to interact with external sources like a Wikipedia API. Furthermore, ReAct's superior performance on interactive decision-making benchmarks suggests its potential in improving the efficiency and effectiveness of LLMs in various applications.", "example": "For instance, in a question answering task, an LLM using ReAct could generate a reasoning trace like: 'The question asks about the capital of France -> I need to retrieve this information -> I interact with the Wikipedia API -> I find that the capital of France is Paris -> I generate the answer: Paris.' This process is more interpretable and trustworthy compared to a direct answer without a reasoning trace."}, "category": "PROMPTING", "novelty_analysis": "ReAct represents a significant advancement in the field of LLMs by synergizing reasoning and acting, which have traditionally been treated as separate topics. The approach's demonstrated effectiveness across a diverse set of tasks and its ability to improve human interpretability and trustworthiness make it a novel contribution.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it introduces a new approach, ReAct, and demonstrates its application across various tasks. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an intriguing contribution to the field of LLMs. The authors' exploration of the synergy between reasoning and acting in LLMs and the demonstration of ReAct's effectiveness across diverse tasks make the paper an interesting read.", "enjoyable_score": 3}