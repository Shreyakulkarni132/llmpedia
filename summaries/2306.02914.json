{"Published": "2023-06-05", "Title": "Beyond Generating Code: Evaluating GPT on a Data Visualization Course", "Authors": "Zhutian Chen, Chenyang Zhang, Qianwen Wang, Jakob Troidl, Simon Warchol, Johanna Beyer, Nils Gehlenborg, Hanspeter Pfister", "Summary": "This paper presents an empirical evaluation of the performance of the Generative Pre-trained Transformer (GPT) model in Harvard's CS171 data visualization course. While previous studies have focused on GPT's ability to generate code for visualizations, this study goes beyond code generation to evaluate GPT's abilities in various visualization tasks, such as data interpretation, visualization design, visual data exploration, and insight communication. The evaluation utilized GPT-3.5 and GPT-4 to complete assignments of CS171, and included a quantitative assessment based on the established course rubrics, a qualitative analysis informed by the feedback of three experienced graders, and an exploratory study of GPT's capabilities in completing border visualization tasks. Findings show that GPT-4 scored 80% on quizzes and homework, and TFs could distinguish between GPT- and human-generated homework with 70% accuracy. The study also demonstrates GPT's potential in completing various visualization tasks, such as data cleanup, interaction with visualizations, and insight communication. The paper concludes by discussing the strengths and limitations of GPT in data visualization, potential avenues for incorporating GPT in broader visualization tasks, and the need to redesign visualization education.", "main_contribution": {"headline": "Empirical Evaluation of GPT's Performance in Data Visualization Tasks", "description": "This paper presents a comprehensive evaluation of the Generative Pre-trained Transformer (GPT) model's performance in various data visualization tasks. The study goes beyond the traditional focus on GPT's code generation abilities, to assess its capabilities in data interpretation, visualization design, visual data exploration, and insight communication. The evaluation was conducted using GPT-3.5 and GPT-4 to complete assignments from Harvard's CS171 data visualization course. The findings reveal that GPT-4 scored 80% on quizzes and homework, and teaching fellows could distinguish between GPT- and human-generated homework with 70% accuracy. The study also highlights GPT's potential in completing various visualization tasks, such as data cleanup, interaction with visualizations, and insight communication."}, "takeaways": {"headline": "GPT Models Show Promise in Data Visualization Tasks", "description": "The paper's findings suggest that GPT models can be effectively used in various data visualization tasks. This includes data interpretation, visualization design, visual data exploration, and insight communication. For LLM practitioners, this opens up new avenues for using GPT models in data visualization tasks, potentially improving efficiency and accuracy. For instance, GPT models could be used to automate the process of data cleanup and visualization design, freeing up human resources for more complex tasks.", "example": "For example, an LLM practitioner could use a GPT model to clean a dataset and create an interactive visualization. The GPT model could then be used to interpret the visualization and communicate insights from the data. This could significantly streamline the data visualization process and improve the quality of the insights generated."}, "category": "USE CASES", "novelty_analysis": "The paper presents a novel approach to evaluating the performance of GPT models in data visualization tasks. While previous studies have focused on GPT's code generation abilities, this study provides a comprehensive evaluation of GPT's capabilities in various aspects of data visualization. This represents a significant advancement in the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, as it involves a detailed evaluation of GPT models' performance in data visualization tasks. However, the concepts and methodologies used in the study are explained clearly and comprehensively, making it accessible to readers with a basic understanding of LLMs and data visualization.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting and novel approach to evaluating GPT models. The findings are presented clearly and the implications for LLM practitioners are discussed in detail, making it an enjoyable and informative read.", "enjoyable_score": 3}