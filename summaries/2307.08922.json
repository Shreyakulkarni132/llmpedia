{"Published": "2023-07-18", "Title": "Large Language Models Perform Diagnostic Reasoning", "Authors": "Cheng-Kuang Wu, Wei-Lin Chen, Hsin-Hsi Chen", "Summary": "We explore the extension of chain-of-thought (CoT) prompting to medical reasoning for the task of automatic diagnosis. Motivated by doctors' underlying reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical results demonstrate that by simply prompting large language models trained only on general text corpus with two DR-CoT exemplars, the diagnostic accuracy improves by 15% comparing to standard prompting. Moreover, the gap reaches a pronounced 18% in out-domain settings. Our findings suggest expert-knowledge reasoning in large language models can be elicited through proper promptings.", "main_contribution": {"headline": "Diagnostic-Reasoning Chain of Thought (DR-CoT) improves LLMs for medical diagnosis", "description": "The paper introduces Diagnostic-Reasoning Chain of Thought (DR-CoT), an extension of the Chain-of-Thought (CoT) prompting technique, specifically designed for the task of automatic diagnosis (AD). DR-CoT is inspired by the reasoning process of doctors, where evidence is gathered, a differential diagnosis (DDx) is formed, and subsequent questions are based on this DDx. By prompting large language models (LLMs) with two DR-CoT exemplars, the authors demonstrate a significant improvement in diagnostic accuracy, outperforming standard prompting by 15% and even reaching an 18% improvement in out-domain settings."}, "takeaways": {"headline": "DR-CoT prompting offers a promising approach for LLMs in healthcare", "description": "The DR-CoT prompting technique presents a novel application for LLMs in the healthcare sector, specifically in the task of automatic diagnosis. By mimicking the reasoning process of doctors, DR-CoT allows LLMs to interact with patients in a more natural and effective manner, improving diagnostic accuracy. This technique could be particularly useful in telemedicine applications, where accurate and efficient diagnosis is crucial.", "example": "For instance, an LLM using DR-CoT prompts could be used in a telemedicine app. The model would interact with the patient, asking about their symptoms (e.g., 'Can you describe your pain?'), forming a differential diagnosis based on the responses, and then asking further questions based on this diagnosis (e.g., 'Have you experienced any nausea or vomiting?'). This process would continue until a final diagnosis is reached."}, "category": "PROMPTING", "novelty_analysis": "The paper introduces a novel extension of the CoT prompting technique, specifically tailored for the task of automatic diagnosis. This represents a significant advancement in the field, particularly in the application of LLMs in healthcare.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, discussing the implementation of the DR-CoT prompting technique and its application in a dialogue system for automatic diagnosis. However, the concepts are explained clearly and should be accessible to those with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an interesting and novel application of LLMs in healthcare. The clear explanation of the DR-CoT prompting technique and its potential impact on automatic diagnosis make it an engaging read.", "enjoyable_score": 3}