{"Published": "2023-06-21", "Title": "Understanding Social Reasoning in Language Models with Language Models", "Authors": "Kanishk Gandhi, Jan-Philipp Fr\u00e4nken, Tobias Gerstenberg, Noah D. Goodman", "Summary": "As Large Language Models (LLMs) become increasingly integrated into our everyday lives, understanding their ability to comprehend human mental states becomes critical for ensuring effective interactions. However, despite the recent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of LLMs, the degree to which these models can align with human ToM remains a nuanced topic of exploration. This is primarily due to two distinct challenges: (1) the presence of inconsistent results from previous evaluations, and (2) concerns surrounding the validity of existing evaluation methodologies. To address these challenges, we present a novel framework for procedurally generating evaluations with LLMs by populating causal templates. Using our framework, we create a new social reasoning benchmark (BigToM) for LLMs which consists of 25 controls and 5,000 model-written evaluations. We find that human participants rate the quality of our benchmark higher than previous crowd-sourced evaluations and comparable to expert-written evaluations. Using BigToM, we evaluate the social reasoning capabilities of a variety of LLMs and compare model performances with human performance. Our results suggest that GPT4 has ToM capabilities that mirror human inference patterns, though less reliable, while other LLMs struggle.", "main_contribution": "The paper introduces a novel framework for evaluating the social reasoning capabilities of Large Language Models (LLMs), addressing the challenges of inconsistent results and concerns about the validity of existing methodologies. The authors develop a new social reasoning benchmark, BigToM, which consists of 25 controls and 5,000 model-written evaluations. The paper also presents an evaluation of various LLMs using BigToM, with a focus on their Theory-of-Mind (ToM) capabilities.", "takeaways": "The new framework and benchmark provide a more reliable and valid method for evaluating the social reasoning capabilities of LLMs. This can help in understanding the strengths and weaknesses of different LLMs in terms of their ToM capabilities, which is crucial for their effective integration into everyday life. The evaluation results suggest that while GPT4 has ToM capabilities that mirror human inference patterns, it is less reliable, and other LLMs struggle with social reasoning.", "novelty_analysis": "The paper presents a novel approach to evaluating the social reasoning capabilities of LLMs, addressing the limitations of previous methodologies. The creation of the BigToM benchmark is a significant contribution, providing a more reliable and valid method for such evaluations. The evaluation of various LLMs using BigToM also provides new insights into their ToM capabilities.", "novelty_score": 3, "category": "BEHAVIOR", "technical_analysis": "The paper is somewhat technical, discussing the development of a new framework and benchmark for evaluating LLMs, and presenting an evaluation of various LLMs using this benchmark. However, the concepts and methods are explained clearly, making it accessible to those with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel and interesting contribution to the field. The clear explanations and insightful evaluation results make it an enjoyable read for those interested in the social reasoning capabilities of LLMs.", "enjoyable_score": 3}