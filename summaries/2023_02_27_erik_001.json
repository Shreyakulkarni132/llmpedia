{"Published": "2023-02-27", "Title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis", "Authors": "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong", "Summary": "Program synthesis strives to generate a computer program as a solution to a given problem specification, expressed with input-output examples or natural language descriptions. The prevalence of large language models advances the state-of-the-art for program synthesis, though limited training resources and data impede open access to such models. To democratize this, we train and release a family of large language models up to 16.1B parameters, called CODEGEN, on natural language and programming language data, and open source the training library JAXFORMER. We show the utility of the trained model by demonstrating that it is competitive with the previous state-of-the-art on zero-shot Python code generation on HumanEval. We further investigate the multi-step paradigm for program synthesis, where a single program is factorized into multiple prompts specifying subproblems. To this end, we construct an open benchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse problem sets that are factorized into multi-turn prompts. Our analysis on MTPB shows that the same intent provided to CODEGEN in multi-turn fashion significantly improves program synthesis over that provided as a single turn. We make the training library JAXFORMER and model checkpoints available as open source contribution: https://github.com/salesforce/CodeGen.", "main_contribution": "The paper introduces CODEGEN, a family of large language models trained on natural language and programming language data, with up to 16.1B parameters. The authors also present a new multi-step paradigm for program synthesis, where a single program is factorized into multiple prompts specifying subproblems. To facilitate this, they construct an open benchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse problem sets that are factorized into multi-turn prompts.", "takeaways": "CODEGEN demonstrates competitive performance with the previous state-of-the-art on zero-shot Python code generation on HumanEval. The multi-step paradigm for program synthesis, as demonstrated on MTPB, shows that providing the same intent to CODEGEN in a multi-turn fashion significantly improves program synthesis over that provided as a single turn. This suggests that breaking down complex programming tasks into smaller, manageable subproblems can enhance the performance of large language models in program synthesis.", "novelty_analysis": "The introduction of CODEGEN and the multi-step paradigm for program synthesis represent significant advancements in the field of program synthesis. The creation of the MTPB benchmark also provides a valuable resource for future research in this area.", "novelty_score": 3, "category": "TRAINING", "technical_analysis": "The paper is quite technical, discussing the training of large language models, the construction of a new benchmark, and the implementation of a new paradigm for program synthesis. It requires a solid understanding of machine learning and programming languages.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and presents a novel approach to program synthesis, making it an interesting read for those in the field. However, the technical nature of the content may make it less accessible to a broader audience.", "enjoyable_score": 2}