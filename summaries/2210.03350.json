{"Published": "2023-05-23", "Title": "Measuring and Narrowing the Compositionality Gap in Language Models", "Authors": "Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, Mike Lewis", "Summary": "We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning.   We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.", "main_contribution": {"headline": "Introduction of 'Self-Ask' method to improve compositional reasoning in LLMs", "description": "The paper introduces a novel method, 'Self-Ask', to improve the compositional reasoning capabilities of Large Language Models (LLMs). The authors identify a 'compositionality gap' in LLMs, where models can answer sub-problems correctly but fail to generate the overall solution. The 'Self-Ask' method addresses this by having the model explicitly ask itself follow-up questions before answering the initial question. This method improves upon the 'chain of thought' approach and can be further enhanced by integrating a search engine to answer the follow-up questions."}, "takeaways": {"headline": "'Self-Ask' method enhances LLMs' reasoning capabilities and accuracy", "description": "The 'Self-Ask' method presents a promising approach to improve the reasoning capabilities of LLMs, particularly in tasks requiring compositional reasoning. By having the model ask itself follow-up questions, it can better understand and answer complex, multi-hop questions. This method can be integrated into existing LLM workflows to improve their performance and accuracy. Furthermore, the possibility of integrating a search engine to answer follow-up questions opens up new avenues for enhancing LLMs' capabilities.", "example": "For instance, when asked a complex question like 'Who won the Master's Tournament the year Justin Bieber was born?', an LLM using the 'Self-Ask' method would first ask itself 'When was Justin Bieber born?' and 'Who won the Master's Tournament in that year?' before answering the initial question. This process can be further enhanced by integrating a search engine to answer the follow-up questions."}, "category": "PROMPTING", "novelty_analysis": "The paper introduces the 'Self-Ask' method, a novel approach to improve the compositional reasoning capabilities of LLMs. This method represents a significant advancement in the field of prompting techniques for LLMs.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, discussing the intricacies of the 'Self-Ask' method and its implementation. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a basic understanding of LLMs.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an intriguing solution to a known problem in LLMs. The introduction of the 'Self-Ask' method and its potential implications make for an engaging read.", "enjoyable_score": 3}