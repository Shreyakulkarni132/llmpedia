{"Published": "2022-05-19", "Title": "Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning", "Authors": "Antonia Creswell, Murray Shanahan, Irina Higgins", "Summary": "Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 50 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex problems. In light of this, we propose a Selection-Inference (SI) framework that exploits pre-trained LLMs as general processing modules, and alternates between selection and inference to generate a series of interpretable, casual reasoning steps leading to the final answer. We show that a 7B parameter LLM used within the SI framework in a 5-shot generalisation setting, with no fine-tuning, yields a performance improvement of over 100% compared to an equivalent vanilla baseline on a suite of 10 logical reasoning tasks. The same model in the same setting even outperforms a significantly larger 280B parameter baseline on the same suite of tasks. Moreover, answers produced by the SI framework are accompanied by a causal natural-language-based reasoning trace, which has important implications for the safety and trustworthiness of the system.", "main_contribution": "The paper introduces a novel Selection-Inference (SI) framework that leverages pre-trained LLMs as general processing modules to improve their performance on multi-step logical reasoning tasks. The SI framework alternates between selection and inference to generate a series of interpretable, causal reasoning steps leading to the final answer. The authors demonstrate that a 7B parameter LLM used within the SI framework, without any fine-tuning, significantly outperforms both an equivalent vanilla baseline and a much larger 280B parameter baseline on a suite of 10 logical reasoning tasks.", "takeaways": "The SI framework presents a significant advancement in the use of LLMs for logical reasoning tasks. It not only improves performance but also provides a causal natural-language-based reasoning trace, enhancing the interpretability, safety, and trustworthiness of the system. This approach could be particularly beneficial for LLM practitioners working on complex problem-solving tasks that require multi-step logical reasoning.", "novelty_analysis": "The SI framework is a novel approach that addresses the challenge of multi-step logical reasoning in LLMs. It combines elements from the neurosymbolic literature with the power of LLMs, resulting in a unique and effective solution for logical reasoning tasks.", "novelty_score": 3, "category": "BEHAVIOR", "technical_analysis": "The paper is quite technical, introducing a new framework and discussing its implementation in detail. It requires a good understanding of LLMs and logical reasoning tasks.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and presents a novel and interesting contribution to the field. However, the highly technical content may make it challenging for some readers.", "enjoyable_score": 2}