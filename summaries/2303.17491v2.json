{"Published": "2023-06-07", "Title": "Language Models can Solve Computer Tasks", "Authors": "Geunwoo Kim, Pierre Baldi, Stephen McAleer", "Summary": "Agents capable of carrying out general tasks on a computer can improve efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving. Ideally, such agents should be able to solve new computer tasks presented to them through natural language commands. However, previous approaches to this problem require large amounts of expert demonstrations and task-specific reward functions, both of which are impractical for new tasks. In this work, we show that a pre-trained large language model (LLM) agent can execute computer tasks guided by natural language using a simple prompting scheme where the agent Recursively Criticizes and Improves its output (RCI). The RCI approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark. We compare multiple LLMs and find that RCI with the InstructGPT-3+RLHF LLM is state-of-the-art on MiniWoB++, using only a handful of demonstrations per task rather than tens of thousands, and without a task-specific reward function. Furthermore, we demonstrate RCI prompting's effectiveness in enhancing LLMs' reasoning abilities on a suite of natural language reasoning tasks, outperforming chain of thought (CoT) prompting. We find that RCI combined with CoT performs better than either separately. Our code can be found here: https://github.com/posgnu/rci-agent.", "main_contribution": {"headline": "Recursive Criticism and Improvement (RCI) enhances LLMs for computer tasks", "description": "The paper introduces a novel method, Recursive Criticism and Improvement (RCI), to guide a pre-trained large language model (LLM) in executing computer tasks using natural language commands. RCI works by having the LLM generate an initial solution, criticize it, and then iteratively improve upon it. This approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark. The authors also demonstrate that RCI, when combined with chain of thought (CoT) prompting, performs better than either separately."}, "takeaways": {"headline": "RCI prompting presents a novel application avenue for LLMs in task automation", "description": "The RCI technique can be used to enhance the performance of LLMs in executing computer tasks, thereby improving efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving. The combination of RCI and CoT prompting can further enhance the reasoning abilities of LLMs. The authors provide their code, which can be used as a starting point for implementing RCI in LLM applications.", "example": "For instance, an LLM utilizing RCI prompts, when given a task like 'Sort the emails in the inbox by date', would generate an initial solution, criticize it, and then iteratively improve upon it until the task is completed efficiently."}, "category": "PROMPTING", "novelty_analysis": "The introduction of the RCI method for guiding LLMs in executing computer tasks is a significant advancement in the field. The combination of RCI with CoT prompting for enhancing LLMs' reasoning abilities is also a novel contribution.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it introduces a new method, RCI, and discusses its implementation in detail. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a background in AI and ML.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and organized, presenting a novel and intriguing contribution. The practical implications of the RCI method and its combination with CoT prompting make the paper an interesting read.", "enjoyable_score": 3}