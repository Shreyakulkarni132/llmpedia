{"Published": "2023-06-30", "Title": "Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting", "Authors": "Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, Michael Bendersky", "Summary": "Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, there has been limited success so far, as researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these ranking formulations, possibly due to the nature of how LLMs are trained. In this paper, we propose to significantly reduce the burden on LLMs by using a new technique called Pairwise Ranking Prompting (PRP). Our results are the first in the literature to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on the Flan-UL2 model with 20B parameters outperforms the previous best approach in the literature, which is based on the blackbox commercial GPT-4 that has 50x (estimated) model size, by over 5% at NDCG@1. On TREC-DL2019, PRP is only inferior to the GPT-4 solution on the NDCG@5 and NDCG@10 metrics, while outperforming other existing solutions, such as InstructGPT which has 175B parameters, by over 10% for nearly all ranking metrics. Furthermore, we propose several variants of PRP to improve efficiency and show that it is possible to achieve competitive results even with linear complexity. We also discuss other benefits of PRP, such as supporting both generation and scoring LLM APIs, as well as being insensitive to input ordering.", "main_contribution": {"headline": "Pairwise Ranking Prompting (PRP) Improves Document Ranking with LLMs", "description": "The paper introduces Pairwise Ranking Prompting (PRP), a novel technique for improving document ranking using Large Language Models (LLMs). PRP reduces the complexity of the ranking task by using the query and a pair of documents as the prompt for LLMs. This approach addresses the limitations of existing pointwise and listwise ranking methods, which have struggled to outperform fine-tuned baseline rankers. The authors propose several variants of PRP to improve efficiency and demonstrate that competitive results can be achieved even with linear complexity. The PRP technique is the first to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized, open-sourced LLMs."}, "takeaways": {"headline": "PRP Offers a More Efficient and Effective Approach to Document Ranking with LLMs", "description": "The Pairwise Ranking Prompting (PRP) technique offers a promising approach to document ranking with LLMs. It reduces the complexity of the task, making it more manageable for LLMs, and achieves superior performance on standard benchmarks. PRP also supports both generation and scoring LLM APIs and is insensitive to input ordering, making it a versatile tool for LLM practitioners. The paper also demonstrates that PRP can achieve competitive results even with linear complexity, making it a more efficient alternative to existing methods.", "example": "For instance, given a query and a pair of documents, an LLM using PRP could be prompted as follows: 'Given the query \"What is the capital of France?\", which of the following two passages is more relevant? Passage A: \"Paris is the capital of France.\" Passage B: \"France is known for its fine wines.\"' The LLM would then rank the passages based on their relevance to the query."}, "category": "PROMPTING", "novelty_analysis": "The introduction of Pairwise Ranking Prompting (PRP) represents a significant advancement in the field of document ranking with LLMs. While previous methods have struggled to outperform fine-tuned baseline rankers, PRP is the first to achieve state-of-the-art performance on standard benchmarks using moderate-sized, open-sourced LLMs. This makes it a novel and impactful contribution to the literature.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, delving into the specifics of the PRP technique and its variants. It provides a detailed analysis of the limitations of existing ranking methods and how PRP addresses these issues. However, the concepts are explained clearly and should be accessible to readers with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a clear narrative, making it an engaging read. The introduction of a novel technique and its successful application to a challenging problem makes for an interesting and insightful paper. The authors' clear explanation of the technical aspects of PRP also enhances the reading experience.", "enjoyable_score": 3}