{"Published": "2023-05-15", "Title": "Large Language Models are Zero-Shot Rankers for Recommender Systems", "Authors": "Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, Wayne Xin Zhao", "Summary": "Recently, large language models (LLMs) (e.g. GPT-4) have demonstrated impressive general-purpose task-solving abilities, including the potential to approach recommendation tasks. Along this line of research, this work aims to investigate the capacity of LLMs that act as the ranking model for recommender systems. To conduct our empirical study, we first formalize the recommendation problem as a conditional ranking task, considering sequential interaction histories as conditions and the items retrieved by the candidate generation model as candidates. We adopt a specific prompting approach to solving the ranking task by LLMs: we carefully design the prompting template by including the sequential interaction history, the candidate items, and the ranking instruction. We conduct extensive experiments on two widely-used datasets for recommender systems and derive several key findings for the use of LLMs in recommender systems. We show that LLMs have promising zero-shot ranking abilities, even competitive to or better than conventional recommendation models on candidates retrieved by multiple candidate generators. We also demonstrate that LLMs struggle to perceive the order of historical interactions and can be affected by biases like position bias, while these issues can be alleviated via specially designed prompting and bootstrapping strategies. The code to reproduce this work is available at https://github.com/RUCAIBox/LLMRank.", "main_contribution": {"headline": "LLMs as Zero-Shot Rankers for Recommender Systems", "description": "The paper investigates the capacity of Large Language Models (LLMs) to serve as ranking models for recommender systems. The authors formalize the recommendation problem as a conditional ranking task, where sequential interaction histories are considered as conditions and the items retrieved by the candidate generation model as candidates. They design a specific prompting approach to solve the ranking task by LLMs, which includes the sequential interaction history, the candidate items, and the ranking instruction. The paper shows that LLMs have promising zero-shot ranking abilities, even competitive to or better than conventional recommendation models."}, "takeaways": {"headline": "LLMs can be used as effective rankers in recommender systems", "description": "The paper demonstrates that LLMs can be used effectively as ranking models in recommender systems, providing a new application for these models. The authors' approach of formalizing the recommendation problem as a conditional ranking task and designing a specific prompting approach can be used as a blueprint for implementing similar systems. However, the paper also highlights that LLMs struggle to perceive the order of historical interactions and can be affected by biases like position bias, which can be mitigated with specially designed prompting and bootstrapping strategies.", "example": "For instance, an LLM can be used in a movie recommendation system where the sequential interaction history (e.g., previously watched movies), the candidate items (e.g., list of movies to recommend), and the ranking instruction (e.g., rank the movies based on the likelihood of the user liking them) are used to generate personalized movie recommendations."}, "category": "USE CASES", "novelty_analysis": "The paper presents a novel application of LLMs as ranking models in recommender systems. While LLMs have been used in various applications, their use in recommender systems as zero-shot rankers is a unique contribution. The authors' approach of formalizing the recommendation problem as a conditional ranking task and designing a specific prompting approach is also a novel contribution.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it involves the application of LLMs in a specific context, i.e., recommender systems. It requires a basic understanding of LLMs and recommender systems. However, the authors provide a clear explanation of their approach, making it accessible to readers with a basic understanding of these concepts.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an interesting application of LLMs. The authors' approach of using LLMs as ranking models in recommender systems is novel and provides a new perspective on the potential applications of these models. The paper is also well-structured, making it easy to follow and understand.", "enjoyable_score": 3}