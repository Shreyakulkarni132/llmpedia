{"Published": "2023-07-20", "Title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "Authors": "Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, Minjoon Seo", "Summary": "Evaluation of Large Language Models (LLMs) is challenging because aligning to human values requires the composition of multiple skills and the required set of skills varies depending on the instruction. Recent studies have evaluated the performance of LLMs in two ways, (1) automatic evaluation on several independent benchmarks and (2) human or machined-based evaluation giving an overall score to the response. However, both settings are coarse-grained evaluations, not considering the nature of user instructions that require instance-wise skill composition, which limits the interpretation of the true capabilities of LLMs. In this paper, we introduce FLASK (Fine-grained Language Model Evaluation based on Alignment SKill Sets), a fine-grained evaluation protocol that can be used for both model-based and human-based evaluation which decomposes coarse-level scoring to an instance-wise skill set-level. Specifically, we define 12 fine-grained skills needed for LLMs to follow open-ended user instructions and construct an evaluation set by allocating a set of skills for each instance. Additionally, by annotating the target domains and difficulty level for each instance, FLASK provides a holistic view with a comprehensive analysis of a model's performance depending on skill, domain, and difficulty. Through using FLASK, we compare multiple open-sourced and proprietary LLMs and observe highly-correlated findings between model-based and human-based evaluations. FLASK enables developers to more accurately measure the model performance and how it can be improved by analyzing factors that make LLMs proficient in particular skills. For practitioners, FLASK can be used to recommend suitable models for particular situations through comprehensive comparison among various LLMs. We release the evaluation data and code implementation at https://github.com/kaistAI/FLASK.", "main_contribution": {"headline": "FLASK: A Fine-Grained Evaluation Protocol for Large Language Models", "description": "The paper introduces FLASK (Fine-grained Language Model Evaluation based on Alignment SKill Sets), a novel evaluation protocol for Large Language Models (LLMs). FLASK decomposes the traditional coarse-level scoring into an instance-wise skill set-level evaluation, providing a more detailed and comprehensive understanding of LLMs' capabilities. The authors define 12 fine-grained skills necessary for LLMs to follow open-ended user instructions and construct an evaluation set by allocating a set of skills for each instance. Additionally, FLASK annotates the target domains and difficulty level for each instance, providing a holistic view of a model's performance depending on skill, domain, and difficulty. The paper demonstrates the application of FLASK by comparing multiple open-sourced and proprietary LLMs, revealing highly-correlated findings between model-based and human-based evaluations."}, "takeaways": {"headline": "FLASK Provides Detailed Insights for Improving LLM Performance", "description": "FLASK's fine-grained evaluation protocol offers a more accurate measure of LLM performance, enabling developers to identify specific areas for improvement. By analyzing the factors that make LLMs proficient in particular skills, developers can focus their efforts on enhancing these areas. For practitioners, FLASK can be used to recommend suitable models for specific situations through a comprehensive comparison among various LLMs. For instance, if a task requires strong logical thinking and background knowledge abilities, FLASK's evaluation can guide practitioners towards models that excel in these skills.", "example": "For example, if a task requires strong logical thinking and background knowledge abilities, FLASK's evaluation can guide practitioners towards models that excel in these skills. The FLASK evaluation protocol can be implemented as follows: \n\n\nfrom flask import FlaskEvaluator\n\n# Initialize evaluator with the defined skills\nevaluator = FlaskEvaluator(skills=['Logical Thinking', 'Background Knowledge'])\n\n# Evaluate the model\nscores = evaluator.evaluate(model, instances)\n\n# Analyze the scores to identify areas of improvement\nanalyzer = FlaskAnalyzer()\nanalysis = analyzer.analyze(scores)\n\nThis code snippet demonstrates how to use the FLASK evaluator to assess a model's performance in specific skills and analyze the scores to identify areas of improvement."}, "category": "BEHAVIOR", "novelty_analysis": "FLASK introduces a novel approach to evaluating LLMs by decomposing coarse-level scoring into an instance-wise skill set-level evaluation. This fine-grained evaluation protocol provides a more detailed understanding of LLMs' capabilities, which is a significant advancement over traditional evaluation methods. The inclusion of target domains and difficulty levels in the evaluation further enhances the novelty of this work.", "novelty_score": 3, "technical_analysis": "The paper presents a new evaluation protocol, which involves defining fine-grained skills, constructing an evaluation set, and annotating target domains and difficulty levels. While the concept is technically advanced, the authors explain the process in a clear and comprehensible manner, making it accessible to readers with a basic understanding of LLMs.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel concept in a clear and comprehensible manner. The use of visual aids and tables enhances the readability of the paper. The detailed comparison of various LLMs using the FLASK evaluation protocol provides insightful and engaging content for the readers.", "enjoyable_score": 3}