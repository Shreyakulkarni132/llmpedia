{"Published": "2023-07-18", "Title": "Large Language Models Perform Diagnostic Reasoning", "Authors": "Cheng-Kuang Wu, Wei-Lin Chen, Hsin-Hsi Chen", "Summary": "We explore the extension of chain-of-thought (CoT) prompting to medical reasoning for the task of automatic diagnosis. Motivated by doctors' underlying reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical results demonstrate that by simply prompting large language models trained only on general text corpus with two DR-CoT exemplars, the diagnostic accuracy improves by 15% comparing to standard prompting. Moreover, the gap reaches a pronounced 18% in out-domain settings. Our findings suggest expert-knowledge reasoning in large language models can be elicited through proper promptings.", "main_contribution": {"headline": "Diagnostic-Reasoning Chain of Thought (DR-CoT) enhances LLMs for automatic diagnosis", "description": "The paper introduces Diagnostic-Reasoning Chain of Thought (DR-CoT), a novel application of CoT prompting to medical reasoning for automatic diagnosis. The DR-CoT is inspired by the iterative question-answering sessions between doctors and patients, where doctors inquire about clinical evidence and form a differential diagnosis (DDx). The DDx then guides the next questions and refines itself based on the patient's answers. By prompting LLMs with two DR-CoT exemplars, the diagnostic accuracy improves significantly compared to standard prompting, demonstrating that expert-knowledge reasoning in LLMs can be elicited through proper promptings."}, "takeaways": {"headline": "DR-CoT prompting presents a novel application avenue for LLMs in healthcare", "description": "The DR-CoT prompting technique can be used to improve the diagnostic accuracy of LLMs in healthcare applications. This technique adds a layer of transparency to the model's diagnostic process, making its conclusions more interpretable. The model's superior performance over standard prompting underlines the potential of LLMs in various healthcare tasks, especially in automatic diagnosis.", "example": "For instance, an LLM utilizing DR-CoT prompts, when fed a patient's symptoms, would generate a series of thought-sequence instead of a direct diagnosis. 'Patient reports severe headache and blurred vision.' --> DR-CoT: 'Severe headache -> Possible migraine -> Ask about light sensitivity -> If positive, confirm migraine diagnosis.' This sequence presents a more comprehensive diagnostic process, aiding in more accurate diagnosis."}, "category": "USE CASES", "novelty_analysis": "The paper extends the boundaries of current research by applying LLMs to automatic diagnosis in healthcare. The introduction of the DR-CoT prompting technique, tailored specifically for this application, represents an incremental advancement in the field.", "novelty_score": 2, "technical_analysis": "While the paper discusses a computational framework for managing LLM inputs and outputs, it does not delve into complex mathematical theories or algorithms, making it accessible to a wider audience.", "technical_score": 1, "enjoyable_analysis": "The engaging narrative style, coupled with practical insights, makes the paper an enjoyable read. It skillfully balances technical details with easily digestible information.", "enjoyable_score": 3}