{"Published": "2023-05-08", "Title": "From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models", "Authors": "Jiaxian Guo, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Boyang Li, Dacheng Tao, Steven C. H. Hoi", "Summary": "Large language models (LLMs) have demonstrated excellent zero-shot generalization to new language tasks. However, effective utilization of LLMs for zero-shot visual question-answering (VQA) remains challenging, primarily due to the modality disconnection and task disconnection between LLM and VQA task. End-to-end training on vision and language data may bridge the disconnections, but is inflexible and computationally expensive. To address this issue, we propose \\emph{Img2Prompt}, a plug-and-play module that provides the prompts that can bridge the aforementioned modality and task disconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end training. In order to provide such prompts, we further employ LLM-agnostic models to provide prompts that can describe image content and self-constructed question-answer pairs, which can effectively guide LLM to perform zero-shot VQA tasks. Img2Prompt offers the following benefits: 1) It can flexibly work with various LLMs to perform VQA. 2)~Without the needing of end-to-end training, it significantly reduces the cost of deploying LLM for zero-shot VQA tasks. 3) It achieves comparable or better performance than methods relying on end-to-end training. For example, we outperform Flamingo \\cite{Deepmind:Flamingo2022} by 5.6\\% on VQAv2. On the challenging A-OKVQA dataset, our method even outperforms few-shot methods by as much as 20\\%.", "main_contribution": "The paper introduces Img2Prompt, a plug-and-play module that enables Large Language Models (LLMs) to perform zero-shot Visual Question Answering (VQA) tasks without the need for end-to-end training. The module works by providing LLM-agnostic prompts that describe image content as exemplar question-answer pairs, effectively bridging the modality and task disconnects between LLMs and VQA tasks.", "takeaways": "Img2Prompt offers several advantages: it can work with a wide range of LLMs, it reduces the cost of deploying LLMs for zero-shot VQA tasks by eliminating the need for end-to-end training, and it achieves comparable or even better performance than methods that rely on end-to-end training. This makes it a flexible and cost-effective solution for leveraging LLMs in VQA tasks.", "novelty_analysis": "The novelty of this work lies in the introduction of Img2Prompt, a module that enables LLMs to perform zero-shot VQA tasks without end-to-end training. This approach addresses the challenges of modality and task disconnects between LLMs and VQA tasks, which have been a significant hurdle in the effective utilization of LLMs for VQA.", "novelty_score": 3, "category": "PROMPTING", "technical_analysis": "The paper is somewhat technical, as it introduces a new module and discusses its implementation and performance in the context of VQA tasks. However, the concepts are explained clearly, making it accessible to readers with a background in computer science or AI research.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel solution to a significant challenge in the field of AI research. The clear explanation of the proposed module and its benefits, along with the impressive performance results, make it an interesting and enjoyable read.", "enjoyable_score": 3}