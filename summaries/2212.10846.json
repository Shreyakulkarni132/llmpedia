{"Published": "2023-05-08", "Title": "From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models", "Authors": "Jiaxian Guo, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Boyang Li, Dacheng Tao, Steven C. H. Hoi", "Summary": "Large language models (LLMs) have demonstrated excellent zero-shot generalization to new language tasks. However, effective utilization of LLMs for zero-shot visual question-answering (VQA) remains challenging, primarily due to the modality disconnection and task disconnection between LLM and VQA task. End-to-end training on vision and language data may bridge the disconnections, but is inflexible and computationally expensive. To address this issue, we propose \\emph{Img2Prompt}, a plug-and-play module that provides the prompts that can bridge the aforementioned modality and task disconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end training. In order to provide such prompts, we further employ LLM-agnostic models to provide prompts that can describe image content and self-constructed question-answer pairs, which can effectively guide LLM to perform zero-shot VQA tasks. Img2Prompt offers the following benefits: 1) It can flexibly work with various LLMs to perform VQA. 2)~Without the needing of end-to-end training, it significantly reduces the cost of deploying LLM for zero-shot VQA tasks. 3) It achieves comparable or better performance than methods relying on end-to-end training. For example, we outperform Flamingo \\cite{Deepmind:Flamingo2022} by 5.6\\% on VQAv2. On the challenging A-OKVQA dataset, our method even outperforms few-shot methods by as much as 20\\%.", "main_contribution": {"headline": "Img2LLM: A plug-and-play module for zero-shot visual question-answering with LLMs", "description": "The paper introduces Img2LLM, a novel plug-and-play module that enables Large Language Models (LLMs) to perform zero-shot visual question-answering (VQA) tasks without the need for end-to-end training. Img2LLM uses LLM-agnostic models to describe image content as exemplar question-answer pairs, which serve as effective prompts for the LLM. This approach addresses the modality and task disconnect between LLMs and VQA tasks, and eliminates the need for computationally expensive end-to-end training. The proposed method outperforms existing methods, including Flamingo, on several VQA datasets."}, "takeaways": {"headline": "Img2LLM offers a cost-effective and flexible approach to VQA with LLMs", "description": "Img2LLM provides a practical solution for LLM practitioners looking to apply LLMs to VQA tasks. It offers a flexible interface with a wide range of LLMs and reduces the cost of deploying LLMs for zero-shot VQA tasks by eliminating the need for end-to-end training. The method's superior performance on various VQA datasets demonstrates its effectiveness. Practitioners can use Img2LLM to develop VQA systems that can be easily updated as new versions of LLMs emerge, without the need for expensive re-training.", "example": "For instance, to use Img2LLM for a VQA task, an LLM practitioner would first use the LLM-agnostic models to generate question-answer pairs that describe the content of the image. These pairs would then be used as prompts for the LLM, guiding it to answer the actual question about the image."}, "category": "PROMPTING", "novelty_analysis": "The paper presents a novel approach to applying LLMs to VQA tasks, addressing the modality and task disconnect between LLMs and VQA tasks without the need for end-to-end training. The introduction of Img2LLM as a plug-and-play module that can interface with a wide range of LLMs is a significant contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical, detailing the workings of the Img2LLM module and its application to VQA tasks. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a background in AI and machine learning.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents a novel and intriguing contribution to the field of LLMs. The clear explanation of the Img2LLM module and its benefits makes the paper an interesting read for practitioners in the field.", "enjoyable_score": 3}