{"Published": "2023-01-29", "Title": "Large Language Models are Zero-Shot Reasoners", "Authors": "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa", "Summary": "Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding \"Let's think step by step\" before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with large InstructGPT model (text-davinci-002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.", "main_contribution": {"headline": "LLMs exhibit strong zero-shot reasoning capabilities with Chain-of-Thought prompting", "description": "The paper demonstrates that Large Language Models (LLMs) can perform well in zero-shot reasoning tasks by using a simple Chain-of-Thought (CoT) prompting technique. The authors introduce a single prompt, 'Let's think step by step', which significantly improves the performance of LLMs on various reasoning tasks. The paper shows that this approach outperforms traditional zero-shot LLM performances on diverse benchmark reasoning tasks, including arithmetic, symbolic reasoning, and other logical reasoning tasks. The results suggest that LLMs have untapped and understudied fundamental zero-shot capabilities that can be harnessed through simple prompting."}, "takeaways": {"headline": "Simple prompting can unlock LLMs' zero-shot reasoning capabilities", "description": "The paper's findings suggest that LLM practitioners can significantly improve the performance of their models on reasoning tasks by using a simple CoT prompting technique. This approach can be applied across a wide range of tasks, making it a versatile tool for LLM practitioners. The paper also highlights the importance of exploring and analyzing the zero-shot knowledge hidden inside LLMs before crafting fine-tuning datasets or few-shot exemplars.", "example": "For instance, when tasked with a reasoning problem, an LLM can be prompted with 'Let's think step by step' before each answer. This encourages the model to break down the problem into smaller steps, improving its ability to reason through the problem and arrive at the correct answer."}, "category": "PROMPTING", "novelty_analysis": "The paper presents a novel approach to prompting LLMs for zero-shot reasoning tasks. While the concept of CoT prompting is not new, the authors' application of it to zero-shot reasoning tasks and their demonstration of its effectiveness across a wide range of tasks is a significant contribution to the field.", "novelty_score": 2, "technical_analysis": "The paper is somewhat technical, as it involves understanding the concept of CoT prompting and how it can be applied to improve the performance of LLMs on reasoning tasks. However, the authors explain these concepts clearly and provide ample experimental results to support their claims, making the paper accessible to readers with a basic understanding of LLMs.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents an interesting approach to improving the performance of LLMs on reasoning tasks. The authors' clear explanation of their methodology and their thorough presentation of their experimental results make the paper an engaging read.", "enjoyable_score": 3}