{"Published": "2023-08-03", "Title": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models", "Authors": "Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi Tan, Chang Zhou", "Summary": "Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model's performance than the model's parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs. We also find RFT brings more improvement for less performant LLMs. Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3% and outperforms the supervised fine-tuning (SFT) accuracy of 35.9% significantly.", "main_contribution": {"headline": "Rejection sampling Fine-Tuning (RFT) improves mathematical reasoning in LLMs", "description": "The paper introduces Rejection sampling Fine-Tuning (RFT), a novel method to augment data samples for improving the mathematical reasoning performance of Large Language Models (LLMs) without human effort. RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. The authors demonstrate that with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs, especially for less performant ones. Furthermore, the combination of rejection samples from multiple models significantly outperforms the supervised fine-tuning (SFT) accuracy."}, "takeaways": {"headline": "RFT offers a scalable way to improve LLMs' mathematical reasoning", "description": "The introduction of Rejection sampling Fine-Tuning (RFT) provides a scalable and efficient way to improve the mathematical reasoning performance of LLMs. By generating and collecting correct reasoning paths as augmented fine-tuning datasets, RFT can be used to enhance the performance of LLMs, especially those with lower initial performance. This method could be particularly useful in applications where mathematical reasoning is crucial, such as in scientific research, financial analysis, or advanced AI systems.", "example": "For instance, an LLM can be fine-tuned using RFT by following these steps: 1. Use a supervised model to generate correct reasoning paths. 2. Collect these paths as augmented fine-tuning datasets. 3. Fine-tune the LLM using these datasets. 4. Repeat the process with multiple models to further improve performance."}, "category": "FINE-TUNING", "novelty_analysis": "The paper presents a novel method, Rejection sampling Fine-Tuning (RFT), for improving the mathematical reasoning performance of LLMs. This method, which uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets, is a unique approach to enhancing LLM performance.", "novelty_score": 3, "technical_analysis": "The paper is quite technical, delving into the details of the RFT method, its implementation, and its impact on the performance of LLMs. It requires a solid understanding of LLMs, fine-tuning techniques, and mathematical reasoning.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and presents a novel and interesting approach to improving the performance of LLMs. However, the technical nature of the content might make it challenging for readers without a strong background in the field.", "enjoyable_score": 2}