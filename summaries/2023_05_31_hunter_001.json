{"Published": "2023-05-31", "Title": "Let's Verify Step by Step", "Authors": "Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, Karl Cobbe", "Summary": "In recent years, large language models have greatly improved in their ability to perform complex multi-step reasoning. However, even state-of-the-art models still regularly produce logical mistakes. To train more reliable models, we can turn either to outcome supervision, which provides feedback for a final result, or process supervision, which provides feedback for each intermediate reasoning step. Given the importance of training reliable models, and given the high cost of human feedback, it is important to carefully compare the both methods. Recent work has already begun this comparison, but many questions still remain. We conduct our own investigation, finding that process supervision significantly outperforms outcome supervision for training models to solve problems from the challenging MATH dataset. Our process-supervised model solves 78% of problems from a representative subset of the MATH test set. Additionally, we show that active learning significantly improves the efficacy of process supervision. To support related research, we also release PRM800K, the complete dataset of 800,000 step-level human feedback labels used to train our best reward model.", "main_contribution": {"headline": "Process Supervision Outperforms Outcome Supervision in Training Reliable LLMs", "description": "The paper presents a comprehensive comparison between outcome supervision and process supervision in training large language models (LLMs) to solve complex problems. The authors found that process supervision, which provides feedback for each intermediate reasoning step, significantly outperforms outcome supervision, which only provides feedback for the final result. The study was conducted using the challenging MATH dataset, and the process-supervised model was able to solve 78% of problems from a representative subset of the MATH test set. The authors also demonstrated that active learning significantly improves the efficacy of process supervision. To support further research, they released PRM800K, a dataset of 800,000 step-level human feedback labels used to train their best reward model."}, "takeaways": {"headline": "Process Supervision Enhances LLMs' Problem-Solving Capabilities", "description": "The findings of this study suggest that process supervision can be a more effective method for training LLMs to solve complex problems. By providing feedback at each intermediate reasoning step, models can better understand where they are making mistakes and adjust accordingly. This approach could be particularly useful in applications where LLMs are required to perform complex multi-step reasoning, such as in advanced natural language understanding tasks, problem-solving tasks, or even in AI alignment. The release of the PRM800K dataset also provides a valuable resource for researchers looking to further explore this area.", "example": "For instance, in a customer service chatbot application, an LLM trained with process supervision could be more effective in understanding and responding to complex customer queries. By receiving feedback at each step of the reasoning process, the model could better understand where it's going wrong and adjust its responses accordingly, leading to more accurate and helpful responses."}, "category": "TRAINING", "novelty_analysis": "The paper presents a novel comparison between outcome supervision and process supervision in training LLMs, providing valuable insights into the effectiveness of these methods. The authors' finding that process supervision significantly outperforms outcome supervision in training models to solve complex problems is a significant contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is highly technical, delving into the specifics of outcome supervision and process supervision, and detailing the methodology used for their comparison. It requires a solid understanding of LLMs, reinforcement learning, and the concepts of outcome and process supervision.", "technical_score": 3, "enjoyable_analysis": "The paper is well-structured and presents a clear comparison between outcome and process supervision. The authors' findings are significant and have important implications for the field of LLMs, making the paper an engaging read for those interested in this area.", "enjoyable_score": 2}