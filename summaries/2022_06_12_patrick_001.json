{"Published": "2022-06-12", "Title": "Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code", "Authors": "Patrick Barei\u00df, Beatriz Souza, Marcelo d'Amorim, Michael Pradel", "Summary": "Few-shot learning with large-scale, pre-trained language models is a powerful way to answer questions about code, e.g., how to complete a given code example, or even generate code snippets from scratch. The success of these models raises the question whether they could serve as a basis for building a wide range code generation tools. Traditionally, such tools are built manually and separately for each task. Instead, few-shot learning may allow to obtain different tools from a single pre-trained language model by simply providing a few examples or a natural language description of the expected tool behavior. This paper studies to what extent a state-of-the-art, pre-trained language model of code, Codex, may serve this purpose. We consider three code manipulation and code generation tasks targeted by a range of traditional tools: (i) code mutation; (ii) test oracle generation from natural language documentation; and (iii) test case generation. For each task, we compare few-shot learning to a manually built tool. Our results show that the model-based tools complement (code mutation), are on par (test oracle generation), or even outperform their respective traditionally built tool (test case generation), while imposing far less effort to develop them. By comparing the effectiveness of different variants of the model-based tools, we provide insights on how to design an appropriate input (\"prompt\") to the model and what influence the size of the model has. For example, we find that providing a small natural language description of the code generation task is an easy way to improve predictions. Overall, we conclude that few-shot language models are surprisingly effective, yet there is still more work to be done, such as exploring more diverse ways of prompting and tackling even more involved tasks.", "main_contribution": {"headline": "Few-shot learning with Codex for code manipulation and generation tasks", "description": "The paper explores the use of Codex, a pre-trained language model, for code manipulation and generation tasks using few-shot learning. The authors compare the performance of Codex with traditional manually built tools for three tasks: code mutation, test oracle generation from natural language documentation, and test case generation. The results show that Codex-based tools can complement, match, or even outperform traditional tools, with significantly less development effort. The paper also provides insights on designing effective prompts and the influence of the model's size on its performance."}, "takeaways": {"headline": "Codex-based tools can simplify code manipulation and generation tasks", "description": "The use of Codex for code manipulation and generation tasks can significantly reduce the effort required to develop such tools. By providing a few examples or a natural language description of the expected tool behavior, different tools can be obtained from a single pre-trained language model. This approach can be particularly useful for tasks such as code mutation, test oracle generation, and test case generation. The paper also provides valuable insights on how to design effective prompts for the model.", "example": "For instance, to generate a test case for a given method, you can provide Codex with a few examples of the expected output for different inputs. Codex can then generate the test case based on these examples, potentially outperforming a traditional manually built tool."}, "category": "USE CASES", "novelty_analysis": "The paper presents a novel application of few-shot learning with Codex for code manipulation and generation tasks. While the use of pre-trained language models for such tasks is not entirely new, the comparison with traditional manually built tools and the insights on prompt design and model size add to the novelty of the paper.", "novelty_score": 2, "technical_analysis": "The paper is somewhat technical, as it involves the application of a pre-trained language model for code manipulation and generation tasks. However, it does not delve into the details of the model's architecture or training process, making it accessible to readers with a basic understanding of machine learning and programming.", "technical_score": 2, "enjoyable_analysis": "The paper is well-structured and presents an interesting application of pre-trained language models. The comparison with traditional tools and the insights on prompt design and model size make it an engaging read for anyone interested in the application of machine learning in software engineering.", "enjoyable_score": 2}