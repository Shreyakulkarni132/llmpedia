{"Published": "2023-03-10", "Title": "Large Language Models Are Human-Level Prompt Engineers", "Authors": "Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, Jimmy Ba", "Summary": "By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the \"program,\" optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.", "main_contribution": {"headline": "Automatic Prompt Engineer (APE) for automatic instruction generation and selection in LLMs", "description": "The paper introduces Automatic Prompt Engineer (APE), a novel method for automatic instruction generation and selection in Large Language Models (LLMs). APE treats the instruction as a 'program' and optimizes it by searching over a pool of instruction candidates proposed by an LLM to maximize a chosen score function. The quality of the selected instruction is evaluated by the zero-shot performance of another LLM following the selected instruction. The experiments show that APE-engineered prompts outperform the prior LLM baseline and achieve better or comparable performance to the instructions generated by human annotators."}, "takeaways": {"headline": "APE brings automation to prompt engineering, improving LLMs performance", "description": "APE represents a significant step towards automating prompt engineering, thereby streamlining the process of task learning for LLMs. By leveraging a score function, this method provides effective prompts for consistent performance. Its demonstrated superiority on various tasks and ability to steer models toward truthfulness and informativeness brings efficiency and potential performance improvements to AI and machine learning practitioners.", "example": "For instance, an LLM can utilize APE to generate a pool of instruction candidates. APE then selects the best instruction based on a chosen score function. The selected instruction is then used by another LLM to perform a task in a zero-shot setting. This process can be iterated to continuously improve the performance of the LLM."}, "category": "PROMPTING", "novelty_analysis": "The introduction of APE, a method enabling automatic generation and selection of instructions, advances the field by reducing the reliance on human-crafted prompts, marking a significant stride in the prompting techniques for LLMs.", "novelty_score": 3, "technical_analysis": "The paper delves into the intricate details of the APE method, its implementation, and how it is used to optimize the performance of LLMs, rendering it a highly technical read that might appeal to experts in the field.", "technical_score": 3, "enjoyable_analysis": "The discovery of APE and its potential are interesting, but the complexity of the technical content can pose a challenge for readers without a strong background in machine learning and statistical algorithms.", "enjoyable_score": 2}