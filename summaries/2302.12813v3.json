{"Published": "2023-03-08", "Title": "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback", "Authors": "Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, Jianfeng Gao", "Summary": "Large language models (LLMs), such as ChatGPT, are able to generate human-like, fluent responses for many downstream tasks, e.g., task-oriented dialog and question answering. However, applying LLMs to real-world, mission-critical applications remains challenging mainly due to their tendency to generate hallucinations and their inability to use external knowledge. This paper proposes a LLM-Augmenter system, which augments a black-box LLM with a set of plug-and-play modules. Our system makes the LLM generate responses grounded in external knowledge, e.g., stored in task-specific databases. It also iteratively revises LLM prompts to improve model responses using feedback generated by utility functions, e.g., the factuality score of a LLM-generated response. The effectiveness of LLM-Augmenter is empirically validated on two types of scenarios, task-oriented dialog and open-domain question answering. LLM-Augmenter significantly reduces ChatGPT's hallucinations without sacrificing the fluency and informativeness of its responses. We make the source code and models publicly available.", "main_contribution": {"headline": "LLM-AUGMENTER: Enhancing LLMs with External Knowledge and Automated Feedback", "description": "The paper introduces LLM-AUGMENTER, a system that augments large language models (LLMs) with plug-and-play modules to improve their performance in real-world applications. The system enables LLMs to generate responses grounded in external knowledge, such as task-specific databases, addressing the models' inability to use external knowledge. It also iteratively revises LLM prompts to improve model responses using feedback generated by utility functions, such as the factuality score of a LLM-generated response. The system significantly reduces the tendency of LLMs to generate hallucinations without sacrificing the fluency and informativeness of their responses."}, "takeaways": {"headline": "LLM-AUGMENTER offers a practical solution to improve LLMs' performance", "description": "LLM-AUGMENTER provides a practical solution to improve the performance of LLMs in real-world applications. By augmenting LLMs with plug-and-play modules, it allows the models to leverage external knowledge and automated feedback to generate more accurate and factual responses. This approach can be particularly useful in applications where the use of up-to-date and accurate information is critical, such as task-oriented dialog and open-domain question answering.", "example": "For instance, in a task-oriented dialog scenario, LLM-AUGMENTER can be used to generate responses based on the latest information stored in a task-specific database. If the initial response is not factual, the system can revise the prompt and generate a new response based on the feedback from the utility function."}, "category": "FINE-TUNING", "novelty_analysis": "The introduction of LLM-AUGMENTER represents a novel approach to improving the performance of LLMs. While previous methods have attempted to improve LLMs using external knowledge, this is the first to do so using plug-and-play modules and automated feedback, making it a significant contribution to the field.", "novelty_score": 3, "technical_analysis": "The paper is somewhat technical as it introduces a new system and discusses its implementation in detail. However, it does not delve into complex mathematical theories or algorithms, making it accessible to readers with a basic understanding of LLMs.", "technical_score": 2, "enjoyable_analysis": "The paper is well-written and presents a novel and intriguing contribution to the field of LLMs. It provides practical insights and real-world examples, making it an enjoyable read for those interested in the application of LLMs.", "enjoyable_score": 3}