{"2209.11515": "Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction", "2306.14101": "Language models are weak learners", "2102.07350": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm", "2306.07174": "Augmenting Language Models with Long-Term Memory", "2206.01335": "Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code", "2306.13651": "Bring Your Own Data! Self-Supervised Evaluation for Large Language Models", "2306.17156": "Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors", "2307.06945": "In-context Autoencoder for Context Compression in a Large Language Model", "2307.14475": "Educational data augmentation in physics education research using ChatGPT", "2307.09288": "Llama 2: Open Foundation and Fine-Tuned Chat Models", "2306.09896": "Demystifying GPT Self-Repair for Code Generation", "2212.10561": "Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions", "2211.09066": "Teaching Algorithmic Reasoning via In-context Learning", "2306.07906": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences", "2305.04388": "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting", "2305.18507": "Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models", "2307.05300": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration", "2202.03371": "Cedille: A large autoregressive French language model", "2307.08621": "Retentive Network: A Successor to Transformer for Large Language Models", "2210.03350": "Measuring and Narrowing the Compositionality Gap in Language Models", "2303.05349": "Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data", "2306.06156": "PoET: A generative model of protein families as sequences-of-sequences", "2203.05300": "Connecting Neural Response measurements & Computational Models of language: a non-comprehensive guide", "2212.06416": "One-shot Machine Teaching: Cost Very Few Examples to Converge Faster", "2307.07164": "Learning to Retrieve In-Context Examples for Large Language Models", "2307.14936": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback", "2307.12980": "A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models", "2305.16582": "Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models", "2306.15595": "Extending Context Window of Large Language Models via Positional Interpolation", "2306.09296": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models", "2307.05695": "Stack More Layers Differently: High-Rank Training Through Low-Rank Updates", "2304.00740": "Inspecting and Editing Knowledge Representations in Language Models", "2307.08674": "TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT", "2110.06500": "Differentially Private Fine-tuning of Language Models", "2302.00093": "Large Language Models Can Be Easily Distracted by Irrelevant Context", "2206.11861": "Automatic Generation of Programming Exercises and Code Explanations using Large Language Models", "2307.10168": "LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs", "2305.05976": "Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge", "2303.10130": "GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models", "2109.08060": "Urdu text in natural scene images: a new dataset and preliminary text detection", "2302.00560": "Co-Writing with Opinionated Language Models Affects Users' Views", "2307.08581": "BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs", "2305.15038": "Is GPT-4 a Good Data Analyst?", "2307.13269": "LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition", "2303.13988": "Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods", "2104.08145": "KI-BERT: Infusing Knowledge Context for Better Language and Domain Understanding", "2306.07951": "Questioning the Survey Responses of Large Language Models", "2306.08122": "Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to Document Level", "2302.06692": "Guiding Pretraining in Reinforcement Learning with Large Language Models", "2201.11990": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model", "2202.07646": "Quantifying Memorization Across Neural Language Models", "2307.03692": "Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning", "2307.03987": "A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation", "2306.07967": "One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning", "2307.02485": "Building Cooperative Embodied Agents Modularly with Large Language Models", "2210.05359": "Mind's Eye: Grounded Language Model Reasoning through Simulation", "2303.13367": "ChatGPT and a New Academic Reality: Artificial Intelligence-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing", "2301.11916": "Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning", "2212.08073": "Constitutional AI: Harmlessness from AI Feedback", "2307.03875": "Large Language Models for Supply Chain Optimization", "2305.13782": "Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks", "2304.13734": "The Internal State of an LLM Knows When its Lying", "2212.08286": "ALERT: Adapting Language Models to Reasoning Tasks", "2307.10169": "Challenges and Applications of Large Language Models", "2304.05332": "Emergent autonomous scientific research capabilities of large language models", "2305.14540": "LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond", "2304.01373": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling", "2305.06161": "StarCoder: may the source be with you!", "2307.02179": "Open-Source Large Language Models Outperform Crowd Workers and Approach ChatGPT in Text-Annotation Tasks", "2304.04370": "OpenAGI: When LLM Meets Domain Experts", "2305.00050": "Causal Reasoning and Large Language Models: Opening a New Frontier for Causality", "2208.10264": "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies", "2305.11206": "LIMA: Less Is More for Alignment", "2302.05206": "The Wisdom of Hindsight Makes Language Models Better Instruction Followers", "2307.02486": "LongNet: Scaling Transformers to 1,000,000,000 Tokens", "2206.10498": "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)", "2301.13819": "Causal-Discovery Performance of ChatGPT in the context of Neuropathic Pain Diagnosis", "2305.06311": "Automatic Evaluation of Attribution by Large Language Models", "2305.00061": "Explainable Verbal Reasoner Plus (EVR+): A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning", "2206.14858": "Solving Quantitative Reasoning Problems with Language Models", "2305.15408": "Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective", "2305.01210": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation", "2110.08413": "Invariant Language Modeling", "2205.08012": "CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction", "2306.05182": "Interactive Fashion Content Generation Using LLMs and Latent Diffusion Models", "2302.01560": "Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents", "2307.13692": "ARB: Advanced Reasoning Benchmark for Large Language Models", "2302.08399": "Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks", "2305.05176": "FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance", "2306.02864": "Leveraging Large Language Models for Topic Classification in the Domain of Public Affairs", "2301.06627": "Dissociating language and thought in large language models: a cognitive perspective", "2210.01287": "Robot Task Planning and Situation Handling in Open Worlds", "2307.03381": "Teaching Arithmetic to Small Transformers", "2301.12597": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models", "2306.06031": "FinGPT: Open-Source Financial Large Language Models", "2304.07619": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models", "2301.10226": "A Watermark for Large Language Models", "2305.13680": "ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course", "2305.14201": "Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks", "2211.13638": "Prototypical Fine-tuning: Towards Robust Performance Under Varying Data Sizes", "2306.08568": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "2207.07051": "Language models show human-like content effects on reasoning", "2303.15324": "Can Large Language Models design a Robot?", "2303.17580": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face", "2212.11214": "Crowd Score: A Method for the Evaluation of Jokes using Large Language Model AI Voters as Judges", "2306.12672": "From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought", "2302.12813": "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback", "2307.13702": "Measuring Faithfulness in Chain-of-Thought Reasoning", "2205.11822": "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations", "2202.13169": "A Systematic Evaluation of Large Language Models of Code", "2210.02406": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks", "2307.14225": "Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences", "2306.12509": "Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference", "2212.03447": "When Geometric Deep Learning Meets Pretrained Protein Language Models", "2210.03629": "ReAct: Synergizing Reasoning and Acting in Language Models", "2203.13474": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis", "2305.03047": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision", "2304.01852": "Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models", "2305.12199": "VNHSGE: VietNamese High School Graduation Examination Dataset for Large Language Models", "2305.08291": "Large Language Model Guided Tree-of-Thought", "2306.07075": "Large Language Models as Tax Attorneys: A Case Study in Legal Capabilities Emergence", "2302.14045": "Language Is Not All You Need: Aligning Perception with Language Models", "2208.11857": "Shortcut Learning of Large Language Models in Natural Language Understanding", "2302.02083": "Theory of Mind May Have Spontaneously Emerged in Large Language Models", "2307.12856": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis", "2208.09625": "SPOT: Knowledge-Enhanced Language Representations for Information Extraction", "2305.13733": "Self-Critique Prompting with Large Language Models for Inductive Instructions", "2307.06962": "Copy Is All You Need", "2305.07759": "TinyStories: How Small Can Language Models Be and Still Speak Coherent English?", "2304.01938": "Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics", "2209.01515": "Do Large Language Models know what humans know?", "2304.15004": "Are Emergent Abilities of Large Language Models a Mirage?", "2306.17806": "Stay on topic with Classifier-Free Guidance", "2212.10403": "Towards Reasoning in Large Language Models: A Survey", "2306.15448": "Understanding Social Reasoning in Language Models with Language Models", "2305.12031": "Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding", "2209.01975": "Selective Annotation Makes Language Models Better Few-Shot Learners", "2306.01116": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only", "2306.07899": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks", "2307.00112": "Performance of ChatGPT on USMLE: Unlocking the Potential of Large Language Models for AI-Assisted Medical Education", "2305.04091": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models", "2108.07435": "Modeling Protein Using Large-scale Pretrain Language Model", "2305.12152": "Re-visiting Automated Topic Model Evaluation with Large Language Models", "2304.01240": "Identifying Mentions of Pain in Mental Health Records Text: A Natural Language Processing Approach", "2307.08922": "Large Language Models Perform Diagnostic Reasoning", "2307.15217": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback", "2306.02707": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4", "2306.00550": "Chain-Of-Thought Prompting Under Streaming Batch: A Case Study", "2305.14314": "QLoRA: Efficient Finetuning of Quantized LLMs", "2208.04024": "Social Simulacra: Creating Populated Prototypes for Social Computing Systems", "2306.11644": "Textbooks Are All You Need", "2307.08701": "AlpaGasus: Training A Better Alpaca with Fewer Data", "2112.02969": "Jigsaw: Large Language Models meet Program Synthesis", "2205.09712": "Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning", "2209.07753": "Code as Policies: Language Model Programs for Embodied Control", "2307.06018": "PolyLM: An Open Source Polyglot Large Language Model", "2205.10775": "Ada-Ranker: A Data Distribution Adaptive Ranking Paradigm for Sequential Recommendation", "2305.08596": "DarkBERT: A Language Model for the Dark Side of the Internet", "2203.07281": "GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models", "2207.08143": "Can large language models reason about medical questions?", "1909.05356": "Entity Projection via Machine Translation for Cross-Lingual NER", "2307.15337": "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding", "2209.05735": "Learning ASR pathways: A sparse multilingual ASR model", "2102.02503": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models", "2212.10071": "Large Language Models Are Reasoning Teachers", "2307.11795": "Prompting Large Language Models with Speech Recognition Abilities", "2306.13421": "Long-range Language Modeling with Self-retrieval", "2301.13379": "Faithful Chain-of-Thought Reasoning", "2212.10846": "From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models", "2307.09793": "On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models", "2306.14514": "Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation", "2212.05238": "Structured information extraction from complex scientific text with fine-tuned large language models", "2305.04369": "Getting More out of Large Language Models for Proofs", "2306.02914": "Beyond Generating Code: Evaluating GPT on a Data Visualization Course", "2307.13854": "WebArena: A Realistic Web Environment for Building Autonomous Agents", "2203.10133": "Probing Factually Grounded Content Transfer with Factual Ablation", "2305.16837": "ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks", "2203.10415": "How does the pre-training objective affect what large language models learn about linguistic properties?", "2306.02230": "Prompt Sapper: LLM-Empowered Software Engineering Infrastructure for AI-Native Services", "2306.16410": "Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language", "2306.08162": "INT2.1: Towards Fine-Tunable Quantized Large Language Models with Error Correction through Low-Rank Adaptation", "2304.03245": "Large language models effectively leverage document-level context for literary translation, but critical errors persist", "2307.09009": "How is ChatGPT's behavior changing over time?", "2307.14995": "Scaling TransNormer to 175 Billion Parameters", "2209.12356": "News Summarization and Evaluation in the Era of GPT-3", "2306.14824": "Kosmos-2: Grounding Multimodal Large Language Models to the World", "2303.14310": "GPT is becoming a Turing machine: Here are some ways to program it", "2305.09993": "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling", "2307.00184": "Personality Traits in Large Language Models", "2302.06527": "Adaptive Test Generation Using a Large Language Model", "1811.04064": "Block Belief Propagation for Parameter Learning in Markov Random Fields", "2304.10428": "GPT-NER: Named Entity Recognition via Large Language Models", "2210.00720": "Complexity-Based Prompting for Multi-Step Reasoning", "2305.08845": "Large Language Models are Zero-Shot Rankers for Recommender Systems", "2302.00618": "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models", "2208.07339": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale", "2303.08119": "How Many Demonstrations Do You Need for In-context Learning?", "2303.08896": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models", "2304.09842": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models", "2303.11366": "Reflexion: Language Agents with Verbal Reinforcement Learning", "2305.10601": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "2305.02301": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes", "2303.17564": "BloombergGPT: A Large Language Model for Finance", "2303.17491": "Language Models can Solve Computer Tasks", "2210.03493": "Automatic Chain of Thought Prompting in Large Language Models", "2210.11610": "Large Language Models Can Self-Improve", "2305.15324": "Model evaluation for extreme risks", "2304.05128": "Teaching Large Language Models to Self-Debug", "2304.03442": "Generative Agents: Interactive Simulacra of Human Behavior", "2210.01293": "ThinkSum: Probabilistic reasoning over sets using large language models", "2212.08410": "Teaching Small Language Models to Reason", "2204.02311": "PaLM: Scaling Language Modeling with Pathways", "2110.01691": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts", "2203.06566": "PromptChainer: Chaining Large Language Model Prompts through Visual Programming", "2212.03551": "Talking About Large Language Models", "2304.13731": "Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model", "2205.11916": "Large Language Models are Zero-Shot Reasoners", "2303.05382": "ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?", "2304.01933": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models", "2209.11302": "ProgPrompt: Generating Situated Robot Task Plans using Large Language Models", "2211.09085": "Galactica: A Large Language Model for Science", "2303.07205": "The Science of Detecting LLM-Generated Texts", "2211.01910": "Large Language Models Are Human-Level Prompt Engineers", "2212.13138": "Large Language Models Encode Clinical Knowledge", "2212.04088": "LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models", "2206.07682": "Emergent Abilities of Large Language Models", "2205.10625": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models", "2304.10592": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models", "2204.00498": "Evaluating the Text-to-SQL Capabilities of Large Language Models", "2205.03767": "Context-Aware Abbreviation Expansion Using Large Language Models", "2303.07678": "Query2doc: Query Expansion with Large Language Models", "2212.09561": "Large Language Models are Better Reasoners with Self-Verification", "2206.12839": "Repository-Level Prompt Generation for Large Language Models of Code", "2211.08411": "Large Language Models Struggle to Learn Long-Tail Knowledge", "2211.10438": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models", "2205.08184": "SKILL: Structured Knowledge Infusion for Large Language Models", "2305.11171": "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models", "2307.15189": "Med-Flamingo: a Multimodal Medical Few-shot Learner", "2308.00951": "From Sparse to Soft Mixtures of Experts", "2308.01825": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models", "2307.16789": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "2308.00436": "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning", "2308.00675": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models", "2308.01320": "DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales", "2305.16504": "On the Tool Manipulation Capability of Open-source Large Language Models", "2308.00304": "Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models", "2307.15780": "LLM-Rec: Personalized Recommendation via Prompting Large Language Models", "2308.00113": "Three Bricks to Consolidate Watermarks for Large Language Models", "2308.01390": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models", "2308.01399": "Learning to Model the World with Language", "2308.00352": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework", "2307.15771": "The Hydra Effect: Emergent Self-repair in Language Model Computations", "2308.01734": "Ambient Adventures: Teaching ChatGPT on Developing Complex Stories", "2308.03958": "Simple synthetic data reduces sycophancy in large language models", "2308.03296": "Studying Large Language Model Generalization with Influence Functions", "2308.03279": "UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition", "2308.05374": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment", "2308.03427": "TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents", "2308.02151": "Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization", "2308.03028": "Pre-Trained Large Language Models for Industrial Control", "2308.03729": "Tiny LVLM-eHub: Early Multimodal Experiments with Bard", "2308.03688": "AgentBench: Evaluating LLMs as Agents", "2308.05221": "Alexa, play with robot: Introducing the First Alexa Prize SimBot Challenge on Embodied AI", "2308.04623": "Accelerating LLM Inference with Staged Speculative Decoding", "2308.04265": "FLIRT: Feedback Loop In-context Red Teaming", "2308.04592": "Shepherd: A Critic for Language Model Generation", "2308.07921": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification", "2308.07968": "Teach LLMs to Personalize -- An Approach inspired by Writing Education", "2308.05960": "BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents", "2308.07286": "The Devil is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation", "2308.07317": "Platypus: Quick, Cheap, and Powerful Refinement of LLMs", "2308.07891": "Link-Context Learning for Multimodal LLMs", "2308.05884": "PIPPA: A Partially Synthetic Conversational Dataset", "2308.06259": "Self-Alignment with Instruction Backtranslation", "2308.07922": "RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models", "2308.06261": "Enhancing Network Management Using Code Generated by Large Language Models", "2308.06912": "CausalLM is not optimal for in-context learning", "2308.07124": "OctoPack: Instruction Tuning Code Large Language Models", "2306.01693": "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training", "2305.18290": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model", "2307.03170": "Focused Transformer: Contrastive Training for Context Scaling", "2307.03172": "Lost in the Middle: How Language Models Use Long Contexts", "2306.00739": "SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL", "2305.12544": "A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models", "2305.15507": "The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python", "2306.17563": "Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting", "2306.08302": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "2306.14898": "InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback", "2307.14334": "Towards Generalist Biomedical AI", "2306.12420": "LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models", "2307.15043": "Universal and Transferable Adversarial Attacks on Aligned Language Models", "2305.15334": "Gorilla: Large Language Model Connected with Massive APIs", "2306.00029": "CodeTF: One-stop Transformer Library for State-of-the-art Code LLM", "2305.17333": "Fine-Tuning Language Models with Just Forward Passes", "2307.01928": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners", "2307.11088": "L-Eval: Instituting Standardized Evaluation for Long Context Language Models", "2305.02309": "CodeGen2: Lessons for Training LLMs on Programming and Natural Languages", "2306.00323": "Thought Cloning: Learning to Think while Acting by Imitating Human Thinking", "2307.14335": "WavJourney: Compositional Audio Creation with Large Language Models", "2306.03819": "LEACE: Perfect linear concept erasure in closed form", "2305.08283": "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models", "2305.16291": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "2306.11695": "A Simple and Effective Pruning Approach for Large Language Models", "2307.08691": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning", "2307.10802": "Meta-Transformer: A Unified Framework for Multimodal Learning", "2306.04563": "ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models", "2307.10928": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "2306.17842": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs", "2307.04964": "Secrets of RLHF in Large Language Models Part I: PPO", "2305.20050": "Let's Verify Step by Step"}