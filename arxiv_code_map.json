{"2209.11515v3": "Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction", "2306.14101v1": "Language models are weak learners", "2102.07350v1": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm", "2306.07174v1": "Augmenting Language Models with Long-Term Memory", "2206.01335v2": "Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code", "2306.13651v2": "Bring Your Own Data! Self-Supervised Evaluation for Large Language Models", "1510.08555v2": "Why Johnny Still, Still Can't Encrypt: Evaluating the Usability of a Modern PGP Client", "2306.17156v2": "Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors", "2307.06945v1": "In-context Autoencoder for Context Compression in a Large Language Model", "2307.14475v1": "Educational data augmentation in physics education research using ChatGPT", "2307.09288v2": "Llama 2: Open Foundation and Fine-Tuned Chat Models", "2306.09896v3": "Demystifying GPT Self-Repair for Code Generation", "2212.10561v3": "Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions", "2211.09066v1": "Teaching Algorithmic Reasoning via In-context Learning", "2306.07906v1": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences", "2305.04388v1": "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting", "2305.18507v1": "Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models", "2307.05300v2": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration", "2202.03371v1": "Cedille: A large autoregressive French language model", "2307.08621v3": "Retentive Network: A Successor to Transformer for Large Language Models", "2210.03350v2": "Measuring and Narrowing the Compositionality Gap in Language Models", "2303.05349v1": "Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data", "2306.06156v1": "PoET: A generative model of protein families as sequences-of-sequences", "2203.05300v1": "Connecting Neural Response measurements & Computational Models of language: a non-comprehensive guide", "2212.06416v1": "One-shot Machine Teaching: Cost Very Few Examples to Converge Faster", "2307.07164v1": "Learning to Retrieve In-Context Examples for Large Language Models", "2307.14936v1": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback", "2307.12980v1": "A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models", "2305.16582v1": "Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models", "2306.15595v2": "Extending Context Window of Large Language Models via Positional Interpolation", "2306.09296v2": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models", "2307.05695v2": "Stack More Layers Differently: High-Rank Training Through Low-Rank Updates", "2304.00740v2": "Inspecting and Editing Knowledge Representations in Language Models", "2307.08674v2": "TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT", "2110.06500v2": "Differentially Private Fine-tuning of Language Models", "2302.00093v3": "Large Language Models Can Be Easily Distracted by Irrelevant Context", "2206.11861v2": "Automatic Generation of Programming Exercises and Code Explanations using Large Language Models", "2307.10168v2": "LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs", "2305.05976v2": "Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge", "2303.10130v4": "GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models", "2109.08060v1": "Urdu text in natural scene images: a new dataset and preliminary text detection", "2302.00560v1": "Co-Writing with Opinionated Language Models Affects Users' Views", "2307.08581v1": "BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs", "2305.15038v1": "Is GPT-4 a Good Data Analyst?", "2307.13269v1": "LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition", "2303.13988v3": "Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods", "2104.08145v2": "KI-BERT: Infusing Knowledge Context for Better Language and Domain Understanding", "2306.07951v1": "Questioning the Survey Responses of Large Language Models", "2306.08122v1": "Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to Document Level", "2302.06692v1": "Guiding Pretraining in Reinforcement Learning with Large Language Models", "2201.11990v3": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model", "2202.07646v3": "Quantifying Memorization Across Neural Language Models", "2307.03692v1": "Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning", "2307.03987v1": "A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation", "2306.07967v1": "One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning", "2307.02485v1": "Building Cooperative Embodied Agents Modularly with Large Language Models", "2210.05359v1": "Mind's Eye: Grounded Language Model Reasoning through Simulation", "2303.13367v2": "ChatGPT and a New Academic Reality: Artificial Intelligence-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing", "2301.11916v2": "Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning", "2212.08073v1": "Constitutional AI: Harmlessness from AI Feedback", "2307.03875v2": "Large Language Models for Supply Chain Optimization", "2305.13782v1": "Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks", "2304.13734v1": "The Internal State of an LLM Knows When its Lying", "2212.08286v2": "ALERT: Adapting Language Models to Reasoning Tasks", "2307.10169v1": "Challenges and Applications of Large Language Models", "2304.05332v1": "Emergent autonomous scientific research capabilities of large language models", "2305.14540v1": "LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond", "2304.01373v2": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling", "2305.06161v1": "StarCoder: may the source be with you!", "2307.02179v1": "Open-Source Large Language Models Outperform Crowd Workers and Approach ChatGPT in Text-Annotation Tasks", "2304.04370v4": "OpenAGI: When LLM Meets Domain Experts", "2305.00050v2": "Causal Reasoning and Large Language Models: Opening a New Frontier for Causality", "2208.10264v5": "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies", "2305.11206v1": "LIMA: Less Is More for Alignment", "1809.07428v1": "Ranking Distillation: Learning Compact Ranking Models With High Performance for Recommender System", "2302.05206v1": "The Wisdom of Hindsight Makes Language Models Better Instruction Followers", "2307.02486v2": "LongNet: Scaling Transformers to 1,000,000,000 Tokens", "2206.10498v3": "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)", "2301.13819v2": "Causal-Discovery Performance of ChatGPT in the context of Neuropathic Pain Diagnosis", "2305.06311v1": "Automatic Evaluation of Attribution by Large Language Models", "2305.00061v1": "Explainable Verbal Reasoner Plus (EVR+): A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning", "2206.14858v2": "Solving Quantitative Reasoning Problems with Language Models", "2305.15408v3": "Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective", "2305.01210v2": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation", "2110.08413v2": "Invariant Language Modeling", "2205.08012v2": "CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction", "2008.01508v2": "Explanation of Reinforcement Learning Model in Dynamic Multi-Agent System", "2306.05182v1": "Interactive Fashion Content Generation Using LLMs and Latent Diffusion Models", "2302.01560v1": "Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents", "2307.13692v2": "ARB: Advanced Reasoning Benchmark for Large Language Models", "2302.08399v5": "Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks", "2305.05176v1": "FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance", "2306.02864v1": "Leveraging Large Language Models for Topic Classification in the Domain of Public Affairs", "2301.06627v1": "Dissociating language and thought in large language models: a cognitive perspective", "2210.01287v1": "Robot Task Planning and Situation Handling in Open Worlds", "2307.03381v1": "Teaching Arithmetic to Small Transformers", "2301.12597v3": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models", "2306.06031v1": "FinGPT: Open-Source Financial Large Language Models", "2304.07619v3": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models", "2301.10226v3": "A Watermark for Large Language Models", "2305.13680v1": "ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course", "2305.14201v1": "Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks", "2211.13638v1": "Prototypical Fine-tuning: Towards Robust Performance Under Varying Data Sizes", "2306.08568v1": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "2207.07051v1": "Language models show human-like content effects on reasoning", "2303.15324v1": "Can Large Language Models design a Robot?", "2303.17580v3": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face", "2212.11214v1": "Crowd Score: A Method for the Evaluation of Jokes using Large Language Model AI Voters as Judges", "2306.12672v2": "From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought", "2302.12813v3": "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback", "2307.13702v1": "Measuring Faithfulness in Chain-of-Thought Reasoning", "2205.11822v2": "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations", "2202.13169v3": "A Systematic Evaluation of Large Language Models of Code", "2210.02406v2": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks", "2307.14225v1": "Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences", "2306.12509v1": "Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference", "2212.03447v1": "When Geometric Deep Learning Meets Pretrained Protein Language Models", "2210.03629v3": "ReAct: Synergizing Reasoning and Acting in Language Models", "2203.13474v5": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis", "2305.03047v1": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision", "2304.01852v3": "Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models", "2305.12199v1": "VNHSGE: VietNamese High School Graduation Examination Dataset for Large Language Models", "2305.08291v1": "Large Language Model Guided Tree-of-Thought", "2306.07075v1": "Large Language Models as Tax Attorneys: A Case Study in Legal Capabilities Emergence", "2302.14045v2": "Language Is Not All You Need: Aligning Perception with Language Models", "2208.11857v2": "Shortcut Learning of Large Language Models in Natural Language Understanding", "2302.02083v3": "Theory of Mind May Have Spontaneously Emerged in Large Language Models", "2307.12856v1": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis", "2208.09625v2": "SPOT: Knowledge-Enhanced Language Representations for Information Extraction", "2305.13733v1": "Self-Critique Prompting with Large Language Models for Inductive Instructions", "2307.06962v1": "Copy Is All You Need", "2110.01140v1": "Structured abbreviation expansion in context", "2305.07759v2": "TinyStories: How Small Can Language Models Be and Still Speak Coherent English?", "2304.01938v1": "Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics", "2209.01515v3": "Do Large Language Models know what humans know?", "2304.15004v2": "Are Emergent Abilities of Large Language Models a Mirage?", "2006.11705v1": "UO2/BeO interfacial thermal resistance and its effect on fuel thermal conductivity", "2306.17806v1": "Stay on topic with Classifier-Free Guidance", "2212.10403v2": "Towards Reasoning in Large Language Models: A Survey", "2306.15448v1": "Understanding Social Reasoning in Language Models with Language Models", "2305.12031v1": "Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding", "2209.01975v1": "Selective Annotation Makes Language Models Better Few-Shot Learners", "2306.01116v1": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only", "2306.07899v1": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks", "2307.00112v2": "Performance of ChatGPT on USMLE: Unlocking the Potential of Large Language Models for AI-Assisted Medical Education", "2305.04091v3": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models", "2108.07435v2": "Modeling Protein Using Large-scale Pretrain Language Model", "2305.12152v1": "Re-visiting Automated Topic Model Evaluation with Large Language Models", "2304.01240v2": "Identifying Mentions of Pain in Mental Health Records Text: A Natural Language Processing Approach", "2307.08922v1": "Large Language Models Perform Diagnostic Reasoning", "2307.15217v1": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback", "2306.02707v1": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4", "2306.00550v1": "Chain-Of-Thought Prompting Under Streaming Batch: A Case Study", "2305.14314v1": "QLoRA: Efficient Finetuning of Quantized LLMs", "2208.04024v1": "Social Simulacra: Creating Populated Prototypes for Social Computing Systems", "2306.11644v1": "Textbooks Are All You Need", "2307.08701v1": "AlpaGasus: Training A Better Alpaca with Fewer Data", "2112.02969v1": "Jigsaw: Large Language Models meet Program Synthesis", "2205.09712v1": "Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning", "2209.07753v4": "Code as Policies: Language Model Programs for Embodied Control", "2307.06018v1": "PolyLM: An Open Source Polyglot Large Language Model", "2205.10775v1": "Ada-Ranker: A Data Distribution Adaptive Ranking Paradigm for Sequential Recommendation", "2305.08596v2": "DarkBERT: A Language Model for the Dark Side of the Internet", "2203.07281v2": "GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models", "2207.08143v3": "Can large language models reason about medical questions?", "1909.05356v2": "Entity Projection via Machine Translation for Cross-Lingual NER", "2307.15337v1": "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding", "2209.05735v3": "Learning ASR pathways: A sparse multilingual ASR model", "2102.02503v1": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models", "2212.10071v2": "Large Language Models Are Reasoning Teachers", "2307.11795v1": "Prompting Large Language Models with Speech Recognition Abilities", "1909.05330v1": "Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", "2306.13421v1": "Long-range Language Modeling with Self-retrieval", "2301.13379v2": "Faithful Chain-of-Thought Reasoning", "2212.10846v3": "From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models", "2307.09793v1": "On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models", "2306.14514v2": "Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation", "2212.05238v1": "Structured information extraction from complex scientific text with fine-tuned large language models", "2305.04369v2": "Getting More out of Large Language Models for Proofs", "2306.02914v1": "Beyond Generating Code: Evaluating GPT on a Data Visualization Course", "2307.13854v1": "WebArena: A Realistic Web Environment for Building Autonomous Agents", "2203.10133v2": "Probing Factually Grounded Content Transfer with Factual Ablation", "2305.16837v1": "ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks", "2203.10415v1": "How does the pre-training objective affect what large language models learn about linguistic properties?", "2306.02230v1": "Prompt Sapper: LLM-Empowered Software Engineering Infrastructure for AI-Native Services", "2306.16410v1": "Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language", "2306.08162v1": "INT2.1: Towards Fine-Tunable Quantized Large Language Models with Error Correction through Low-Rank Adaptation", "1904.08003v1": "Explicit Motion Risk Representation", "2304.03245v3": "Large language models effectively leverage document-level context for literary translation, but critical errors persist", "2307.09009v1": "How is ChatGPT's behavior changing over time?", "2307.14995v1": "Scaling TransNormer to 175 Billion Parameters", "2209.12356v2": "News Summarization and Evaluation in the Era of GPT-3", "2306.14824v3": "Kosmos-2: Grounding Multimodal Large Language Models to the World", "2303.14310v1": "GPT is becoming a Turing machine: Here are some ways to program it", "2305.09993v1": "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling", "2307.00184v1": "Personality Traits in Large Language Models", "2302.06527v2": "Adaptive Test Generation Using a Large Language Model", "1811.04064v1": "Block Belief Propagation for Parameter Learning in Markov Random Fields"}